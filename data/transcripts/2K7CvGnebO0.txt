 The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. So I've got a little list of things I'm hoping to do today. I'll begin with a few final words about saddle points. The reason I'm interested in saddle points is when we get to this deep learning direction, you know that the big step there is finding a minimum of the total cost function and gradient descent, which we'll certainly discuss as the usual method, or stochastic gradient descent. And all kinds of issues arise. What happens if you have a saddle point? Or a degenerate minimum? All these possibilities and the understanding of deep learning is focusing more and more on what does that gradient descent algorithm produce? So I just thought minima and maxima we know about. Saddle points are kind of a little hazier, right? This is a perfect example, and I'll just say a few more words about it. Then I want to talk about the lab 3 that I boldly posted on Stellar, and also about projects, just to get us thinking about those. And then my real math topic for today and this week is basic ideas of statistics, particularly the covariance matrix. I'm sure you've met mean and variance. Those are the most used words, and we'll use them again. But then I want to go on to covariance. OK, so that's what's coming today. A few words on saddle points, a lot of words about the lab, and anything you want to ask about projects, and then some basic statistics. OK, saddle point. So the example I'm taking is this Rayleigh quotient. And I'm taking a simple matrix S. I might as well take a diagonal matrix, because it's symmetric, of course. And any symmetric matrix, I could just change variables by a Q matrix, an orthogonal matrix, to get to something like that. And then the x, we're in 3D. So we've got a sort of manageable size here. And the x vector is uvw. So this is the quotient. X transpose x, you see, is just exactly 5u squared, 3v squared, and 1w squared. And I divide by the length to normalize things. So what are the main facts that we know that I'm not going to prove? But what are the main facts? What's the maximum value of R? What's the minimum value of R, of that function? And is there a saddle point? So saddle of R. OK, what's the maximum value? How large could you make that ratio, capital R? I just think this isn't a standard topic in 1806. But with an example like this, you'll see the whole point. OK, so how large could I make R? Yeah, go ahead and say it. Sigma 1, but what is it here? Let's just do with these numbers. How big can I make that ratio R? And what choice of uvw makes it big? So how big I can get it is? 5. That ratio can't be more than 5. You see, it would be 5. Well, how do I get to 5? Maximum of R is 5. And what is the uvw that at? So I'll say at. What choice of uvw would give us 5 here? You see it immediately, 1, 0, 0. And what about the minimum of R? The minimum of this ratio? How do I make that ratio small? Well, I load stuff onto w instead of loading it up onto u. It's just clear. So what is the minimum value of R? 1, because I'll load everything into w. So the minimum value will be 1. And that will be at the vector 0, 0, 1. I've loaded everything there. And then the point of this short discussion is, is there another place where the derivatives, first derivatives of R are all 0? That's where, of course, the first derivatives are 0 at the max, at the min. But we have three variables here. And we're going to find a third point. And what is that point? You probably guess. And what will be the saddle value? So you have to see some kind of a surface. I guess, what are we in? 4D. So we have vectors. We have base coordinates, uvw. And R goes vertically. And we plot that surface. And we don't really understand it, unless we think a lot about it, which we haven't. But we can pretty well guess what's what. And so what do you think is the saddle value? And where is it going to be reached? Everybody's going to tell me correctly. Saddle value would be 3 at this middle point. OK. And what are these three with respect to the matrix? They're its eigenvectors. What are these three numbers with respect to the matrix? They're its eigenvalues. It's just like that's why that Rayleigh quotient is such an important function. It's kind of a messy function. If you take its derivative, you've got to use the quotient rule or use Lagrange multiplier to make it. That's the way to make it more manageable. But it's kind of messy. But the results could not be better. The values there are the eigenvalues. And the places where you reach them are the eigenvectors. And so the max is the most important. So that's sigma 1. Here's sigma 3, or lambda and sigma, because the matrix is symmetric positive definite. And here in the middle is sigma 2. And if we want to compute eigenvectors, which I'm not planning to do today just to make this remark, computing eigenvectors, getting the largest one or the smallest one is a lot quicker in general than getting these ones in the middle. You have to use good codes and pay attention to computing those saddle point values. So is there anything nice I can do with saddle points? How does one think about saddle points? So again, saddle point is defined by first derivatives equal 0. And the second derivative, OK, so that's a matrix. Here's a vector, the gradient vector. The derivative with respect to u, the derivative with respect to v, and dr, dw, just a vector. And all those components are 0. The gradient vector is 0. But what about second derivatives? Well, that's getting more. There are nine of those now, because I've got R uu, second derivative, with respect to u, second. But I've got mixed derivatives, second derivative of R with respect to du, dv. So I have a 3 by 3 matrix. Fortunately, that matrix is symmetric, because we're blessed by that wonderful fact that the derivative with respect to u and then v is the same as v and then u. So we get a symmetric matrix. And it's, well, I won't write it down. But it's going to have a, you know, it's got the maximum, minimum, and saddle information built in. Here's this one additional thought that I want to communicate about saddle points, because it's really nice to somehow get back to maxima and minima. So the idea of this idea for a saddle point is to be able to write it as the maximum of a minimum. In a way, yeah. So let me do that. And then I'm all done. So I'm going to say that lambda 2, that value, is the maximum of over something of the minimum over something of x trans of our function. OK, now, of course, I have to tell you what you're maximizing over and what you're minimizing over. But that's the idea, is that one way to get into that middle place there where the saddles are sitting is to have a maximum of a minimum. And that leads, this what I'm about to complete here, would lead you, for example, very quickly to the interlacing theorem that I spoke about for eigenvalues and for singular values of when you perturb s or when you throw away a row and column of s, the eigenvalues go in between. That is the kind of conclusion that this max-min stuff is set up to produce. So here, let me just tell you what it would be. I'm aiming to get lambda 2. OK, so I'm going to take a maximum over 2D, two-dimensional spaces, subspaces of R3. We're in 3D. So you can see that sort of like two-dimensional spaces. Let me give that subspace a name like V. Yeah, that'll do. Cap V, everybody can see that that's a cap V. And then this will be the minimum over V. So it's kind of tricky. So I take any subspace that's two-dimensional. And I'll take one in a moment. And I'll figure out the minimum. Well, suppose I take the subspace V, which is spanned by the first two. It's supposed to be a 2D subspace. Spanned by the first, suppose I try example. Example, the span of 1, 0, 0 and 0, 1, 0. In other words, all vectors u, v, 0. That's a 2D space. What is the minimum of that Rayleigh quotient over that two-dimensional space? So now I'm taking a minimum. I don't have to think about saddle points. So I'm looking at the thing. But w is 0 now. Everybody sees that I've squeezed it down to 2D. So w is 0. So what is the minimum now? So this thing would become, for this space, would become the 5u squared and the 3v squared over the u squared plus the v squared. But the w is 0. So what's the minimum of that? 3. 3. OK. The minimum is 3 for this particular space. Let me call it v special. For that particular space, the minimum is 3. Correct? Everybody sees that because I just have u and v to play with, the 5 and the 3. So if I put everything into v, I get the 3. And now I take the maximum. So I've learned that this, so the maximum is at least 3 because this particular choice of v gave me the answer 3. And now I'm taking the maximum of all possible 2D spaces. And I'll certainly, I got 3 for one of the possible spaces v. And I might get higher than 3 for some other one. But actually, I don't. The truth is that this turns out to be 3, which is, of course, exactly what we wanted. So I'm saying that this particular two-dimensional space, the minimum over that, minimum, the minimum there is 3. And now I maximize over all others. And so the idea is that for any other one, the minimum value will be below 3. And therefore, when I go for the max of the mins, I get 3. So I just repeat that and then be quiet about this whole subject. So it's a maximum over subspaces of a minimum of the Rayleigh quotient. If that subspace is exactly the perfect choice, this one, I get the value 3. And I'm claiming that's the biggest value I can get. Because if I pick any other subspace, what if I picked a subspace that, suppose another v would be all vectors 0, v, w. What would be the minimum? What would I get for the minimum of this thing? But now w is in the picture. And u is not in the picture. What would I get for the minimum there? 1. I'd get 1. The minimum would be when I put everything into w and I got 1. And then when I take the max, it's not a winner. It's thrown out. The winner will be that space and the 3. So I guess I'm hoping that you sort of see in this small example that you can express this middle saddle value as a. It's reasonable to think of it as a maximum in some directions and a minimum in another. Think of the, well, try to think of some surface which is going up in some directions. So it's a minimum in those directions. And it's going down in other directions. So it's a max in those directions. And the saddle point is perched in there at that, right at that place at the saddle point. If you're hiking from here to California or something, you're going to pass a saddle point. Actually, you see it on the Mass. Pike has an amazing little sign. I don't know if you've noticed it. If you drive west on the Mass. Pike, pretty far west of Boston, there's a little sign, saying telling you the altitude or elevation, whatever. And it says there, this is the highest point until you reach the Rockies, basically. That's like, OK, Midwest is pretty flat, right? Because that's a long way away. You don't think of Massachusetts as like really in the big league with high spots. But there it is. It's the highest one until you get. And I think it tells you where the next one will be in Colorado. Anyway, those highest points tend to be saddles, the very, very highest point. Where is that? In Alaska or somewhere. That's a max, of course, by definition. But there are a lot of saddle points in other places. And those would be maxima of minima or minima of maxima. Good. I'm stopping there. We might see this again when we start gradient descent. But at least, because saddle points don't come up much in teaching calculus, I thought that was good. OK. The second point is models, lab 3, and projects, anything you'd like to ask about projects. So please, this is your chance to ask. You could also ask by email. If you have a suggested idea for a project, let me encourage you or a team to work on it or just yourself. And if you want to think, OK, shall I get some feedback of does this sound sensible, any suggestions, send me an email. Yeah. I'll be happy to. Of course, I'm a total beginner here, too. When I created this lab 3, I was desperate. Not for model 1. For model 1, have you looked at the online? It's reached stellar. It's only one printed page. Have people had a look at this? So I'll just repeat quickly. Model 1 is an example of overfitting and what's going on with model 1. So model 1 says take 5 would be enough, but I probably said 10 or something, so I'll make it 6 points. And put a curve through them. So if you put a curve, and the curve is going to be a polynomial. So we're going to fit by polynomial. Everybody knows polynomial is c0 plus c1x plus whatever. ckx to the k, let's say. OK. For k equals 0, well, I don't know if I even asked 0. That would be the best straight line. That would be run along the average. k equal to 1, that would be a straight line fit. And you would compute that by these squares, because of course, no straight line is going to go through all the points. You're going to have some error by least squares. 2 would be fitting by a parabola. Again, you'll have some error, but smaller, since parabolas include straight lines. So you can only reduce the total sum of squares error by going to degree 2, degree 3, and up to how many points? Should we take 1, 2? Let me just use the same letter I've used here. Probably have 0. Well, the m is the number of points, but m varies between one point, I guess, and probably n points. Yeah, or maybe k here. Up to n. Up to 6, let's say. And I want to make a comment about 6. No, 5 would do it. Won't. Degree 5 will fit the 6 points. We've got 6 points here. But if I stop at degree 5, I was better there, because degree 5 polynomial also has a constant term. So it really has 6 coefficients. So there's a degree. There's a 1 degree 5 polynomial with 6 numbers, 6 coefficients, that goes through those 6 points. So it's a perfect fit. That would be an exact fit of the data. So here's the data. Create a polynomial of degree 5 that goes through those points exactly and look at the result. And what would you see if you look at the result? Would it be smooth? Of course. It's a polynomial. Would it be nice? No, it'll be horrible. To get through those points, did I get 6 points? Yeah. To get through those points, I'm guessing that that fifth degree polynomial, the perfect fit, is an example that occurs to practically everybody of overfitting. Because making that decision, perfect fit, learn the training data exactly, will send a polynomial. I don't know what it looks like. Well, I do want to know, but not right now. Anyway, craziness. And of course, I'm going to ask. It doesn't look like that, probably. I'm going to ask you to plot the results. What's the least squares error when you fit by a straight line, when you fit by a horizontal line, a constant, fit by a straight line, move up to parabolas, move up to cubics? But when you hit this, you're not making any error at all. You're not really needing to use least squares. You can solve Ax equal b, Ac equal b equals b. So this is the b thing. And c is the vector of coefficients. And the matrix A is bad news when it's 6 by 6, when you get up to a complete fit. And I guess what I wanted just to see is a lot of things I don't know. Like, suppose I change 6 to 20 or something. Then I'm pretty sure that out there at 18, 19, 20, this thing is really off the map. And you could compute its max. And you'd see a very big number. But I don't know where. But of course, for a straight line, that would be pretty safe. The slope would be pretty moderate. And I don't know where you. So that's probably underfitting to try to fit this by a straight line. It's not as close as you would want. But fitting by a full perfect fitting, so high degree polynomial is certainly overfitting. Where is the boundary? I'm sure people know about this. But I think it is something we could learn from. So that's what that model 1 is about. And just to make one final comment, that matrix A has a name in the case where it's a square matrix, where you're fitting exactly. Interpolating would be the word. So that exact fit, that corresponds to square matrix A. And the word for it is interpolation. And I guess it's Lagrange again, seeing that guy too often here. So it'd be Lagrange interpolation. But the matrix has a different name. And whose name is associated with that matrix? Vandermonde. Vandermonde. So this is the square matrix, which was, so let me write it. This is called a Vandermonde matrix. And it's a matrix that has a crazy large inverse. Because just as I'm saying, the C that comes out from the perfect fit, from the interpolation, from the square matrix, the C is going to be giant. And so you will construct a matrix, of course, to do this. And it will be identical to the Vandermonde. So we've heard this word Vandermonde matrix in this class within the last week. Anybody remember where the word Vandermonde came up in class? It was in Professor Townsend's lecture. So you could go back to that video if you wanted as an example of a matrix which had a horrible inverse, a giant matrix. The Hilbert matrix was another example. I think he did two examples, Vandermonde and Hilbert. So this Vandermonde matrix, I could write it down, but I'll leave that to you, has a big inverse. And its eigenvalues, well, no, singular values, because it's not symmetric, its singular values are way scattered. It has tiny little singular values plus an ordinary size singular values. So that's the example that I just think you could go with. And as far as I can see, sending it to autograder as a Julia file, it'll be even worse than usual sending it to autograder. I think it wouldn't know what to do as far as I can see. So I'm thinking of some submissions coming to grade scope. And I'm thinking of some plots to show what happens as K increases and some tables of data maybe, and then maybe a paragraph of conclusion, like what degree is safe, and when does it become risky, and when does it become disaster? So stuff like that. It's really these are sort of open-ended labs, and you use any language. Questions about that example, which is really that's what I'm expecting to be ready and quite a good example for Wednesday after the break. Question or? Anyway, you could email me. You should probably see what the model looks like. Then the second one, I've taken a first jump into networks, made a very simple network without any hidden layers at all, actually, and just wrote down what I think might work. But you may find that you want to modify model 2, go for it. I don't have any patent or personal stake in the way model 2 is written, but the idea is fit data and start with data, but don't make it too perfect, because we want some learning to happen here. And so it's the classification problem. So it won't be least squares with variables like u and v and w. It's just plus 1 or minus 1, or 1, 0, or cat and dog, whatever the classification is. So that's the basic problem to start with in deep learning. For quite a long time, that's the natural problem. So it's a classification problem. And the description here suggests one way to set up the training data and execute a neural net-like experiment, but without getting very far away from ordinary linear algebra. Yeah. As I say, if you want to change this, develop it further, get some ideas about it, that's what the whole point is here. Actually, the faculty meeting on this week, maybe today. What's today? Wednesday? Yeah, so it's this afternoon. Faculty doesn't come too much, but of course, it's late in the afternoon. But faculty meeting this afternoon is about MIT's plans for requirements or courses in computational thinking. And in a way, this course within the math department is among the ones that are in that direction. Of course, in other departments, those are further along. Anyway, when Raj Rao taught the course last spring, he had the Julia system better developed. And it was a chance to bring computers and bring laptops and do things in class. And you'll have that chance again when he visits in a month. OK, enough. And I'm open to questions about the project. Should I maybe ask you to email me a rough idea of a project? And tell me if you're in a group or if you would like to find a group of maybe two or three people. I'm not thinking of groups of 50. Two or three would be sensible. Questions about project. I mean, I just introduced this idea of a project, and I apologize for it, not bringing it up the first week. But I just couldn't see. I don't want to do exams on linear algebra. We've passed that point. So this seemed the right way to go. But I'm not looking for a PhD thesis here. Questions, thoughts? I guess I hope you know you can ask. Yeah, oh, good. AUDIENCE 2 So can you maybe describe the scope of the project? So not PhD thesis. Right. How will I? I think, yeah, so the scope is connected to the time that you would devote to it. And what should I say about scope? Maybe the equivalent of three homeworks or something? Because I'll tamp down homeworks as project date gets closer. Does that give an idea that it's not infinite, but it's not something tiny and trivial? Yeah, good. Do you have any example projects? Well, that's the thing. There aren't really past years. We are the ones. We are the ones. So I will have next year if you contribute some good ideas. Maybe I should ask Professor Rao to maybe send us the projects he uses in Michigan. That would be some ideas. But remember that he hasn't, up to now anyway, moved the course toward deep learning. He did other topics, all of which would be fine. But then quite a few people have had some 6036 or know something about convolutional neural nets. And I'm certainly excited to get to that topic. So the project could get there or it could not. Both totally fine. OK, that's a good idea. I'll ask Raj for just the projects. And you'll recognize a couple because you've done a couple. But there are a bunch more. Yeah, then there was another question or thought. And I'm remembering that there was, I think, maybe everybody got an email or a stellar announcement that some members of the class took an initiative, which was wonderful, to open the possibility of people just showing up one evening a week in the media lab, was it? Or was there a location? And has it happened? Or is it a future event? It happened. OK. But people, I hadn't mentioned it in class, so probably you didn't have and were not really into projects yet. So it was probably a quiet evening? Yeah, yeah. And that's productive but quiet. OK, so will it happen again? AUDIENCE 2 Sure. I think maybe now we'll be looking after spring break. GILBERT STRANGEIRO. After spring break, OK. So post again on Stellar the plan for the next meeting that people could come to. Yeah, that is good. So this is David Anderton. So you'll recognize his name. And did you have the meeting in the media lab? AUDIENCE 2 We had it on the Thursday and the Friday. GILBERT STRANGEIRO. OK, OK. So with the break coming and spring hopefully coming after today's potential storm. Yeah, when we come back, good. OK, is that good? I hope some of that is helpful. You get an idea. You're seeing about as much as I know, which is model 1 is definitely doable and very significant. And van der Waals matrices and so on are truly important. And their instability is a big issue. But then moving toward weights and training data and test data is where we want to go. Good, OK. So do I have some time? I do. Just to speak about mean and variance, the two golden words of statistics, and covariance, the matrix, the intersection of linear algebra with statistics, and then some famous inequality. So I'll continue with this on Friday and post some of the material. So that's coming from a later section of notes. OK, can I just talk about? So I either have probabilities P1 up to Pn adding to 1, or I have a continuous distribution of probabilities, maybe from all x's from minus infinity to infinity, again giving 1. Let me work with the discrete example. That's where people naturally start. So what does the mean? So I have n possible outcomes with those probabilities. And I can ask you about the sample mean, or I can ask you about the expected mean. So the sample means we've done an experiment. We've got some output. The expected mean means we know probabilities, but we haven't used them yet. So this uses actual output. And the sample mean is simply, let me, shall I just say, M for mean. Well, these two are importantly different. One is something where you've done the experiment, and this is before you do the experiment. And the letters get maybe mu. I'll change to mu. I don't want to use S, because S gets used with variance. OK, so it's just the average, the average output from the sample. So like I flipped a coin a million times, and the output was 0 or 1. So I got a million 1's and 0's, and I take the average, and I'm expecting a number like half a million, because I'm thinking of a fair coin. So that, and the law of large numbers, would say that this sample mean does approach 1 half with probability 1 as the number of samples gets larger. So sample mean is straightforward. The expected mean means these are actual sample outputs. They happened. Whereas the expected mean is just the, and I'll use M for that, it's the probability of the first output times that output, plus the probability of the second output times that output, plus Pnxn. Pnxn. OK. So that will approach that with probability 1 as this number, capital N. Notice the difference. Capital N here is the number of samples, the number of trials. And it gets big. We keep doing things more and more. This is just, this little n is the number of possible different outputs with their probabilities. And there you see it. And of course, in the continuous case, we would take the integral of x, P of x dx. So let me just by analogy. You should know what the continuous version is and what the discrete version is. OK. That's the mean. OK. Now for variance. Sample variance. And shall I say expected variance? I don't know. Just variance is what people would usually say. I don't know if I remember the right word there. Sample variance. It's a, what is that? I included this topic in the linear algebra book. Anyway, yeah. OK. So what's the sample variance? So I guess I'm, yeah. So what is the sample variance? What's the variance about, anyway? What's the key point of variance? It's the distance from the mean. So it'll be, this will be a distance from the sample mean. And this will be a distance from the expected mean. So not distance from 0, but distance from mu and m from the center of the thing. OK, so the sample variance. So again, we have n samples. But for some wonderful reason in statistics, you divide by n minus 1 this time. And the reason has to do with the fact that you used 1. This will involve the mean. So this would be the first output minus mu squared up to the n-th output minus mu squared. So it's the average distance from mu, average square distance from mu, but with this little twist that, of course, when n is large, it's not a very significant difference between n and n minus 1. I think that's about right. All this is that I'm just doing one experiment over and over. Covariance, which is the deeper idea, is where linear algebra comes in. I have a matrix. Because why? Because I'm doing several, multiple experiments at the same time. I'm flipping two coins. I'm flipping 15 coins. I'm doing other things. So that will be covariances when I'm doing several experiments at once. That will involve matrices of that size. So what's the variance? I should have given you the usual notation, the expected value of x. That's what's the mean. And here I'm looking at the expected value of what? So when I'm computing a variance using probabilities, so I'm using expectations, not trial runs. Expectations means use the probabilities. And what is the expectation of the distance from x to the mean squared? OK. And that is, when I'm doing an expectation for a discrete set, I think of the probability, the first probability that goes with an output x1, and a second probability that goes with an output x2. And each time I subtract from the mean and square. OK. So that's the variance that everybody calls sigma squared. OK. Now, two minutes left is enough to say a few more words about covariance. Oh, to get to covariance, I really have to speak about joint probabilities. That's a key idea, joint probabilities. So I'm doing two experiments at once. So each one has its own probabilities. But together, I have to ask, so here are two easy cases. Suppose I'm flipping two coins. So I might get heads, heads. I may get heads, tails, tails, heads, or tails, tails. Four possibilities, four possible outputs there, four possible pairs. OK. And if you're flipping one coin and I'm flipping another one, those are independent results. Those are independent results. There won't be a covariance where by knowing what my flip was, I would know more about your flip. But now, the other possibility would be to glue the coins together. Now, if I do a flip, they always come up, heads and heads, or tails and tails. So the heads, tails combination is not possible. In fact, one output is totally dependent on the other output. So that's the other extreme. We have independent outputs with covariance 0. And we have totally dependent outputs when the things are just glued together, when one result tells us what the other result is. Then that situation where the covariance is a maximum couldn't be bigger than that. And say in polling, if you were polling a family, say political polling, well, there would be some covariance expected there. The two or three or five people living in the same house wouldn't be independent, entirely independent, nor would they always say all five give the same answer. So the covariance matrix would have some off diagonal, but it would still be not invertible. And actually, what I want to tell you about next time at the start is that covariance matrix, which I have to define for you, will be symmetric positive definite or semidefinite. What's the semidefinite case? Of course, that's the case where the coins are glued together. OK, thanks. So you know what's coming Friday. I know that holiday is also coming Friday, and you'll make a good plan, and I'll move on after the break. Good.