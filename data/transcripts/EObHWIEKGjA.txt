 Το επόμενο πρόγραμμα προσφέρει πάνω από ένα δίκτυο Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει να προσφέρει υψηλές ειδικές παιδικοί ειδικές πράγματα για ελεύθερα. Για να κάνετε μια δομή ή να παρακολουθείτε περισσότερα υλικά από χιλιάδες μαθητές MIT, επισκεφθείτε το MIT OpenCourseWare στηn ocw.mit.edu. Ωραία, καλημέρα. Σήμερα θα έχουμε μια αρκετά συγκεντρωμένη δική διάσκεδα. Θα τελειώσουμε με το κεφάλαιο 2, Διεξαρτημένες διεξαρτημένες διαφορετικές, και θα μιλήσουμε κυρίως για διεξαρτημένες διεξαρτημένες διαφορετικές. Και αυτό είναι και το τελευταίο διάσκεδο, εξ αριθμού προς το πρόγραμμα 1. Θα κλείσει το υλικό μέχρι σήμερα, και φυσικά το επόμενο διεξαρτημένο και τουτορίαλ. Εντάξει, θα δούμε γρήγορα τι παρουσιάσαμε στο τέλος της τελευταίας διεξαρτημένης, όπου μιλήσαμε για το συγκεντρωμένο PMF των δύο διεξαρτημένων διαφορετικών. Θα μιλήσουμε για το πρόβλημα με περισσότερα δύο διεξαρτημένες διαφορετικών επίσης. Θα μιλήσουμε για τα γνωστικά μας κοινά κοινότητα, εξ αρχής και ανεξαρτημένων, αλλά προσφερμένα σε διεξαρτημένες διαφορετικές αντί για πράγματα. Θα δούμε πια τις εξετάσεις, θα μιλήσουμε για μερικές αντικειμενιές που έχουν, και μετά θα λύσουμε μερικές προβλήματα και θα καταφερθούμε μερικές πράγματα σε κάποια λεπτομέρειες. Ο πρώτος σημείο που θέλω να κάνω είναι ότι, σε μεγάλο σημείο, ό,τι συμβαίνει στον κεφάλαιο μας στις διεξαρτημένες διαφορετικές αντίδρατες είναι μόνο ένα δραστηριόμενο εξετάσιο. Υπάρχουν πράγματα και κοινότητες που ήθελες να γνωρίσεις, προβλήματα, προβλήματα για δύο πράγματα συμβαίνοντας, προβλήματα συνδεδεμένων, και όλα αυτά που κάνουμε, σε κάποιο σημείο, είναι να γραφτούμε αυτές τις γνωστές κοινότητες σε νέα σημεία. Για παράδειγμα, αυτό είναι η συγκεντρωμένη πλειοψηφία δύο δραστηριόμενων διαφορετικών, δίνει για κάθε δίκιο δυνατόν αξιωματικών διαιτημάτων την προβλήματιά ότι αυτή η δίκιοψηφία συμμετεχνίζεται. Στη συντονή, αυτή η προβλήματιά είναι ότι X Corner ε��τερ metallic με τη σημερινή το πτώμα για αυτό το βασ niveλή και Y Corner εδώ εννομενος αξιωματικ Signal to Value για αυτό το βάσιμο το βασιμο försöή. παρεμπάει ένα σύμφωνα πλεονυκό τεντόπλικο, κι courtscrew, όπου υπάρχει μόνο μια εστίοτητα εισηθισμάτων εισητιστιών ευαε ellas. Δυ modsilence Regio δυ modsilince Rego δυ modsilincre ενός τέτοιού handle Another normal Βμη Pr. Η σχόλη μας για τα καταδικασμένα πιθανότητα, τα καταδικασμένα πιθανότητα γενικά είναι σαν καθαρές πιθανότητες, εσείς καταδικαστείτε σε κάτι συγκεκριμένο, οπότε εδώ καταδικαστούμε σε ένα συγκεκριμένο y, οπότε πιστεύτε στο λίγο y ως μια κομμάτια, και μετά δείτε αυτό ως ένα λειτουργικό x. Οπότε, δεδομένου το y, με το οποίο καταδικαστούμε, δεδομένου το νέο μας κόσμο, εξετάζουμε τα διάφορα ευθύνα για x και τις προφιλότητες που έχουν. Τώρα, οι προφιλότητες για όλα τα x, φυσικά, πρέπει να προσθέσουμε ένα, οπότε πρέπει να έχουμε μια σχέση αυτού του είδους. Οπότε, είναι σαν καθαρές προφιλότητες για τα διαφορετικά x σε ένα κόσμο όπου μας λένε το αριθμό της δίκαιης διευθύνης y. Τώρα, πώς είναι αυτοί συνδεδεμένοι? Ας το λέμε το αριθμό, αυτό το κοινό, αυτό το συνδεδεμένο, και υπάρχουν μερικές σχέσεις με αυτά. Για παράδειγμα, για να βρεις το αριθμό από το κοινό, είναι αρκετά εύκολο. Η προφιλότητα ότι x πάρει ένα συγκεκριμένο αριθμό είναι η σωματία των προφιλότητων όλων των διαφορετικών τρόπων που μπορεί να συμβαίνει αυτό το συγκεκριμένο αριθμό. Ποιες είναι οι διαφορετικές τρόποι? Μπορεί να συμβαίνει μαζί με μια συγκεκριμένη y, ή μαζί με κάποια άλλη y, ή μαζί με κάποια άλλη y. Λοιπόν, αντιμετωπίζεις όλες τις δυνατόν y που μπορούν να συμβαίνουν μαζί με αυτήν την x, και προσθέτεις όλων αυτών των δυοπαίρων, για τα οποία λάβουμε αυτό το συγκεκριμένο αριθμό x. Και τότε υπάρχει μια σχέση που συνδέει αυτά τα δύο προφιλότητα με την συνδεδεμένη προφιλότητα, και είναι αυτή η σχέση. Εντάξει, δεν είναι τίποτα νέο, είναι μόνο μια νοτατία νέα για να γράψουμε αυτό που ήδη γνωρίζουμε, ότι η προφιλότητα των δύο πράγμαντων συμβαίνει είναι η προφιλότητα ότι το πρώτο πράγμα συμβαίνει, και τότε, διότι το πρώτο πράγμα συμβαίνει, η προφιλότητα ότι το δεύτερο πράγμα συμβαίνει. Λοιπόν, πώς πάμε από ένα στο άλλο? Νομίζω το A ως το πράγμα που η x παίρνει το αριθμό x, και το B ως το πράγμα που η y παίρνει το αριθμό λίγο y. Λοιπόν, η σύνδεση προφιλότητα, είναι η προφιλότητα ότι αυτοί οι δύο πράγματα συμβαίνουν σύνθετον. Είναι η προφιλότητα ότι η x πάρει αυτό το αριθμό, με την ανθροπιστική προφιλότητα ότι η y πάρει αυτό το αριθμό, δεδομένη από το γεγονός ότι η x πήρε αυτό το πρώτο αριθμό. Λοιπόν, είναι η γνωστή ψηφιακή ρόλη, αλλά μόνο μεταγραφείτες στην νέα μας σημεία. Οπότε, τίποτα νέο μέχρι τώρα. Οκ, γιατί πήγαμε μέχρι αυτό το δραστηριόμενο και αυτή την σημεία? Είναι γιατί, στις εξετάσεις που εμείς είμαστε ενδιαφέροντες, τύπικα, υπάρχουν πολλά αδερφάδια κομμάτια, υπάρχουν πολλές διπλανές διαφορετικές, και θέλουμε να μπορούμε να μιλήσουμε για αυτά τα ίδια. Οκ, γιατί δύο και όχι περισσότερο από δύο? Πώς για τρία διπλανές διαφορετικές? Ως εάν καταλαβαίνετε τι συμβαίνει σε αυτό το σκηνικό, θα πρέπει να μπορείτε να γεννηθείτε αυτό αυτοματοφερικά σε περίπτωση διπλανών διαφορετικών διαφορετικών. Λοιπόν, για παράδειγμα, αν έχουμε τρία διπλανές διαφορετικές, X, Y και Z, και βλέπετε ένα εφαρμογήμα όπως αυτό, θα πρέπει να είναι ξεκάθαρο τι σημαίνει. Είναι η πιθανότητα ότι X πάρει αυτό το αριθμό, και συνεχώς Y πάρει αυτό το αριθμό, και συνεχώς Z πάρει αυτό το αριθμό. Νομίζω ότι αυτό είναι ένα κλειδί Z εδώ, αυτό είναι ένα κλειδί Z. Οκ, και αν σας ζητώ να βρειτε το κλειδί X, αν σας πω την συμμετεχνία PMF των τρία διπλανών διαφορετικών και σας ζητώ αυτό το αριθμό, πώς θα το βρείτε? Βλέπω ότι θα προσπαθήσετε να γεννιτιοποιήσετε αυτή την σχέση εδώ. Η πιθανότητα ότι X συμβαίνει είναι η σωματία των πιθανότητών όλων των συμβουλών που κάνουν X να πάρει αυτό το αριθμό. Οπότε τι είναι όλες τις συμβουλές? Αυτή η συμβουλή X μπορεί να συμβεί μαζί με κάποια Y και κάποια Z. Δεν μας αργούν ποια Y και Z, κάποια Y και Z θα κάνουν. Οπότε όταν προσφέρουμε όλες τις δυνατότητες, πρέπει να προσφέρουμε εδώ όλες τις δυνατότητες Y και Z. Προσφέρουμε όλες τις διπλανών, XYZ. Συγκρινίστε X και προσφέρουμε όλες τις δυνατότητες για τα υπόλοιπα διαφορετικά, Y και Z. Προσφέρουμε όλες τις δυνάτοιες και αυτό σας δίνει το πλήρισμα PMF X. Και τότε υπάρχουν άλλα πράγματα που μπορείτε να κάνετε. Αυτή είναι η συμβουλή για δύο συμβούλες. Είδαμε πριν στο κεφάλαιο 1 ότι υπάρχει μια συμβουλή όταν μιλήσετε για περισσότερα από δύο συμβούλες και μπορείτε να γράψετε μια κλίμακα για δυνατότητες. Μπορούμε σίγουρα να κάνουμε το ίδιο για την νέα μας σύνδεση. Ας δούμε την κλίμακα εδώ. Κλίμακα για τρία δυνάτοιες διαφορετικά. Τι λέει? Η πιθανότητα των τρία πράγματων συνεχώς συμβαίνοντας, X, Y, Z, πάρουν συγκεκριμένα αξίες, λίγο X, λίγο Y, λίγο Z. Αυτή η πιθανότητα είναι η πιθανότητα ότι το πρώτο πράγμα συμβαίνει, ότι το X πάρει αυτή την αξία. Δεδομένου ότι το X πάρει αυτή την αξία, διδάσκουμε με την πιθανότητα ότι το Y πάρει επίσης μια συγκεκριμένη αξία. Και τώρα, διότι το X και το Y έχουν πάρει αυτές τις συγκεκριμένες αξίες, διδάσκουμε με την πιθανότητα ότι το τρίτο πράγμα συμβαίνει, διότι το πρώτο πράγμα συμβαίνει. Αυτή είναι μόνο η πιθανότητα διαπραγματεύσεις για τρία συμβουλές, η οποία θα ήταν η πιθανότητα A εναντίον B εναντίον C που είναι, ξέρετε, το υπόλοιπο της ορισμού. Απλά διαφράζετε αυτή την ορισμότητα με τη σύγκριση π.μ.F. Η πιθανότητα A εναντίον B εναντίον C είναι η πιθανότητα A, η οποία αντιμετωπίζεται με αυτό το τερμό, με την πιθανότητα B, δεδομένη με A, με την πιθανότητα C, δεδομένη με A και B. OK. Τι άλλο υπάρχει από το κεφάλαιο 1 που μπορούμε ή πρέπει να γεννιτιοποιήσουμε σε δύο διευθυντικές διαφορές? Βέβαια, υπάρχει η νόση της ανεξαρτησίας. Ας δημιουργήσουμε τι σημαίνει ανεξαρτησία. Αντί να μιλήσουμε μόνο για δύο διευθυντικές διαφορές, ας πάμε αυτοκτονικά στο πράγμα διευθυντικών διευθυντικών διαφορών. Όταν μιλήσαμε για συμφωνίες, τα πράγματα ήταν λίγο συγκλειμένα. Είχαμε μια απλή κατεστημένη για ανεξαρτησία δύο συμφωνίες. Αλλά για τρία συμφωνίες ήταν λίγο σκληρά. Πρέπει να γράψουμε πολλά κατάσταση. Για διευθυντικές διαφορές, τα πράγματα, σε κάποιο σημείο, είναι λίγο απλότερα. Πρέπει μόνο να γράψουμε ένα πρόγραμμα και να το παρατηρήσουμε ως κατεστημένη κατεστημένη κατεστημένη. Τρία διευθυντικές διαφορές είναι ανεξαρτηστικές. Αν και μόνο αν, από τελοφόνο, η διευθυντική πραγματικότητα της συμφωνίας συμφωνίζεται με το ίδιο σύμφωνος πραγματικός διευθυντικός διευθυντικός διευθυντικός. Η προσφορά όλων των τρέντων συμφωνίων είναι τα επίπαιδη προφανωτικών πραγματικών σε κάθε έναν από αυτά τα τρία συμφωνία. Αυτή η ανεξαρτησία σημαίνει, μεταγραφικά, that you can just multiply probabilities to get the probability of several things happening simultaneously. Okay, so with events, with three events, we have to write a huge number of equations, of equalities that have to hold. How can it be that with random variables we can only manage with one equality? Well, the catch is that this is not really just one equality. We require this to be true for every little x, y, and z. So in some sense, this is a bunch of conditions that are being put on the joint PMF, a bunch of conditions that we need to check. So this is the mathematical definition. What is the intuitive content of this definition? The intuitive content is the same as for events. Random variables are independent if knowing something about the realized values of some of these random variables does not change our beliefs about the likelihood of various values for the remaining random variables. So independence would translate, for example, to a condition such as the conditional PMF of x given y should be equal to the marginal PMF of x. What is this saying? That you have some original beliefs about how likely it is for x to take this value. Now someone comes and tells you that y took on a certain value. This causes you, in principle, to revise your beliefs, and your new beliefs will be captured by the conditional PMF, or the conditional probabilities. Independence means that your revised beliefs actually will be the same as your original beliefs. Telling you information about the value of y doesn't change what you expect for the random variable x. Why didn't we use this definition of independence? Well, because this definition only makes sense when this conditional is well-defined. And this conditional is only well-defined if the event that y takes on that particular value has positive probability. We cannot condition on events that have 0 probability. So conditional probabilities are only defined for y's that are likely to occur, that have a positive probability. Now similarly, with multiple random variables, if they're independent, you would have relations such as the conditional of x given y and z should be the same as the marginal of x. What is this saying? Again, that if I tell you the values, the realized values of random variables y and z, this is not going to change your beliefs about how likely x is to occur. Whatever you believed in the beginning, you're going to believe the same thing afterwards. So it's important to keep that intuition in mind, because sometimes this way you can tell whether random variables are independent without having to do calculations and to check this formula. OK, so let's check our concepts with a simple example. Let's look at two random variables that are discrete, take values between 1 and 4 each. And this is a table that gives us the joint PMF. So it tells us the probability that x equals to 2 and y equals to 1 happening simultaneously. It's an event that has probability 1 over 20. Are these two random variables independent? You can try to check a condition like this. But can we tell directly from the table? If I tell you a value of y, could that give you useful information about x? Certainly. If I tell you that y is equal to 1, this tells you that x must be equal to 2. But if I tell you that y was equal to 3, this tells you that still x could be anything. So telling you the value of y kind of changes what you expect or what you consider possible for the values of the other random variable. So by just inspecting here, we can tell that the random variables are not independent. OK, what's the other concept we introduced in Chapter 1? We introduced the concept of conditional independence. And conditional independence is like ordinary independence, but applied to a conditional universe where we're given some information. So suppose someone tells you that the outcome of the experiment is such that x is less than or equal to 2 and y is larger than or equal to 3. So we are given the information that we now live inside this universe. So what happens inside this universe? Inside this universe, our random variables are going to have a new joint PMF, which is conditioned on the event that we were told that it has occurred. So let A correspond to this sort of event here. And now we're dealing with conditional probabilities. What are those conditional probabilities? We can put them in a table. So it's a 2 by 2 table, since we only have two possible values. What are they going to be? Well, these probabilities show up in the ratios 1, 2, 2, and 4. Those ratios have to stay the same. The probabilities need to add up to 1. So what should the denominators be? Since these numbers add up to 9, these are the conditional probabilities. So this is the conditional PMF in this example. OK. Now, in this conditional universe, is x independent from y? If I tell you that y takes this value, so we live in this universe, what do you know about x? What you know about x is that this value is twice as likely as that value. If I condition on y taking this value, so we're living here, what do you know about x? What you know about x is that this value is twice as likely as that value. So it's the same. Whether we live here or we live there, this x is twice as likely as that x. So the conditional PMF in this new universe, the conditional PMF of x given y in the new universe is the same as the marginal PMF of x, but of course, in the new universe. So no matter what y is, the conditional PMF of x is the same, and that conditional PMF is 1 third and 2 thirds. This is the conditional PMF of x in the new universe, no matter what y occurs. So y does not give us any information about x, doesn't cause us to change our beliefs inside this little universe, and therefore the two random variables are independent. Now, the other way that you can verify that we have independence is to find the marginal PMFs of the two random variables. The marginal PMF of x, you find it by adding those two terms, you get 1 third. Adding those two terms, you get 2 thirds. Marginal PMF of y, you find it, you add these two terms and you get 1 third. And the marginal PMF of y here is going to be 2 thirds. And then you ask the question, is the joint the product of the marginals? And indeed it is. This times this gives you 1 ninth. This times this gives you 2 ninths. So the values in the table with the joint PMFs is the product of the marginal PMFs of x and y in this universe. So the two random variables are independent inside this universe. So we say that they're conditionally independent. All right, now let's move to the new topic, to the new concept that we introduced in this chapter, which is the concept of expectations. So what are the things to know here? One is the general idea. The way to think about expectations is that it's something like the average value of a random variable if you do an experiment over and over, and if you interpret probabilities as frequencies. So you get x's over and over. With a certain frequency, p of x, a particular value little x gets realized. And each time that this happens, you get x dollars. How many dollars do you get on the average? Well, this formula gives you that particular average. So first thing we do is to write down a definition for this sort of concept. But then the other things you need to know is how to calculate expectations using shortcuts sometimes, and what properties they have. The most important shortcut there is that if you want to calculate the expected value, the average value of a random variable, you do not need to find the PMF of that random variable, but you can work directly with the x's and the y's. So you do the experiment over and over. The outcome of the experiment is a pair xy, and each time that a certain xy happens, you get so many dollars. So this fraction of the time, a certain xy happens, and that fraction of the time you get so many dollars. So this is the average number of dollars that you get. So what you end up, since it is the average, then that means that it corresponds to the expected value. Now this is something that, of course, needs a little bit of mathematical proof, but it's just a different way of accounting. And it turns out to give you the right answer, and it's a very useful shortcut. Now when we're talking about functions of random variables, in general, we cannot speak just about averages. That is, the expected value of a function of a random variable is not the same as the function of the expected values. A function of averages is not the same as the average of a function. So in general, this is not true. But what is important to know is to know the exceptions to this rule. And the important exceptions are mainly two. One is the case of linear functions of a random variable. We discussed this last time. So expected value of temperature in Celsius is you first find the expected value of temperature in Fahrenheit, and then you do the conversion to Celsius. So whether you first average and then do the conversion to the new units or not, it shouldn't matter when you get the result. The other property that turns out to be true when you talk about multiple random variables is that expectation still behaves linearly. So let X, Y, and Z be the score of a random student at each one of the three sections of the SAT. So the overall score, SAT score, is X plus Y plus Z. This is the average score, the average total SAT score. Another way to calculate that average is to look at the first section of the SAT and see what was the average. Look at the second section, look at what was the average, and so the third, and add the averages. So you can do the averages for each section separately, add the averages, or you can find total scores for each student and average them. So I guess you probably believe that this is correct if you talk just about averaging scores. Since expectations are just a variation of averages, it turns out that this is also true in general. And the derivation of this is very simple based on the expected value rule, and you can look at it in the notes. So this is one exception, which is linearity. The second important exception is the case of independent random variables, that the product of two random variables has an expectation which is the product of the expectations. In general, this is not true. But for the case where we have independence, the expectation works out as follows. Using the expected value rule, this is how you calculate the expected value of a function of a random variable. So think of this as being your g of x, y, and this being your g of little x, y. So this is something that's generally true. Now if we have independence, then the PMFs factor out. And then you can separate this sum by bringing together the x terms, bring them outside the y summation, and you find that this is the same as expected value of x times expected value of y. So independence is used in this step here. OK, now what if x and y are independent, but instead of taking the expectation of x times y, we take expectation of the product of two functions of x and y. I claim that the expected value of the product is still going to be the product of the expected values. How do we show that? We could show it by just redoing this derivation here. Instead of x and y, we would have g of x and h of y, so the algebra goes through. But there's a better way to think about it, which is more conceptual. And here's the idea. If x and y are independent, what does it mean? x does not convey any information about y. If x conveys no information about y, does x convey information about h of y? No. If x tells me nothing about y, nothing new, it shouldn't tell me anything about h of y. Now if x tells me nothing about h of y, could g of x tell me something about h of y? No. So the idea is that if x is unrelated to y, doesn't have any useful information, then g of x could not have any useful information for h of y. So if x and y are independent, then g of x and h of y are also independent. OK, so this is something that one can try to prove mathematically, but it's more important to understand conceptually why this is so. OK, it's in terms of conveying information. So if x tells me nothing about y, x cannot tell me anything about y cubed, or x cannot tell me anything about y squared, and so on. That's the idea. And once we are convinced that g of x and h of y are independent, then we can apply our previous rule that for independent random variables, expectations multiply the right way. Apply the previous rule, but apply it now to these two independent random variables. And we get the conclusion that we wanted. Now besides expectations, we can also apply the rule that we introduced in the last class. Now besides expectations, we also introduced the concept of the variance. And if you remember the definition of the variance, let me write down the formula for the variance of AX. It's the expected value of the random variable that we're looking at minus the expected value of the random variable that we're looking at. So this is the difference of the random variable from its mean. And we take that difference and square it, so it's the squared distance from the mean, and then take expectations of the whole thing. So when you look at that expression, you realize that A can be pulled out of those expressions. And because there is a squared, when you pull out the A, it's going to come out as an A squared. So that gives us the rule for finding the variance of a scalar product of a random variable. The variance captures the idea of how wide, how spread out a certain distribution is. Bigger variance means it's more spread out. Now if you take a random variable and add a constant to it, what does it do to its distribution? It just shifts it. But it doesn't change its width. So intuitively, it means that the variance should not change. You can check that mathematically, but it should also make sense intuitively. So the variance, when you add the constant, does not change. Now can you add variances the way we added expectations? Does variance behave linearly? It turns out that not always. Here we need a condition. It's only in special cases, for example, when the two random variables are independent, that you can add variances. The variance of the sum is the sum of the variances if x and y are independent. The derivation of this is, again, very short and simple. We'll skip it. But it's an important fact to remember. Now to appreciate why this equality is not true always, we can think of some extreme examples. Suppose that x is the same as y. What's going to be the variance of x plus y? Well, x plus y in this case is the same as 2x. So we're going to get 4 times the variance of x, which is different than the variance of x plus the variance of x. So that expression would give us twice the variance of x, but actually now it's 4 times the variance of x. The other extreme would be if x is equal to minus y. Then the variance is the variance of the random variable, which is always equal to 0. Now a random variable which is always equal to 0 has no uncertainty. It is always equal to its mean value. So the variance in this case turns out to be 0. So in both of these cases, of course, we have random variables that are extremely dependent. Why are they dependent? Because if I tell you something about y, it tells you an awful lot about the value of x. There's a lot of information about x if I tell you y in this case or in that case. And finally, a short drill. If I tell you that the random variables are independent and you want to calculate the variance of a linear combination of this kind, then how do you argue? You argue that since x and y are independent, this means that x and 3y are also independent. x has no information about y, so x has no information about minus y. x has no information about minus y, so x should not have any information about minus 3y. So x and minus 3y are independent. So the variance of z should be the variance of x plus the variance of minus 3y, which is the variance of x plus 9 times the variance of y. Important thing to note here is that no matter what happens, you end up getting a plus here, not a minus. So that's the sort of important thing to remember in this type of calculation. All right, so this has been all concepts, reviews, new concepts, and all that. It's the usual fire hose. Now let's use them to do something useful, finally. So let's revisit our old example, the binomial distribution, which counts the number of successes in n independent trials of a coin. It's a biased coin that has a probability of heads or probability of success equal to p at each trial. Finally, we can go through the exercise of calculating the expected value of this random variable. And there's the way of calculating that expectation that would be the favorite of those people who enjoy algebra, which is to write down the definition of the expected value. We add over all possible values of the random variable, over all the possible k's, and weigh them according to the probabilities that this particular k occurs. The probability that X takes on a particular value k is, of course, the binomial PMF, which is this familiar formula. OK, clearly that would be a messy and challenging calculation. Can we find a shortcut? There's a very clever trick. There's lots of problems in probability that you can approach really nicely by breaking up a random variable of interest into a sum of simpler and more manageable random variables. And if you can make it to be a sum of random variables that are just 0's or 1's, so much the better. Life is easier. Random variables that take values 0 or 1, we call them indicator variables. They indicate whether an event has occurred or not. In this case, we look at each coin flip one at a time. For the i flip, if it resulted in heads or a success, we record a 1. If not, we record a 0. And then we look at the random variable. If we take the sum of the Xi's, what is it going to be? We add 1 each time that we get a success. So the sum is going to be the total number of successes. So we break up the random variable of interest as a sum of really nice and simple random variables. OK, and now we can use the linearity of expectations. We're going to find the expectation of X by finding the expectation of the Xi's and then adding the expectations. What's the expected value of Xi? Well, Xi takes the value 1 with probability p and takes the value 0 with probability 1 minus p. So the expected value of Xi is just p. So the expected value of X is going to be just n times p. Because X is the sum of n terms, each one of which has expectation p, the expected value of the sum is the sum of the expected values. So I guess that's a pretty good shortcut for doing this horrendous calculation up there. So in case you didn't realize it, that's what we just established without doing any algebra. Good, how about the variance of Xi? Two ways to calculate it. One is by using directly the formula for the variance, which would be, let's see what it would be. With probability p, you get a 1. And in this case, you are so far from the mean, that's your squared distance from the mean. With probability 1 minus p, you get a 0, which is so far away from the mean. And then you can simplify that formula and get an answer. How about a slightly easier way of doing it? Instead of doing the algebra here, let me indicate the slightly easier way. We have a formula for the variance that tells us that we can find the variance by proceeding this way. That's a formula that's generally true for variances. Why is this easier? What's the expected value of Xi squared? Backtrack. What is Xi squared, after all? It's the same thing as Xi. Since Xi takes values 0 and 1, Xi squared also takes the same values, 0 as 1. So the expected value of Xi squared is the same as the expected value of Xi, which is equal to p. And the expected value of Xi squared is p squared. So we get the final answer, p, 1 minus p. If you were to work through and do the cancellations in this messy expression here, after one line you would also get to the same formula. But this sort of illustrates that working with this formula for the variance, sometimes things work out a little faster. Finally, are we in business? Can we calculate the variance of the random variable X as well? Well, we have the rule that for independent random variables, the variance of the sum is the sum of the variances. So to find the variance of X, we just need to add the variances of the Xi's. We have n Xi's, and each one of them has variance p, 1 minus p, and we're done. So this way we have calculated both the mean and the variance of the binomial random variable. It's interesting to look at this particular formula and see what it tells us. If you are to plot the variance of X as a function of p, it has this shape. And the maximum is here at 1 half. OK, p times 1 minus p is 0 when p is equal to 0, and when p equals to 1. It's a quadratic, so it must have this particular shape. So what does it tell us? If you think about variance as a measure of uncertainty, it tells you that coin flips are most uncertain when your coin is fair. When p is equal to 1 half, that's when you have the most randomness. And this is kind of intuitive. If, on the other hand, I tell you that the coin is extremely biased, p very close to 1, which means it almost always gives you heads, then that would be a case of low variance. There's low variability in the results. There's little uncertainty about what's going to happen. It's going to be mostly heads with some occasional tails. So p equals 1 half, fair coin, that's the coin which is the most uncertain of all coins in some sense. And it corresponds to the biggest variance. It corresponds to an X that has the widest distribution. Now that we're on a roll and we can calculate such hugely complicated sums in simple ways, let us try to push our luck and do a problem with this flavor, but a little harder than that. So you go to one of those old-fashioned cocktail parties, all males at least, who have those standard big hats, which look identical. They check them in when they walk in. And when they walk out, since they look pretty identical, they just pick a random hat and go home. So n people, they pick their hats completely at random, quote unquote, and then leave. And the question is to say something about the number of people who end up by accident or by luck to get back their own hat, the exact same hat that they checked in. OK, first, what do we mean completely at random? Completely at random, we basically mean that any permutation of the hats is equally likely. Any way of distributing those n hats to the n people, any particular way, is as likely as any other way. So there's complete symmetry between hats and people. So what we want to do is to calculate the expected value and the variance of this random variable X. Let's start with the expected value. Let's reuse the trick from the binomial case. So total number of hats picked, we're going to think of total number of hats picked as a sum of 0, 1 random variables. X1 tells us whether person 1 got their own hat back. If they did, we record a 1. X2, the same thing. By adding all X is how many 1's did we get, which counts how many people selected their own hats. So we broke down the random variable of interest, number of people who get their own hats back, as a sum of random variables. And these random variables, again, are easy to handle because they are binary. They only take two values. What's the probability that Xi is equal to 1? The i-th person, what's the probability that they get their own hat? There's n hats by symmetry. The chance that they ended up getting their own hat, as opposed to any one of the other n minus 1 hats, is going to be 1 over n. So what's the expected value of Xi? It's 1 times 1 over n. With probability 1 over n, you get your own hat. Or you get a value of 0 with probability 1 minus 1 over n, which is 1 over n. OK. All right. So we've got the expected values of the Xi's. And remember, what we want to do is to calculate the expected value of X by using this decomposition. OK. Are the random variables Xi independent of each other? OK. You can try to answer that question by writing down a joint PMF for the X's. But I'm sure that you will not succeed. But can you think intuitively? If I tell you information about some of the Xi's, does it give you information about the remaining ones? Yeah, if I tell you that out of 10 people, 9 of them got their own hat back, does that tell you something about the 10th person? Yes. If the 9 got their own hat, then the 10th must also have gotten their own hat back. So the first 9 random variables tell you something about the 10th one. And conveying information of this sort, that's the case of dependence. All right. So the random variables are not independent. Are we stuck? Can we still calculate the expected value of X? Yes, we can. And the reason we can is that expectations are linear. Expectation of a sum of random variables is the sum of the expectations. And that's always true. There's no independence assumption that's being used to apply that rule. So we have that the expected value of X is the sum of the expected value of the Xi's. And this is a property that's always true. You don't need independence. You don't care. So we're adding n terms, each one of which has expected value 1 over n. And the final answer is 1. So out of the 100 people who select hats at random, on the average, you expect only one of them to end up getting their own hat back. Very good. So since we are succeeding so far, let's try to see if we can succeed in calculating the variance as well. And of course we will. But it's going to be a little more complicated. The reason it's going to be a little more complicated is because the Xi's are not independent. So the variance of the sum is not the same as the sum of the variances. So it's not enough to find the variances of the Xi's. We'll have to do more work. And here's what's involved. Let's start with the general formula for the variance, which, as I mentioned before, is usually the simpler way to go about calculating variances. So we need to calculate the expected value of X squared, and subtract from it the expectation squared. Well, we already found the expected value of X. It's equal to 1, so 1 squared gives us just 1. So we're left with the task of calculating the expected value of X squared, the random variable X squared. OK, let's try to follow the same idea. Write this messy random variable X squared as a sum of hopefully simpler random variables. So X is the sum of the Xi's. So you square both sides of this, and then you expand the right-hand side. When you expand the right-hand side, you get the squares of the terms that appear here. And then you get all the cross terms. For every pair of i, j that are different, i different than j, you're going to have a cross term in the sum. So now, in order to calculate the expected value of X squared, what does our task reduce to? It reduces to calculating the expected value of this term, and calculating the expected value of that term. So let's do them one at a time. Expected value of Xi squared, what is it going to be? Same trick as before. Xi takes value 0 or 1, so Xi squared takes just the same values, 0 or 1. So that's the easy one. That's the same as expected value of Xi, which we already know to be 1 over n. OK. So this gives us a first contribution down here. The expected value of this term is going to be what? We have n terms in the summation, and each one of these terms has an expectation of 1 over n. So we did a piece of the puzzle. So now let's deal with the second piece of the puzzle. Let's find the expected value of Xi, Xj. Now by symmetry, the expected value of Xi, Xj is going to be the same, no matter what i and j you see. So let's just think about X1 and X2, and try to find the expected value of X1 and X2. X1 times X2 is a random variable. What values does it take? Only 0 or 1. Since X1 and X2 are 0 or 1, their product can only take the values of 0 or 1. So to find the probability distribution of this random variable, it's just sufficient to find the probability that it takes the value of 1. Now what does X1 times X2 equal to 1 mean? It means that X1 was 1 and X2 was 1. The only way that you can get the product of 1 is if both of them turned out to be 1's. So that's the same as saying persons 1 and 2 both picked their own hats. The probability that person 1 and person 2 both picked their own hats is the probability of two things happening, which is the product of the first thing happening times the conditional probability of the second given that the first happened. And in words, this is the probability that the first person picked their own hat times the probability that the second person picks their own hat given that the first person already picked their own. So what's the probability that the first person picks their own hat? We know that. It's 1 over n. Now how about the second person? If I tell you that one person has their own hat, and that person takes their hat and goes away, from the point of view of the second person, there's n minus 1 people left looking at n minus 1 hats, and they're getting just hats at random. What's the chance that I will get my own? It's 1 over n minus 1. So think of them as person 1 goes, picks a hat at random. It happens to be their own, and it leaves. You're left with n minus 1 people and their n minus 1 hats out there. Person 2 goes and picks a hat at random with probability 1 over n minus 1 is going to pick his own hat. So the expected value now of this random variable is, again, that same number because this is a 0, 1 random variable. So this is the same as expected value of Xi, Xj when i is different than j. So here, all that's left to do is to add the expectations of these terms. Each one of these terms has an expected value that's 1 over n times 1 over n minus 1. And how many terms do we have? How many of these are we adding up? It's n squared minus n. When you expand the quadratic, there's a total of n squared terms. Some are self terms, n of them. And the remaining number of terms is n squared minus n. So here we got n squared minus n terms. And so we need to multiply here with n squared minus n. And after you realize that this number here is 1, and you realize that this is the same as the denominator, you get the answer that the expected value of X squared equals 2. And then finally, going up to the top formula, we get expected value of X squared, which is 2, minus 1. And the variance is just equal to 1. So the variance of this random variable, number of people who get their own hats back, is also equal to 1, equal to the mean. Looks like magic. Why is this the case? Well, there's a deeper explanation why these two numbers should come out to be the same. But this is something that would probably have to wait a couple of chapters before we could actually explain it. And so I'll stop here.