 Το επόμενο πρόγραμμα είναι προσδοκημένο υπό δίκτυο Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει να προσφέρει υψηλές ειδικές παιδικοσύνης ειδικές παιδικοσύνες αγώνας ελεύθερα. Για να κάνετε μια δονάση ή να παρακολουθείτε προσδοκίες αυξαντικών από χιλιάδες μαθητές MIT, επισκεφτείτε MIT OpenCourseWare στηn ocw.mit.edu. Οπότε, θα επισκεφθείμε ό,τι έχουμε συζητήσει τελικά. Θα μιλήσουμε για μια κλασική εφαρμογή μαρκούφ κλίμακας για να αναλύσουμε πώς να εξετάσεις ένα πhone-σύστημα. Και τελικά, θα υπάρχουν δύο νέα πράγματα σήμερα. Θα δούμε πώς μπορούμε να κατασκευάσουμε συγκεκριμένες εξαιρετικές ποσότητες που έχουν να κάνουν με μαρκούφ κλίμακες. Ας ξεκινήσουμε. Είχαμε μαρκόφ κλίμακας. Ας κάνουμε την αποδοχή ότι η κλίμακα είναι κάπως ωραία. Και ωραία σημαίνει ότι έχουμε ίσως κάποια τραγωδικά κλίματα. Και τότε έχουμε μια μοναδική κλίμακα με εξετασμό εξετασμών. Αυτή είναι μια μοναδική εξετασμό στον σημασίο ότι από κάθε κλίμακα μπορείς να φτάσεις σε κάθε άλλο κλίμακα. Άρα, μια φορά που είσαι εδώ, θα διακυρνίζεσαι και θα συνεχίσεις να επισκεφθείς όλες αυτές τις κλίματα. Αυτές τις κλίματα εδώ είναι τραγωδικές. Η κατεύθυνση μπορεί να κινήσει εδώ, αλλά, επιτυχώς, μια από αυτές τις τραγωδίες θα συμβεί και θα τελειώσεις σε αυτήν την λάμπη. Ας κάνουμε την αποδοχή ότι αυτή η μοναδική εξετασμό δεν είναι περιοδική. Αυτές είναι οι καλύτερες είδες από τα Markov κλίματα, και είναι καλύτερες γιατί έχουν την εξετάσμηση. Η πιθανότητα ότι βρίσκεσαι σε κάποιο συγκεκριμένο κλίμακο j στην στιγμή n, όταν αυτή η στιγμή είναι πολύ μεγάλη, αυτή η πιθανότητα καθαρίζεται σε μια ασφάλεια κλίμακα που αποδοχάμε από πι-συμ-j. Και υπάρχουν δύο μέρη σε αυτή τη στήματια, η πιθανότητα που είναι j, και υπάρχουν δύο μέρη σε αυτή τη στήματια. Μία μέρη είναι ότι αυτό το σύστημα υπάρχει, οπότε η πιθανότητα κλίμακα j καθαρίζεται σε κάτι, και, παραπάνω, αυτή η πιθανότητα δεν είναι επηρεασμένη από i. Δεν σημαίνει πού ξεκίνησατε. Δεν σημαίνει πού ξεκίνησατε, η πιθανότητα κλίμακα j θα είναι η ίδια σε πολύ λόγο. Ίσως μια πιο εύκολη σημειοδοτία μπορεί να είναι αυτή, η πιθανότητα κλίμακα j, εξαρτάτα από η πρωτοβολή i, είναι εξαρτάτα από πιθανότητα j, σε λιμή. Αν δεν σας πω πού ξεκίνησατε, και αν δείτε την αδυναμωμένη πιθανότητα κλίμακα i, μπορείτε να επικοινωνήσετε πάνω από τις πρωτοβολές, χρησιμοποιώντας το θεωρήμα τοπίου εξετεινών, και θα λάβετε το ίδιο απαντάδες πι-j, σε λιμή. Αυτό σας λέει ότι η θεωρητική πιθανότητα δεδομένης κλίμακα, σε λιμή, είναι η ίδια σαν και η αδυναμωμένη πιθανότητα. Και αυτή είναι μια κατάσταση που αναγνωρίζουμε ως μια όπου έχουμε εξαρτάτα. Αυτό που μας λέει αυτό το αποτέλεσμα είναι ότι xn και xi είναι περίπου εξαρτάτα. Βγαίνουν εξαρτάτα σε λιμή, εάν n πέτυχε. Αυτό είναι το ποιο ο θεωρητικός πιθανότητας μας. Οι αρχαίες συνθήκες δεν σημαίνουν, οπότε το πιθανότητες σας σε κάποια μεγάλη στιγμή n δεν έχει τίποτα να κάνει, δεν είναι επηρεασμένο από το τι ήταν το πρωτοβουλίο σας. Και γνωρίζοντας ότι το πρωτοβουλίο δεν σας πει τίποτα για το πιθανότητες σας σε στιγμή n, λοιπόν, το πιθανότητες σε στιγμές, λοιπόν, δεν σημαίνει από το ποιο πρωτοβουλίο ξεκινήθηκε. Λοιπόν, αν η μαρκόφ κλίμακα είναι να λειτουργεί για πολύ καιρό και είμαστε ενδιαφέρον στην ερώτηση, ποιο είναι το πιθανότητες, τότε η απάντησή σας θα είναι, δεν ξέρω, είναι αρχαία, αλλά θα είναι ένα συγκεκριμένο j με αυτήν την συγκεκριμένη πιθανότητα. Λοιπόν, αυτές οι πιθανότητες στο στήριο πιθανότητες είναι ενδιαφέρουσιές για εμάς και αυτό αφορά τη ζήτηση πώς τα καταγραφούμε. Η τρόπο που τα καταγραφούμε είναι από το σωτήριο ενδιαφέρουσιών συστήματων, που ονομάζονται τα εξορδεμένα εξορδεμένα, μαζί με έναν επιπλέον εξορδεμένο, το εξορδεμένο εξορδεμένο που πρέπει να υπεροχθεί από τις πιθανότητες. Τα πιθανότητες πρέπει πάντα να αντιμετωπίσουν σε ένα. Συζητήσαμε για την εξορδεμένη αυτή την λεπτομέρεια τελικά. Η πιθανότητα να βρεις τον εαυτό σου στο στήριο J σε ένα συγκεκριμένο στιγμή είναι η τοταλή πιθανότητα της τελευταίας διαγραφής που με πάρει στο στήριο J. Η τελευταία διαγραφή με πάρει στο στήριο J σε διάφορες τρόπους. Μπορεί να είναι ότι την προηγούμενη φορά ήμουν σε ένα συγκεκριμένο στήριο K και έκανα μια διαγραφή από K στο J. Λοιπόν, αυτό το αριθμό εδώ το αντιμετωπίζουμε ως η συγκεκριμένη φορά με την οποία διαγραφές αυτής της συγκεκριμένης τύπης, K στο J, συμβαίνουν. Και με το να προσθέσουμε πάνω από όλες τις K, με θεωρούμε διαγραφές όλων των τύπων που μας οδηγούν μέσα στο στήριο J. Λοιπόν, η πιθανότητα να βρείς στο J είναι η τοταλή πιθανότητα να βρείς στο J. Αν είχαμε πολλές συγκεκριμένες κλάσσες? Λοιπόν, αν πάμε σε αυτό το φωτογραφικό και το αλλάξουμε σε αυτό. Λοιπόν, εδώ έχουμε μια δεύτερη συγκεκριμένη κλάσσα. Αν είσαι εδώ, δεν μπορείς να βρείς εκεί. Αν είσαι εδώ, δεν μπορείς να βρείς εκεί. Τι συμβαίνει με το μεγάλο τεχνικό? Λοιπόν, με το μεγάλο τεχνικό, αν αρχίσεις από εδώ, θα κάνεις μια μετατραπή επιτέλους, είτε με αυτόν τον τύπο και θα τελειώσεις εδώ, ή θα κάνεις μια μετατραπή με αυτόν τον τύπο και θα τελειώσεις εκεί. Αν τελειώσεις εδώ, τα δεξιά στατιστικά της σύγχρονης σου κλάσσας, δηλαδή τις προφανθήσεις των διαφορετικών κλάσσων, θα είναι οι προφανές προφανές αυτής της κλάσσας με το θέμα της εισολόγησης. Λοιπόν, πηγαίνεις πάνω και λύσεις αυτό το σύστημα εξετάσεις μόνο για αυτήν την κλάσσα, και αυτές θα είναι τις προφανές προφανές της σύγχρονης σου αν συμβαίνεις να τελειώσεις εδώ. Αν, στον άλλο, συμβαίνει ότι πήγες εκεί, δεξί από αυτό το πράγμα, τότε τι συμβαίνει στον διάστημα έχει να κάνει με μόνο αυτήν την κλάσσα που λειτουργεί μόνο από εκείνη, οπότε βρεις τις προφανές προφανές μέσα σε αυτήν την εισόλογη. Λοιπόν, λύσεις το σύστημα εξετάσεις μόνο για αυτήν την κλάσσα και για αυτήν την κλάσσα μόνο. Αν συμβαίνεις να ξεκινήσεις μέσα εδώ, τότε οι προφανές προφανές εξετάσεις για αυτήν την εισόλογη θα εφαρμόζονται. Τώρα, φυσικά, αυτό απαιτεί το ερώτημα, αν ξεκινήσω εδώ, πώς ξέρω αν θα έρθω εδώ ή εκεί. Βέβαια, δεν ξέρεις, είναι αρκετό. Μπορεί να γίνει ότι έρχεσαι εδώ, μπορεί να γίνει ότι έρχεσαι εκεί, οπότε θα είμαστε ενδιαφέροντες στον πραγματικό ότι, επιτυχώς, θα τελειώσεις εδώ, αντί την προφανότητα ότι, επιτυχώς, θα τελειώσεις εκεί. Αυτό είναι κάτι που θα κάνουμε προς την τελική διάρκεια αυτής της διδασκαλίας. Βεβαίως, λοιπόν, ως προσοχή, για να δούμε πώς εξετάσουμε αυτές τις προφανές εισόλες, ας δούμε το παράδειγμα μας που είναι γνωστό. Αυτή είναι μια δύο-στάδια κλίμακα. Την τελευταία φορά, έγραψαμε τα εξετάσματα αλληλεγγύης για αυτήν την κλίμακα, και βρήκαμε ότι οι προφανές εισόλες θα είναι 2 7 και 5 7, αντιμετωπίζοντας. Ας προσπαθήσουμε να καταγραφήσουμε κάποιες ποσότητες. Αντιμετωπίζουμε ότι ξεκινάτε στο στάδιο 1 και θέλετε να καταγραφήσετε αυτήν την συγκεκριμένη προφανότητα. Οπότε, εφόσον αποδεχόμαστε ότι ξεκινάμε στο στάδιο 1, βασικά εδώ, εμείς προσφέρουμε την αρχή να είναι εξατμιστή σε 1. Τώρα, η προφανή πιθανότητα που συμβαίνουν δύο πράγματα είναι η πιθανότητα ότι το πρώτο πράγμα συμβαίνει, αλλά ζούμε σε έναν κόσμο όπου είπαμε ότι το πρώτο στάδιο, το αρχικό στάδιο ήταν 1. Και μετά, διότι αυτό συμβαίνει, η πιθανότητα ότι το δεύτερο πράγμα συμβαίνει. Αλλά, ξανά, μιλάμε για προφανές πιθανότητες, διότι το αρχικό στάδιο ήταν 1. Λοιπόν, τι είναι αυτή η ποσότητα? Αυτή είναι η πιθανότητα της μετατραπτώσεις από στάδιο 1 στο στάδιο 1. Λοιπόν, είναι P11. Πώς αφορά τη δεύτερη πιθανότητα? Λοιπόν, διότι άρχισατε στο 1 και την επόμενη φορά ήσασταν στο 1, ποια είναι η πιθανότητα ότι στο 100 πρώτο στάδιο ήσασταν στο 1? Τώρα, εξαιτίας της πραγματικότητας Markov, αν σας πω ότι σ' αυτό το στάδιο ήσασταν στο 1, δεν αφορά πώς ήσασταν εκεί. Λοιπόν, αυτή η μέρα της προφανωλήσεως δεν αφορά. Και αυτό που έχουμε είναι η 99-ή στήλη προφανωλήσεως από στάδιο 1 στο στάδιο 1. Λοιπόν, η προφανωλήσεως που έρθεις στο 1, και μετά 99 βήματα βρίσκεσαι ξανά στο 1, είναι η προφανωλήσεως ότι η πρώτη στήλη πάρει το 1, εξατμώς η προφανωλήσεως ότι μετά τις 99 επόμενες στήλες, ξεκινώντας από 1 μετά 99 βήματα, τώρα ξανά βρίσκεσαι στο στάδιο 1. Τώρα, 99 είναι, μπορεί, ένα μεγάλο τόπο. Και οπότε, προσφέρουμε αυτή την ποσότητα χρησιμοποιώντας την αρνητική προφανωλή σε στάδιο 1. Και αυτό μας δίνει μια προσφέρωση για αυτή την συγκεκριμένη εξηγή. Μπορούμε να κάνουμε το ίδιο για να καταφέρουμε κάτι του ίδιου είδους. Λοιπόν, ξεκινάς στο στάδιο 1. Ποιο είναι η προφανωλή σε το 100 βήματα μετά, είσαι ξανά στο στάδιο 1. Αυτό θα είναι 100, δεν π. R. R11, η 100 βήματα μεταφράσης προφανωλή, η οποία ξεκινά από 1, και το πάντα πάνε στο 1. Και μετά από το 100, τι είναι η προφανωλή που, την επόμενη φορά, θα βρείς στο στάδιο 2. Αυτό θα είναι η προφανωλή P12. Και, σχεδόν, εφόσον 100 είναι ένα μεγάλο τόπο, αυτό είναι σχεδόν π. π. 1 x P12. OK. Λοιπόν, αυτό είναι πώς μπορούμε να χρησιμοποιήσουμε προφανωλές στήλης για να κάνουμε προφανωλή. Ή μπορείτε, για παράδειγμα, αν συνεχίσετε να κάνετε παραδείγματα τέτοιας, μπορείτε να ζητήσετε ποιο είναι η προφανωλή που x στο στιγμό 100 είναι 1. Και επίσης, η προφανωλή x στο στιγμό 200 είναι εξατμώς 1. Λοιπόν, αυτό θα είναι η προφανωλή διαχωρισμού από 1 στο 1, σε 100 βήματα. Και μετά από τα επόμενα 100 βήματα, από 1, θα βρείτε ξανά στο 1. Και αυτό θα είναι εξατμώς πι 1 x πι 1. Λοιπόν, προφανωλούμε τα προφανωλή διαχωρισμού με τα προφανωλή διαχωρισμού στο στιγμό, όταν το τρόπο n που είναι εμφανιστεί εδώ είναι μεγάλο. Τώρα, είπα ότι 99 ή 100 είναι μεγάλο. Πώς γνωρίζουμε ότι είναι μεγάλο αρκετά, ώστε η λιμή να έχει αποτελέσμα, και ότι η προστασία είναι καλή. Αυτό έχει κάτι να κάνει με τη χρονοσύνη της μαρκής μας. Και με χρονοσύνη, εννοώ πόσο πολύ χρόνο πρέπει για να παρακαλώ το αρχικό στήμα. Πόσο πολύ χρόνο πρέπει για να υπάρχει αρκετή αρκετότητα, ώστε τα πράγματα να μιλήσουν, και δεν αφορά όπου ξεκινάτε. Αν δείτε στην κλίμακα, η λιμή χρειάζεται, ας πούμε, 5 προσπάθειες για να κάνετε μια μεταρρυθμία τέτοιας. Η λιμή χρειάζεται, σε αρκετό, 2 προσπάθειες για να συμμετέχει μια μεταρρυθμία τέτοιας. Άρα κάθε 10 φορές ή λίγο, υπάρχει λίγο αρκετότητα, πάνω από 100 φορές, υπάρχει πολύ αρκετότητα. Άρα εξετάζετε ότι η αρχική στήματη θα έχει παρακολουθεί και δεν αφορά. Υπάρχει αρκετό μιξεύγιο και αρκετότητα που συμβαίνει πάνω από 100 φορές. Και οπότε αυτή η προσπαθία είναι καλή. Στην άλλη, αν οι αριθμούς ήταν διαφορετικοί, η ιστορία θα ήταν διαφορετική. Αντιμετωπίζετε ότι αυτό το αριθμό είναι 0.999, και αυτό το αριθμό είναι κάτι σαν 0.998, ώστε αυτό το αριθμό να γίνει 0.002, και αυτό το αριθμό να γίνει 0.001. Αντιμετωπίζετε ότι οι αριθμούς ήταν αυτός ο τρόπος. Πόσο λόγο χρειάζεται να ξεχάσω το αρχικό στήμα? Αν ξεκινάω εδώ, υπάρχει μια πιθανότητα 1 στο 1,000, η οποία θα είναι εκείνη την εποχή. Άρα, το αριθμό θα χρειάζεται περίπου 1,000 φορές απλά για να αφήσω αυτό το στήμα. Άρα, πάνω από περίπου 1,000 φορές, το αρχικό στήμα μου πραγματικά έχει σημασία. Αν σας πω ότι ξεκινήσατε εδώ, είστε αρκετά σίγουροι ότι, ας πούμε, πάνω από τα επόμενα 100 φορές, θα είστε ακόμα εδώ. Λοιπόν, το αρχικό στήμα έχει μεγάλο επίπτωμα. Σε αυτό το στήμα, λέμε ότι η κλίμακα αυτού του έχει μια πολύ χαμηλότερη σχέση χρόνου. Χρειάζεται πολύ λιγότερο χρόνο για να μιλάτε. Χρειάζεται πολύ λιγότερο χρόνο για να ξεχάσετε το αρχικό στήμα. Αυτό σημαίνει ότι δεν μπορούμε να κάνουμε αυτόν τον σύγχρονο αν το ποσό βήματα είναι μόνο 99. Εδώ θα χρειαζόμαστε N να είναι τόσο μεγάλο, ας πούμε, 10,000 ή λοιπόν, πριν μπορούμε να ξεκινήσουμε να χρησιμοποιούμε την σύγχρονη. Λοιπόν, όταν χρησιμοποιούμε αυτή την σύγχρονη, πρέπει να έχουμε κάποιο σημασίο για το πόσο γρήγορα κινδύει το στήμα και να το υποστηρίζουμε. Λοιπόν, υπάρχει μια ολόκληρη σύγχρονη που αντιμετωπίζει ή καταφέρνει πόσο γρήγορα διαφορετικά μαρκοφύλλακια μπλουδάνουν, και αυτή είναι η ερώτηση ποιος μπορεί να χρησιμοποιήσεις αυτές τις σύγχρονες αριθμοί. Λοιπόν, τώρα ας πάμε λίγο κοντά στο πραγματικό κόσμο. Θα μιλήσουμε για ένα διάσημο πρόβλημα που ήταν θεωρηθεί, διερευνει και λύθηκε από έναν Δανεισμό εγχειριαστή με το όνομα του Erlang. Αυτός είναι ο ίδιος άνθρωπος, το οποίο όνομα δίνεται στην ερλανγκ διερήνωση που είδαμε στο κατάσταση των πρόσωπων πρόσωπων. Λοιπόν, αυτό ήταν πάνω από 100 χρόνια πριν, όταν οι τηλέφωνοι είχαν ξεκινήσει να υπάρχουν, και ήταν προσπαθώντας να καταφέρει πώς να κατασκευάσει, τι θα έπρεπε να κάνει για να κατασκευάσει ένα τηλέφωνο σύστημα, πόσες στρατιώτες πρέπει να κατασκευάσεις για μια κοινότητα για να μπορέσει να κοινωνικοποιήσει με το ξύλο. Λοιπόν, εδώ είναι η ιστορία. Έχετε ένα χωριό, και αυτό το χωριό έχει μια συγκεκριμένη ποπιλία. Και θέλετε να ετοιμάσετε τηλέφωνες. Λοιπόν, θέλετε να ετοιμάσετε ένα τρόπο τηλέφωνων. Ας πούμε ότι αυτό το τρόμο είναι B, στον ξύλο. Και πώς θέλετε να το κάνετε αυτό? Λοιπόν, θέλετε B να είναι κάπως μικρό. Δεν θέλετε να ετοιμάσετε τόσο πολλά στρατιώτες, γιατί είναι αρκετά δέσμευση. Στην άλλη πλευρά, θέλετε να έχετε αρκετά στρατιώτες, ώστε αν ένα αρκετό σωστό τρόμο ανθρώπους παίξει τηλέφωνες συνεχώς, θα πάντα θα πάντει μια στρατιώτη, και θα μπορούν να μιλήσουν. Λοιπόν, αν B είναι 10, και 12 άνθρωποι θέλουν να μιλήσουν την ίδια στιγμή, τότε 2 από αυτές οι άνθρωποι θα παίξουν μια στρατιώτη σύνδεση, και αυτό δεν είναι κάτι που θέλουμε. Θα θέλαμε B να είναι αρκετά μεγάλο, ώστε να υπάρχει μια αρκετή δυνατότητα, ότι υπάρχει πάντα σίγουρο, ότι υπό διευθυντικές κατάστασεις, κανένας δεν θα παίξει μια στρατιώτη σύνδεση. Λοιπόν, πώς θα κατασκευάσουμε μια στιγμή σαν αυτή? Λοιπόν, για να εγκατασκευάσουμε μια στρατιώτη, χρειαζόμαστε 2 κομμάτια. Η πρώτη είναι να περιγράψουμε πώς ξεκινάνται οι τηλέφωνικές συνέχεσεις, και μόλις ξεκινά μια τηλέφωνική συνέχεση, πόσο λίγο χρειάζεται μέχρι να τελειώσει η τηλέφωνική συνέχεση. Λοιπόν, θα κάνουμε τις απλύτερες υποθέσεις που μπορούν. Ας υποθέσουμε ότι οι τηλέφωνικές συνέχεσεις ορίζονται ως ένα πρόοδος Poisson. Δηλαδή, από αυτήν την ποπιλία, οι άνθρωποι δεν συγκεντρωθούν πραγματικά. Σε τελείως αρκετές φορές, διαφορετικοί άνθρωποι αποφασίζουν να πάρουν το τηλέφωνο. Δεν υπάρχουν εξασφάλειες μεταξύ διαφορετικών ανθρώπων. Δεν υπάρχει τίποτα σχετικό για διαφορετικές φορές. Διαφορετικές φορές είναι αξιωματικές. Οπότε, ένα πρόοδος Poisson είναι μια αξιωματική τύπωση που μπορεί να σχεδιαστούμε αυτήν την κατάσταση. Και θα είναι ένα πρόοδος Poisson με κάποια λαμβάνια ρατή. Η λαμβάνια ρατή θα είναι εύκολη να καταγραφείς σε εργασία. Θα παρατηρήσεις τι συμβαίνει σε αυτό το χωριό, μετά από μερικές ημέρες, και θα καταφέρεις τι είναι η ρατή με την οποία οι άνθρωποι προσπαθούν να προσφέρουν τηλέφωνικές συνέχεσεις. Σχετικά με τις συνέχεσεις, θα καταφέρουμε ότι η διάρκεια μιας συνέχεσης είναι μια δίκαιη διαφορά που έχει μια εξωτερική διαδίκτυα με μια συγκεκριμένη παράμετρα μη. Λοιπόν, 1 πάνω από μη είναι η διάρκεια μεγάλης διάρκειας μιας συνέχεσης. Η διάρκεια μεγάλης διάρκειας, ξανά, είναι εύκολη να καταγραφείς. Απλά παρατηρήσεις τι συμβαίνει, δείτε στην μείωση πόσο πολύ αυτές οι συνέχεσεις είναι. Είναι η αξιολογική υποθέση μια καλή υποθέση? Λοιπόν, σημαίνει ότι η μεγαλύτερη ποσότητα συνέχεσες θα είναι λίγο μικρό, αλλά θα υπάρχει μια πλήρη από συνέχεσες που θα είναι μεγαλύτερα και τότε μια πολύ μικρή πλήρη που θα είναι ακόμα μεγαλύτερα. Λοιπόν, ακούγεται αρνητικό. Δεν είναι ακριβώς πραγματικό, δηλαδή, συνέχεσες που διατηρούν 15 δευτερόλεπτα δεν είναι τέτοια κοινή. Οπότε, ούτε τίποτα συμβαίνει, ούτε πρέπει να το πούμε μερικές φράσεις και τέτοια. Επίσης, πριν από τις ημέρες όταν άνθρωποι έπαιζαν να συνδεθούν στο Ινternet χρησιμοποιώντας Dial-up modems, αυτή η υποθέση ήταν ολόκληρη καταστραφή, γιατί οι άνθρωποι θα διατηρούν και τότε θα κρατήσουν το σχηματικό τους για μερικές ώρες, αν η συνέχεση ήταν ελεύθερη. Οπότε, σε αυτές τις φορές, η αριθμητική υποθέση για τη συνέχεση των φωνών ήταν ολόκληρη καταστραφή. Αλλά, αφού αφήσουμε αυτή τη σημερινή ειδοποίηση, είναι μια λειτουργική υποθέση να ξεκινήσουμε με αυτό το πρόβλημα. Βεβαίως, τώρα που έχουμε αυτές τις υποθέσεις, προσπαθήσουμε να φτιάξουμε ένα μοντέλο, και θα ετοιμάσουμε ένα μοντέλο Markov-process. Τώρα, το Process Φεσσάρει σε χρόνο συνεχής, και οι δραστηριότητες, να είναι εξωτερικές δραστηριότητες, είναι επίσης συνεχές δραστηριότητες. Λοιπόν, φαίνεται ότι είμαστε σε έναν κοινωνικό κόσμο τεχνικής χρονίας. Αλλά, έχουμε μόνο διδάσκει Markov-chain για το συγκεκριμένο πράγμα της χρονίας. Τι θα κάνουμε? Μπορούμε να ανεξεργαστούμε τη θεωρία της συνεχής χρονίας Markov-chain, η οποία είναι πιθανό, αλλά δεν θα το κάνουμε σε αυτή τη σχέση. Ή μπορούμε να διδάσκουμε τη χρονιά και να δουλέψουμε με ένα μοντέλο διδασκομενό χρονίο. Λοιπόν, θα διδάσκουμε τη χρονιά με τον γνωστό τρόπο, τον τρόπο που το έκαναμε όταν ξεκίνησαμε το πρόοδο του Poisson. Θα πάρουμε την αξία της χρονίας και θα την διαπίσω σε μικρές, διδασκομενές μινί-σλότες, όπου κάθε μινί-σλότ έχει μια διάρκεια δελτή. Λοιπόν, αυτή η δελτή πρέπει να είναι ένα πολύ σημαντικό πρόβλημα. Ποιο είναι το κόσμο του σύστημαού? Λοιπόν, αν δείτε τη κατάσταση στο σύστημα, κάποιος στιγμός, και σας ρωτώ, τι συμβαίνει σήμερα, τι πληροφορίες θα μου πείτε? Λοιπόν, θα μου πείτε ότι σήμερα, από αυτές τις καπιταλίες B, 10 από αυτές είναι κουρασμένες ή 12 από αυτές είναι κουρασμένες. Αυτό περιγράφει το κόσμο του σύστημαου. Αυτό πεινάει μου τι συμβαίνει σε αυτό το σημείο. Αυτό περιγράφει τις αριθμές από 0 στο B. 0 συμβαίνει σε ένα κόσμο στο οποίο όλες οι τηλέφωνες είναι ελεύθερες, κανένας δεν μιλεί. B συμβαίνει σε ένα κόσμο όπου όλες οι τηλέφωνες είναι κουρασμένες. Και τότε έχετε κόσμα μεταξύ. Και τώρα, ας δούμε τις προσδιορίες της μετατραπής. Αντιμετωπίστε ότι σήμερα έχουμε ει-1 τελειών που είναι κουρασμένες. Ή, ίσως, ας δούμε εδώ. Αντιμετωπίστε ότι υπάρχουν ει-διαφάνειες που είναι κουρασμένες. Τι μπορεί να συμβεί το επόμενο στιγμό? Τι μπορεί να συμβεί είναι ότι μια νέα τηλέφωνη αριθμή γίνεται, στο οποίο τελειώνει η κίνηση μου από 1, ή μια αρχική αριθμή τελειώνει, στο οποίο η κίνηση μου πέτρεται από 1, ή κανένας από τους 2 συμβαίνει, στο οποίο παραμείνω στο ίδιο κίνημα. Είναι επίσης πιθανό να συμβεί μια νέα τηλέφωνη αριθμή συνεχώς, αλλά όταν παίρνεις τα στάδια πολύ μικρά, θα έχει μια αρνητική πιθανότητα σύνολος δελτών στρατιώτων, οπότε αφήνουμε αυτό. Ποιό είναι η πιθανότητα μιας ανάπτυξης? Αυτή είναι η πιθανότητα ότι η διαδικασία περνάει μια αριθμή κατά μινι-σλάτος της διάρκειας δελτών. Σύμφωνα με την κατεστημία της διαδικασίας, η πιθανότητα που συμβαίνει είναι μόνο λαμδα δελτών. Έτσι, κάθε μια από αυτές τις προχωρήσεις έχει την ίδια πιθανότητα λαμδα δελτών. Έτσι, έχετε λαμδα δελτών σε κάθε μέρη αυτής της διαδικασίας. Πώς αφορά τώρα τις τελειώσεις της τηλέφωνης αριθμής? Αν είχατε μια μόνη τηλέφωνη που ήταν ακτιβή, εάν ήσασταν εδώ, ποιό είναι η πιθανότητα ότι η τηλέφωνη αριθμή τελειώσει? Αυτό είναι το ποιό είναι η πιθανότητα που συμβαίνει με την πιθανότητα μμ. Και πριν, έχουμε συζητήσει ότι μια αριθμή τελειώση μπορεί να είναι θεωρία ως η πρώτη φορά στον πρόοδο του Poisson. Έτσι, η πιθανότητα που συμβαίνει με μια τελειώση αριθμής δελτών είναι μόνο μμ. Εκεί έχουμε πόλεις iPhone που είναι ακτιβές. Κάθε μια από αυτές έχει μια πιθανότητα ως μμ. Αλλά, συλλογικά, η πιθανότητα που μια από αυτές τελειώσει γίνεται μμ. Αυτό είναι γιατί εσείς λάβετε μια πιθανότητα ως τελειώση από κάθε μια πιθανότητα γιατί αφορά η πιθανότητα ότι δύο φωνές τελειώνουν την ίδια στιγμή. Αυτή είναι η κατάλληλη αριθμή. Όταν έχετε φωνές iPhone που συμμετεχνούν και περιμένουν μια από αυτές να τελειώσει, είναι σαν να έχετε εξωτερικές πρόοδες που τελειώνουν παράλληλα πρόοδες. Όταν βάζετε όλες αυτές τις πρόοδες μαζί, είναι σαν να έχετε μια πρόοδα Poisson με τελειωμένη αισθήση i times μμ. Άρα i times μμ δελτα είναι η πιθανότητα ότι συμβαίνει κάτι σε τέτοιες φωνές τελειώσεις. Σε οποιοδήποτε πράγμα, αυτή είναι η αριθμή τελειώσεις για τα πιθανότητα τελειώσεις. Τώρα που έχουμε αυτό, μπορούμε να αναλύσουμε αυτή την κλίμακα. Αυτή έχει τη φορματία πρόοδου που συζητήσαμε προς τέλος της τελευταίας διδασκάδας. Και για τα πιθανότητα τελειώσεις είναι εύκολο να γράψουμε να βρούμε τις πιθανότητες τελειώσεις. Αντί να γράψουμε τις εξετάσεις με την κοινωνική τεχνική, πιστεύουμε, σε τερμός της κρατικότητας ή των πρόοδων, αντιμετωπίζοντας τι συμβαίνει σε ένα συγκεκριμένο κομμάτι σε αυτό το πλαίσιο. Το ποσό πρόοδων από εδώ εδώ, πρέπει να είναι σχεδόν εξασφαλής με το ποσό πρόοδων από εδώ εκεί, γιατί ό,τι έρχεται, πρέπει να έρχεται και τότε έρχεται, και τέτοια. Οπότε, η συμφωνία με την οποία πρόοδες αυτού του είδους είναι παρατηριασμένα, πρέπει να είναι η ίδια σύμφωνα με τις προσοχές των προσοχών αυτών. Ποιο είναι η συμφωνία με την πόσο συμφωνίες αυτών συμβαίνουν. Και με συμφωνία, ποιο είναι η συμφωνία με αυτήν την σύμφωνα. Για να συμφωνήσουμε με αυτήν την συμφωνία, πρέπει να είμαστε στο στάδιο i-1, που συμβαίνει τόσο πολύ με την ώρα, και τότε η πιθανότητα λ δ ότι η συμφωνία είναι αυτή. Οπότε, η συμφωνία με την οποία αυτή η συμφωνία είναι παρατηριασμένη, είναι λ δ π i-1. Αυτή είναι η πρακτική των στήριων με τα οποία μια συμφωνία από αυτήν τη στιγμή σε αυτήν τη στιγμή είναι παρατηριασμένη. Αυτό πρέπει να είναι το ίδιο σαν τη συμφωνία με την οποία συμφωνίες τέτοιων τέτοιων είναι παρατηριασμένες. Και αυτή η συμφωνία θα είναι i-μπ δ λ δ π i. Και τότε εξαρτάμε τις δελτές και παραμείνουμε με λ δ π i-1. Αν γνωρίσαμε πι 0, μπορούμε να χρησιμοποιήσουμε αυτή την εξαρτάσταση για να αποδεχτούμε πι 1. Μετά από το γνωστό πι 1, μπορούμε να χρησιμοποιήσουμε αυτή την εξαρτάσταση για να αποδεχτούμε πι 2. Και τέτοια. Και η γενική ορισμό που έρχεται από αυτό, δεν θα κάνω την αλγέβη, είναι μια εύκολη εξαρτάσταση. Βλέπετε πως πι i, η διευθυντική πραγματικότητα του στήριου i, αντιμετωπίζει το πι 0, από το οποίο ξεκίνησαμε. Τώρα, τι είναι πι 0? Δεν ξέρουμε ακόμα, αλλά μπορούμε να το βρούμε χρησιμοποιώντας την εξαρτάσταση. Η ορισμό των πι i- πρέπει να είναι εξαρτάσταση 1. Οπότε η ορισμό των όλων αυτών των αριθμών πρέπει να είναι εξαρτάσταση 1. Και η μόνη τρόπο που μπορεί να συμβεί αυτό είναι από το γνωστό πι 0 να είναι εξαρτάσταση εκείνου τύπου. Αν σας πω το αριθμό των B, μπορείτε να ετοιμάσετε αυτήν την κλίμακα. Μπορείτε να καθορίσετε πι 0, και μετά μπορείτε να καθορίσετε πι i. Και τότε ξέρετε ποια εξαρτάσταση, ξέρετε τις αριθμότητες εξαρτάστασης αυτής της κλίμακας. Μπορείτε να απαντήσετε τη ερώτηση αν βγάλω στον τελευταίο τρόπο, πόσο σχεδόν θα βρω το στήριο να είναι εδώ, ή το στήριο να είναι εκεί. Οι αριθμότητες εξαρτάστασης είναι αριθμότητες, αλλά τα επίσης τα εξαρτάζουμε ως φροντίδια. Λοιπόν, μια φορά που βρω πι i, μου λέει επίσης ποια εξαρτάσταση της στιγμής είναι η στιγμή η οποία είναι εξαρτάσταση εξαρτάσταση εξ. Και μπορείτε να απαντήσετε αυτήν την ερώτηση για κάθε εξ αρθάτου. Τώρα, γιατί κάναμε αυτό το δραστηριόμενο? Είμαστε ενδιαφέρον ότι η συστημή είναι κουζίνη. Αυτή η νέα ερώτηση θα βρει το σύστημα σε ένα αρχαίο κόσμο. Αυτό το αρχαίο κόσμο είναι οδηγό σε στήριο από τις εξ αρθάτου, τα πι i. Και η ευθύνη που βρεις η συστημή να είναι κουζίνη είναι η ευθύνη ότι όταν βγεις, το στήριο συμβαίνει να είναι αυτό το συγκεκριμένο τόπο B. Λοιπόν, πι sub B είναι η ευθύνη να είσαι κουζίνη. Και αυτή είναι η ευθύνη ότι θέλεις να είσαι μικρό σε ένα καλό συστηματισμένο κόσμο. Λοιπόν, ρωτάς τη ερώτηση πώς θα πρέπει, δεδομένου τη λ και μ, η ερώτηση μου είναι να αποφασίσω B, το αριθμό των στήριων ώστε αυτό το αριθμό να είναι μικρό. Μπορούμε να φτιάξουμε ένα καλό αριθμό για B παράγοντας μια πίσω-από-το-σύμβολο καλύπτωση. Ας υποστηρίξουμε ότι λ είναι 30 και μ είναι 1 3. Λοιπόν, πιστεύω ότι ας αποφασίσουμε αυτές τις ρότες να είναι στήριοι π.μ. και αυτό το μ, ξανά, είναι ένα αριθμό π.μ. ξανά, τα στήρια μ θα είναι στήριοι π.μ. Λοιπόν, εφόσον η ερώτηση μας είναι στήριοι, η μεσαία διάσταση στήριων είναι 1 π.μ. Λοιπόν, ένα τυπικό στήριο, ή, σε μεσαίο, μια ρωτησία πλήρωνε για 3 λεπτά. Και λοιπόν, πληρώνεις το 30 π.μ. Κάθε ρώτηση πλήρωνε για 3 λεπτά σε μεσαίο. Λοιπόν, σε μεσαίο, αν B ήταν υποστηρίχη, όταν κάθε ρώτηση αποπούθηκε, ποιες ρώτειες θα ήταν ζητές σε μεσαίο. Λοιπόν, πληρώνεις το 30 π.μ. Αν μια ρώτηση lasted exactly one minute, then at any time you would have 30 calls being active. Now a call lasts on the average for three minutes. So during each minute, you generate 90 minutes of talking time. So by thinking in terms of averages, you would expect that at any time there would be about 90 calls that are active. And if 90 calls are active on the average, you could say, OK, I'm going to set up my capital B to be 90. But that's not very good, because if the average number of phone calls that want to happen is 90, sometimes you're going to have 85, sometimes you will have 95. And to be sure that the phone calls will go through, you probably want to choose your capital B to be a number a little larger than 90. How much larger than 90? Well, this is a question that you can answer numerically. So you go through the following procedure. I try different values of capital B. For any given value of capital B, I do this numerical calculation. I find the probability that the system is busy. And then I ask, what's the value of B that makes my probability of being busy to be, let's say, roughly 1%. And if you do that calculation with the parameters that I gave you, you find that B would be something like 106. So with the parameters I gave you, where you have, on the average, 90 phone calls being active, you actually need some margin to protect against statistical fluctuations if suddenly, by chance, more people want to talk. And if you want to have a good guarantee that an incoming person will have a very small probability of finding a busy system, then you will need about 106 phone lines. So that's the calculation and the argument that Erlang went through a long time ago. It's actually interesting that Erlang did this calculation before Markov chains were invented. So Markov's work and the beginning of work on Markov chains happens about 10, 15 years after Erlang. So obviously, he didn't call that a Markov chain. But it was something that he could study from first principles. So this is a pretty useful thing. These probabilities that come out of that model, at least in the old days, they would all be very well tabulated in handbooks that every decent phone company engineer would sort of have with them. So this is about as practical as it gets. It's one of the standard real world applications of Markov chains. So now to close our subject, we're going to consider a couple of new skills and see how we can calculate a few additional interesting quantities that have to do with the Markov chain. So the problem we're going to deal with here is the one I hinted at when I was talking about this picture. You start at the transient state. You're going to eventually end up here or there. We want to find the probabilities of one option of the two happening or the other happening. So in this picture, we have a class of states that are transient. And these are transient because you're going to move around those states, but there's a transition that you can make, and you go to a state from which you cannot escape afterwards. Are you going to end up here or are you going to end up there? You don't know. It's random. Let's try to calculate the probability that you end up at state 4. Now, the probability that you end up at state 4 will depend on where you start. Because if you start here, you probably have more chances of getting to 4 because you get that chance immediately. Whereas if you start here, there's more chances that you're going to escape that way because it kind of takes you time to get there. It's more likely that you exit right away. So the probability of exiting and ending up at state 4 will depend on the initial state. That's why when we talk about the absorption probability, we include an index, i, that tells us what the initial state is. And we want to find this absorption probability, the probability that we end up here, for the different initial states. Now, for some initial states, this is very easy to answer. If you start at state 4, what's the probability that eventually you end up in this part of the chain? It's 1. You're certain to be there. That's where you started. If you start at state 5, what's the probability that you end up eventually at state 4? This probability is 0. There's no way to get there. Now, how about if you start at a state like state 2? If you start at state 2, then there's a few different things that can happen. Either you end up at state 4 right away, and this happens with probability 0.2. Or you end up at state 1, and this happens with probability 0.6. So if you end up at state 4, you are done. We are there. If you end up at state 1, then what? Starting from state 1, there's two possibilities. Either eventually you're going to end up at state 4, or eventually you're going to end up at state 5. What's the probability of this happening? We don't know what it is, but it's what we defined to be a1. This is the probability. a1 is the probability that eventually you settle in state 4, given that the initial state was 1. So this probability is 1. So our event of interest can happen in two ways. Either I go there directly, or I go here with probability 0.6, and given that I go there, eventually I end up at state 4, which happens with probability a1. So the total probability of ending up at state 4 is going to be the sum of the probabilities of the different ways that this event can happen. So our equation in this case is going to be that a2 is going to be 0.2. That's the probability of going there directly. Plus, with probability 0.8, I end up at state 1. And then from state 1, I will end up at state 4 with probability a1. So this is one particular equation that we got for what happens if we start from this state. We can do a similar argument starting from any other state. Starting from state i, the probability that eventually I end up at state 4 is, we consider the different possible scenarios of where do I go next, which is my state j, with probability pij next time I go to j. And given that I started at j, this is the probability that I end up at state 4. So this equation that we have here is just an abstract version in symbols of what we wrote down for the particular case where the initial state was 2. So you write down an equation of this type for every state inside here. You'll have a separate equation for a1, a2, and a3. And that's going to be a system of three equations with three unknowns, the a's inside the transient states. So you can solve that 3 by 3 system of equations. Fortunately, it turns out to have a unique solution. And so once you solve it, you have found the probabilities of absorption at the probability that eventually you get absorbed at state 4. Now in the picture that we had here, this was a single state, and that one was a single state. How do things change if our recurrent or trapping sets consist of multiple states? Well, it doesn't really matter that we have multiple states. All that matters is that this is one lump. And once we get there, we are stuck in there. So if the picture was, let's say, like this, 0.1 and 0.2, that basically means that whenever you are at that state, there's a total probability of 0.3 of ending in that lump and getting stuck inside that lump. So you would take that picture and change it and make it instead a total probability of 0.3 of ending somewhere inside that lump. And similarly, you take this lump and you view it as just one entity, and from any state you record the total probability that given that I'm here, I end up in that entity. So basically, if the only thing you care is the probability that you're going to end up in this lump, you can replace that lump with a single state, view it as a single state, and calculate probabilities using this formula. All right. So now we know where the chain is going to get to. At least we know probabilistically. We know with what probability it's going to go here, and that also tells us the probability that eventually it's going to get there. Other question. How long is it going to take until we get to either this state or that state? We can call that event absorption, meaning that the state got somewhere into a recurrent class from which it cannot get out. OK. Let's deal with that question for the case where we have only one absorbing state. So here, our Markov chain is a little simpler than the one in the previous slide. We've got our transient states. We've got our recurrent state. And once you get into the recurrent state, you just stay there. So here we're certain that no matter where we start, we're going to end up here. How long is it going to take? Well, we don't know. It's a random variable. The expected value of that random variable, let's call it mu. But how long it takes to get there certainly depends on where we start. So let's put in our notation again this index i that indicates where we started from. And now the argument is going to be of the same type as the one we used before. We can think in terms of a tree once more that considers all the possible options. So suppose that you start at state 1. Starting from state 1, the expected time until you end up in that trapping state is mu1. Now starting from state 1, what are the possibilities? You make your first transition. And that first transition is going to take you either to state 2 or to state 3. It takes you to state 2 with probability 0.6. It takes you to state 3 with probability 0.4. Starting from state 2, eventually you're going to get to state 4. How long does it take? We don't know. It's a random variable. But the expected time until this happens is mu2. Starting from state 2, how long does it take you to get to state 4? And similarly, starting from state 3, it's going to take you on the average mu3 time steps until you get to state 4. So what's the expected value of the time until I end at state 4? So with probability 0.6, I'm going to end up at state 2. And from there on, it's going to be the expected time mu2. And with probability 0.4, I'm going to end up at state 3. And from there, it's going to take me so much time. So this is the expected time it's going to take me after the first transition. But we also spend one time step for the first transition. The total time to get there is the time of the first transition, which is 1, plus the expected time starting from the next state. This expression here is the expected time starting from the next state. But we also need to account for the first transition. So we add 1. And this is going to be our mu1. So once more, we have a linear equation that ties together the different mus. And the equation starting from state 4 in this case, of course, is going to be simple. Starting from that state, the expected number of steps it takes you to get there for the first time is, of course, 0, because you're already there. So for that state, this is fine. And for all the other states, you get an equation of this form. Now we're going to have an equation for every state. It's a system of linear equations. Once more, we can solve them. And this gives us the expected times until our chain gets absorbed in this absorbing state. And it's nice to know that this system of equations always has a unique solution. OK, so this was the expected time to absorption for this case where we had the single absorbing state. Suppose that we have our transient states and that we have multiple recurrent classes, or multiple absorbing states. OK. Suppose you've got a picture like this. And we want to calculate the expected time until we get here or there, expected time until we get to an absorbing state. What's the trick? Well, we can lump both of these states together and think of them as just one bad state, one place for which we're interested in how long it takes us to get there. So lump them as one state and accordingly kind of merge all those probabilities. So starting from here, my probability that the next time I end up in this lump and I get absorbed is going to be this probability plus that probability. So we would change that picture. Think of this as being just one big state. And sort of add those two probabilities together to come up with a single probability, which is the probability that starting from here, next time I find myself at some absorbing state. So once you know how to deal with a situation like this, you can also find expected times to absorption for the case where you've got multiple absorbing states. You just lump all those multiple absorbing states into a single one. Finally, there's a kind of related quantity that's of interest. The question is almost the same as in the previous slide, except that here we do not have any absorbing states. Rather, we have a single recurrent class of states. You start somewhere. You start at some state i. You have a special state that's state s. And you ask the question, how long is it going to take me until I get to s for the first time? It's a single recurrent class of states. So you know that the state keeps circulating here and keeps visiting all of the possible states. So eventually, this state will be visited. How long does it take for this to happen? So we're interested in how long it takes for this to happen, how long it takes until we get to s for the first time. And we don't care about what happens afterwards. So we might as well change this picture and remove the transitions out of s and make them self-transitions. Is the answer going to change? No. The only thing that we changed was what happens after you get to s. But what happens after you get to s doesn't matter. The question we're dealing with is, how long does it take us to get to s? So essentially, after we do this transformation, it's the same question as before. What's the time it takes until eventually we hit this state? And now in this new picture, this state is an absorbing state. Or you can just think from first principles. Starting from the state itself, s, it takes you 0 time steps until you get to s. Starting from anywhere else, you need one transition. And then after the first transition, you find yourself at state j with probability Pij. And from then on, you're going to take expected time, Tj, until you get to that terminal state, s. So once more, these equations have a unique solution. You can solve them and find the answer. And finally, there's a related question, which is the mean recurrence time of s. In that question, you start at s. The chain will move randomly. And you ask, how long is it going to take until I come back to s for the next time? So notice the difference here. We're talking the first time after time 0, whereas here it's just the first time anywhere. So here, if you start from s, Ts star is not 0. You want to do at least one transition and ask how long it's going to take me until I get back to s. Well, how long does it take me until I get back to s? I do my first transition. And then after my first transition, I calculate the expected time from the next state, how long it's going to take me until I come back to s. So all these equations that I wrote down, they all kind of look the same. But they're different. So you can either memorize all these equations, or instead, what's better is to just get the basic idea. That is, to calculate probabilities or expected values, you use the total probability or total expectation theorem and condition on the first transition and take it from there. So you're going to get a little bit of practice with these skills in recitation tomorrow and, of course, in your problem set as well.