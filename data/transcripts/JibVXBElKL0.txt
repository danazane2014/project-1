 Okay. This is lecture five in linear algebra. And, it will complete this chapter of the book. So the last section of this chapter is 2.7 that talks about permutations, which finished the previous lecture, and transposes, which also came in the previous lecture. There's a little more to do with those guys, permutations and transposes. But then the heart of the lecture will be the beginning of what you could say is the beginning of linear algebra, the beginning of real linear algebra, which is seeing a bigger picture with vector spaces, not just vectors, but spaces of vectors, and subspaces of those spaces. So we're a little ahead of the syllabus, which is good, because we're coming to the place where, there's a lot to do. Okay. So, to begin with permutations. Can I just, so these permutations, those are matrices P, and they execute row exchanges. And we may need them. We may have a perfectly good matrix, a perfect matrix A that's invertible, that we can solve Ax equal b, but to do it, I've got to allow myself that extra freedom that if a zero shows up in the pivot position, I move it away. I get a nonzero. I get a proper pivot there by exchanging from a row below. And you've seen that already, and I just want to collect the ideas together. And in principle, I could even have to do that two times, or more times. So I have to allow, to complete the theory, the possibility that I take my matrix A, I start elimination, I find out that I need row exchanges, and I do it and continue and I finish. Okay. Then all I want to do is say, and I won't make a big project out of this, what happens to A equal lu? So A equal lu, lu, this was a matrix L with ones on the diagonal and zeros above and multipliers below, and this u we know, with zeros down here. That's only possible. That, that description of elimination assumes that we don't have a P, that we don't have any row exchanges. And now I just want to say, okay, how do I count for row exchanges? Because that doesn't. The P in this factorization is the identity matrix. The rows were in a good order, we left them there. Maybe I'll just add a little moment of reality, too, about how MATLAB actually does elimination. MATLAB not only checks whether that pivot is not zero, as, as, as every human would do, it checks for is that pivot big enough, because it doesn't like very, very small pivots. Pivots close to zero are numerically bad. So actually, if we ask MATLAB to solve a system, it will do some elimination, some, some row exchanges, which we don't think are necessary. Algebra doesn't say they're necessary, but, accuracy, numerical accuracy says they are. Well, we're doing algebra. So here we will say, well, what would, what do row exchanges do, but we won't do them unless we have to. But we may have to. And then the result is, it's hiding here, it's the main fact. This is the description of elimination with row exchanges. So A equal L U becomes P A equal L U. And this act- so this P is the matrix that does the row exchanges. And actually, it does them, it, it, it gets the rows into the right order, into the good order where pivots will not, where zeros won't appear in the pivot position, where L and U will come out right, as, as up here. So that's the, that's the point. Actually, I don't want to labor that point. That a permutation matrix, and you remember, you remember what those were. Can I just, I'll remind you from last time of what the main points about permutation matrices were. And, and then just leave this factorization as the general case. This is, this becomes, this is for any, any invertible A, we get this. For almost every one, we don't need a P. But there's that handful that do need row exchanges, and if we do need them, there they are. OK. Finally, just to remember what P was. So permutations, P is the, the identity matrix with reordered rows. So, well, I include in reordering the possibility that you just leave them the same. So the identity matrix is, is OK. That's, like, the basic, your basic permutation matrix, well, your, your do-nothing permutation matrix is the identity. And then there are the ones that exchange two rows, and then the ones that exchange three rows, and then the ones that exchange four. Well, it gets a little, the, the, it gets more interesting algebraically. If you've got four rows, you might exchange them all in one big cycle, one to two, two to three, three to four, four to one, or you might have exchange one and two, and three and four, lots of possibilities there. In fact, how many possibilities? The answer was n factorial. This is n times n minus one times n minus two times three times two times one. That's the number of, this counts the reorderings, the possible reorderings, so it counts all the n by n permutations. And all those matrices have these, have this nice property that they're all invertible, because we can bring those rows back into the normal order. And the matrix that does that is just P-trans- is just the same as the transpose. You might take a permutation matrix, multiply by its transpose, and you'll see how that the ones hit the ones and give the ones in the identity matrix. So this is a, we'll be highly interested in matrices that have nice properties. And one property that, maybe I could rewrite that as P-transpose P is the identity. That tells me in other words that this is the inverse of that. OK. We'll be interested in matrices that have P-transpose P equal the identity. There are more of them than just permutations, but my point right now is the permutations are like a little group in the middle, in the center of these special matrices. OK. So now we know how many there are. Twenty-four in the case of, there are twenty-four four by four permutations. There are five factorial, which is a hundred and twenty. Five times twenty-four would bump us up to a hundred and twenty, so listing all the five by five permutations would be, not so much fun. OK. So that's permutations. Now also in section two seven is some discussion of transposes. And can I just complete that discussion? First of all, I haven't even transposed a matrix on the board here, have I? So I better do it. So suppose I take a matrix like one two four three three one. So I, it's a rectangular matrix, three by two, and I want to transpose it. So what's its trans- I'll use, I'll use a T, although MATLAB would use a prime. And the result will be, I'll write it here, because this was three rows and two columns, this was a three by two matrix, the transpose will be two rows and three columns, two by three. So it's short and wider. And, of course, the row, that column becomes a row, that column becomes the other row. And at the same time, that row became a column, this row became a column. Oh, what's the general formula for the transpose? So the transpose. You see, you see it in numbers. What I'm going to write is the same thing in symbols. The numbers are the clearest, of course. But in symbols, if I take A transpose and I ask, what number is in row I and column J of A transpose? Well, it came out of A. It came out of A by this flip across the main diagonal. And, actually, it was the number in A, which was in row J, column I. So the row and column numbers just get reversed. The row number becomes the column number, the column number becomes the row number. No problem. OK. Now, a special, the best matrices, we could say. In a lot of applications, symmetric matrices show up. So can I just call attention to symmetric matrices? What does that mean? What does that word symmetric mean? It means that this transposing doesn't change the matrix. A transpose equals A. And an example. So let's take a matrix that's symmetric, so whatever is sitting on the diagonal, but now what's above the diagonal, like a one, had better be there, a seven had better be here, a nine had better be there. There's a symmetric matrix. I happen to use all positive numbers as its entries. That's not the point. The point is that if I transpose that matrix, I get it back again. So symmetric matrices have this property A transpose equals A. I guess at this point, I'm just asking you to notice this family of matrices that are unchanged by transposing. And they're easy to identify, of course. You know, it's not maybe so easy. Before, we had a case where the transpose gave the inverse. That's highly important, but not so simple to see. This is the case where the transpose gives the same matrix back again. That's totally simple to see. OK. Actually, maybe I could even say when would we get such a matrix? For example, that matrix is absolutely far from symmetric, right? The transpose isn't even the same shape, because it's rectangular, it lies down on its side. But let me tell you a way to get a symmetric matrix out of this. Multiply those together. If I multiply this rectangular, shall I call it R for rectangular, so let that be R, for rectangular matrix, and let that be R transpose, which it is, then I think that if I multiply those together, I get a symmetric matrix. Can I just do it with the numbers and then ask you why? How did I know it would be symmetric? So my point is that R transpose R is always symmetric. OK? And I'm going to do it for that particular R transpose R, which was, let's see, the column was one, two, four, three, three, one. I called that one R transpose, didn't I? And I called this guy one, two, four, three, three, one. I called that R. Shall we just do that multiplication? OK, so up here I'm getting a ten. Next to it I'm getting two, a nine, I'm getting an eleven. Next to that I'm getting four and three, a seven. Now what do I get there? This eleven came from one, three times two, three, right? Row one, column two. What goes here? Row two, column one, but no difference. One, three, two, three, or two, three, one, three, same thing, it's going to be an eleven. That's the symmetry. I can continue to fill it out. What --? Oh, let's get that seven. That seven will show up down here, too. And then four more numbers. That seven will show up here because one, three times four, one gave the seven, but also four, one times one, three, it'll give that seven. Do you see that it works? Actually, do you want to see it work also in matrix language? I mean, that's quite convincing, right? That seven is no accident. The eleven is no accident. But just tell me, how do I know if I transpose this guy, how do I know it's symmetric? Well, I'm going to transpose it. And when I transpose it, I'm hoping I get the matrix back again. So can I transpose R transpose R? So just, so why? Why? Well, my suggestion is take the transpose. That's the only way to show it's symmetric, take the transpose and see that it didn't change. OK, so I take the transpose of R transpose R. How do I do that? This is our little practice on the rules for transposes. So the rule for transposes is the order gets reversed. Just like inverses, which we did prove, same rule for transposes and which we'll now use. So the order gets reversed, it's this, it's the transpose of that that comes first, and the transpose of this that comes now. Is that, yeah, that's what I have to write, right? This is a product of two matrices and I want its transpose. So I put the matrices in the opposite order and I transpose them. But what have I got here? What is R transpose transpose? Well, don't all speak at once. R transpose transpose, I've flipped over the diagonal, I flipped over the diagonal again, so I've got R. And that's just my point, that if I started with this matrix, I transposed it, I got it back again. So that's the check without using numbers, but with it checked in two lines that I always get symmetric matrices this way. And actually, that's where they come from in so many practical applications. Okay. So now I've said something today about permutations and about transposes and about symmetry, and I'm ready for chapter three. Can we take a breath? The tape won't take a breath, but the lecturer will, because to tell you about vector spaces is we really have to start now and think, okay, listen up. What are vector spaces? And what are subspaces? Okay. So the point is the main operations that we do, what do we do with vectors? We add them. We know how to add two vectors. We multiply them by numbers, usually called scalars. If we have a vector, we know what three v is. If we have a vector v and w, we know what v plus w is. Those are the two operations that we've got to be able to do. To legitimately talk about a space of vectors, the requirement is that we should be able to add the things and multiply by numbers and that there should be some decent rules satisfied. Okay. So let me start with examples. So I'm talking now about vector spaces, and I'm going to start with examples. Let me say again what this word space is meaning. When I say that word space, that means to me that I've got a bunch of vectors, a space of vectors, but not just any bunch of vectors. A space of vectors has to allow me to do the operations that vectors are for. I have to be able to add vectors and multiply by numbers. I have to be able to take linear combinations. Well, where did we meet linear combinations? We met them back in, say, in R2. So there's a vector space. What's that vector space? So R2 is telling me I'm talking about real numbers and I'm talking about two real numbers. So this is all two-dimensional vectors real, such as -- well, I'm not going to be able to list them all, but let me put a few down. Three, two. Zero, zero. Pi, e. So on. And it's natural -- OK. Let's see, I guess I should do algebra first. Algebra means what can I do to these vectors? I can add them. I can add that to that. And how do I do it? A component at a time, of course. Three, two added to zero, zero gives me, ah, three, two. Sorry about that. Three, two added to pi, e gives me three plus pi, two plus e. Oh, you know what it does. And you know the picture that goes with it. There's the vector three, two. And often the picture has an arrow. The vector zero, zero, which is a highly important vector, it's got, like, the most important here, is there. And of course, it's not much of an arrow. Pi, e. I have to remember, pi is about three and a little more, e is about two and a little more, so maybe there's pi, e. I never drew pi, e before. It's just natural to this, this is the first component on the horizontal and this is the second component going up the vertical. OK. And the whole plane is R2. So R2 is, we could say, the plane, the xy plane. That's what everybody thinks. But the point is, it's a vector space because all those vectors are in there. If I removed one of them, I've, suppose I removed zero, zero. Suppose I tried to take the, consider the xy plane with a puncture, with a point removed, like the origin. That'd be, like, awful to take the origin away. Why is that? Why do I need the origin there? Because I have to be allowed, if I had these other vectors, I have to be allowed to multiply three, two. This was three, two, by anything, by any scalar, including zero. I've got to be allowed to multiply by zero and, and, and, and the result's got to be there. I can't do without that point. And I have to be able to add three, two to the, the opposite guy, minus three, minus two. And if I add those, I'm back to the origin again. No way I can do without the origin. Every vector space has got that zero vector in it. OK, that's an easy vector space, because we have a natural picture of it. OK, similarly easy is R3. This would be all, let me go up a little here. This would be R3 would be all three-dimensional vectors, or shall I say vectors with three real components. OK, let me just, just to be sure we're, we're together, let me take the vector three, two, zero. Is that a vector in R2 or R3? Definitely it's in R3. That, it's got three components, one of them happens to be zero, but that's perfectly OK number. So that's a vector in R3. We don't, we don't want to mix up the, I mean, keep these vectors straight and keep Rn straight. So what's Rn? Rn. So this is our big example, is all vectors with n components. And I'm making these darn things column vectors. Can I, can I try to follow that convention, that there'll be column vectors and their components should be real, real numbers? Later we'll need complex numbers and complex vectors, but much later. OK, so that's a vector space. Now, let's see. What's, what do I have to tell you about vector spaces? I said the most important thing, which is that we can add any two of these and we're still in R2. We can multiply by any number and we're still in R2. We can take any combination and we're still in R2. And same goes for Rn. Honesty requires me to mention that this, these operations of adding and multiplying have to obey a few rules. Like, we can't just arbitrarily say, OK, the sum of three two and pi e is zero zero. It's not. The sum of three two and minus three two is zero zero. So, oh, I'm not going to the, the book actually lists the eight rules that the addition and, and multiplication have to satisfy, but they do. They certainly satisfy it in Rn and, and usually it's not those eight rules that are, are in doubt. What's, what's, what the question is, can we do those additions and do we stay in the space? Let me show you a case where you can't. So suppose this is, this is going to be not a vector space. Suppose I take the xy plane, so there's R2. That is a vector space. Now suppose I just take part of it, just this, just this one, just this one quarter of the vector space. All the vectors with positive or at least not negative components. Can I add those safely? Yes. If I add a vector with, like, two, three two to another vector, like five six, I'm still up in this quarter, no problem with adding. But there's a heck of a problem with multiplying by scalars, because there's a lot of scalars that will take me out of this quarter plane, like negative ones. If I took three two and I multiplied by minus five, I'm way down here. So that's not a vector space, because it's not closed, is the right word. It's not closed under multiplication by all real numbers. So a vector space has to be closed under multiplication and addition of vectors, in other words, linear combinations. So it means that if I give you a few vectors, yeah, look, here's an important here- now we're getting to some really important vector spaces. Well, Rn, like, they are the most important. But we will be interested in some- in vector spaces that are inside Rn. Vector spaces that follow the rules, but they- we don't need all of- see, there we- we started with R2 here and took part of it and messed it up. What we got was not a vector space. Now tell me a vector space that is part of R2 and is still safely- we can multiply, we can add, and we stay in the- in this smaller vector space. So it's going to be called a subspace. So I'm going to change this bad example to a good one. Okay. So I'm going to start again with R2, but I'm going to take an example that is a vector space, so it'll be a vector space inside R2. And we'll call that a subspace of R2. Okay. What can I do? It's got something in it. Suppose it's got this vector in it. Okay. If that vector is in my little subspace and it's a true subspace, then there's got to be some more in it, right? I have to be able to multiply that by two, and that double vector has to be included. I have to be able to multiply by zero, that vector, or by half, or by three quarters, all these vectors, or by minus a half, or by minus one. I have to be able to multiply by any number, so that is going to say that I have to have that whole line. Do you see that? Once I get a vector in there, I've got the whole line of all multiples of that vector. I can't have a vector space without extending to get those multiples in there. Now I still have to check addition, but that comes out okay. This line is going to work, because I could add something on the line to something else on the line, and I'm still on the line. So example, so this is all examples, example of a subspace. Our example is a line in R2. Actually, not just any line. If I took this line, would that -- so all the vectors on that line, so that vector and that vector and this vector and this vector, so in lighter type, I'm drawing something that doesn't work. It's not a subspace. The line in R2, to be a subspace, the line in R2 must go through the zero vector. Because why is this line no good? Let me do a dashed line. Because if I multiply that vector on the dashed line by zero, then I'm down here, I'm not on the dashed line. Zero's got to be. Every subspace has got to contain zero, because I must be allowed to multiply by zero, and that will always give me the zero vector. OK. Now, I was going to make, create some subspaces. Oh, while I'm in R2, why don't we think of all the possibilities? R2, there can't be that many. So what are the possible subspaces of R2? Let me list them. So all subs- so I'm listing now the subspaces of R2. And one possibility that we always allow is all of R2, the whole thing, the whole space. That counts as a subspace of itself. You always want to allow that. Then the others are lines, any line, a line meaning infinitely far in both directions, through the zero. So that's a, that's like the whole space, that's like whole 2D space. This is like one dimension. Is this line the same as R1? No. I don't- you could say it looks a lot like R1. R1 was just a line, and this is a line. But this is a line inside R2. The vectors here have two components. So that's not the same as R1, because there the vectors only have one component. Very close, you could say, but not, no, not the same. OK. And now there's a third possibility. There's a third subspace that's of R2 that's not, not the whole thing, and it's not a line. It's even less. It's just the zero vector alone. The zero vector alone, only. Only. I'll often call this subspace Z, just for zero. Here's a line, L. Here's a plane, all of R2. So you see that the zero vector's OK. You would just, to understand subspaces, we have to know the rules, and knowing the rules means that we have to see that, yes, the zero vector by itself, just this guy alone satisfies the rules. Why is that? Oh, it's too dumb to tell you. If I took that and added it to itself, I'm still there. If I took that and multiply by seventeen, I'm still there. So I've done the operations, adding and multiplying by numbers that are required, and I didn't go outside this one-point space. So that's the littlest subspace. The largest subspace is the whole thing, and in between come, you know, whatever's in between. OK, so for example, what's in between for R3? So if I'm in ordinary three dimensions, the subspaces are all of R3 at one extreme, the zero vector at the bottom, and then a plane, a plane through the origin, or a line, a line through the origin. So with R3, the subspaces were R3, plane through the origin, line through the origin, and the zero vector by itself, zero, zero, zero, just that single vector. OK, you've got the idea. But now comes the reality is, what are these -- where do these subspaces come -- how do they come out of matrices? And I want to take this matrix -- oh, let me take that matrix. So I want to create some subspaces out of that matrix. Well, one subspace is from the columns. OK. So this is the important subspace, the first important subspace that comes from that matrix. I'm going to -- let me call it A again. Back to, OK, I'm looking at the columns of A. Those are vectors in R3. So the columns are in R3. Columns are in R3. So I want those columns to be in my subspace. Now, I can't just put two columns in my subspace and call it a subspace. What do I have to throw in? If I'm going to put those two columns in, what else has got to be there to have a subspace? I must be able to add those things. So the sum of those columns. So these columns are in R3, and I have to be able- I'm going to- I want that to be in my subspace, I want that to be in my subspace, but therefore I have to be able to multiply them by anything, zero zero zero has got to be in my subspace. I have to be able to add them so that four five five is in the subspace. I've got to be able to add one of these plus three of these, that'll give me some other vector. I have to be able to take all the linear combinations. So these are columns in R3, and all their linear combinations form a subspace. What do I mean by linear combinations? I mean multiply that by something, multiply that by something, and add. The two operations of linear algebra, multiplying by numbers and adding vectors. And if I include all the results, then I'm guaranteed to have a subspace. I've done my- the job. And we'll give it a name, the column space, called the column space. Column space. And maybe I'll call it C of A. C for column space. There's an idea there, that you want- that this is the- like, the central idea for today's lecture is got a few vectors. Not satisfied with a few vectors, we want a space of vectors. The vectors are in- these vectors are in R3, so our space of vectors will be vectors in R3. The key idea is we have to be able to take their combinations. So tell me, geometrically, if I drew all these things, like if I drew one, two, four, that would be somewhere maybe there. If I drew three, three, one, who knows, might be, I don't know, I'll say there. There's column one, there's column two. What else- what's in the whole column space? How do I draw the whole column space now? I take all combinations of those two vectors. Do I get- well, I guess I actually listed the possibilities. Do I get the whole space? Do I get a plane? I get more than a line, that's for sure. And I certainly get more than the zero vector, but I do get the zero vector included. What do I get if I combine- take all the combinations of two vectors in R3? So I've got all this stuff on the- I get the- that whole line gets filled out, that whole line gets filled out, but all in between gets filled out, between the two lines, because I'm allowed to add something from one line, something from the other. You see what's coming? I'm getting a plane. That's my- and it's through the origin. Those two vectors, namely one two four and three three one, when I take all their combinations, I fill out a whole plane. Please think about that. That's the picture you have to see. You sure have to see it in R3, because we're going to do it in R10, and we may take a combination of five vectors in R10, and what will we have? God knows. It's some subspace. We'll have five vectors, they're all have ten components, we take their combinations. We don't have R5, because our vectors have ten components. And we possibly have, like, some five-dimensional flat thing going through the origin for sure. Well, of course, if those five vectors were all on a line, then we would only get that line. So you see, there are, like, other possibilities here. It depends what- it depends on those five vectors. Just like if our two columns had been on the same line, then the column space would have been only a line. Here it was a plane. OK. I'm going to stop at that point. That's the central idea of the- the great example of how to create a subspace from a matrix. Take its columns, take their combinations, all their linear combinations, and you get the column space. And that's the central sort of- we're looking at linear algebra at a higher level. When I look at A- I want to look at Ax equal b. That'll be the first thing in the next lecture. How is that- how do I understand Ax equal b in this language- in this new language of vector spaces and column spaces? And what are other subspaces? So the column space is a big one. There are others to come. OK. Thanks.