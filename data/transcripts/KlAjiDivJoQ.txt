 All right. So today, we are going to prove the theorem that I mentioned last time, the Hanbanach theorem, which is a theorem about being able to extend bounded linear functionals on some subspace of a normed space to all of the normed space. And this will therefore answer the question that we posed at the beginning of this topic, whether or not the dual, which is the space of all bounded linear functionals on a normed space, is non-trivial for every normed space. Now, one of the tools we're going to need is this axiom or lemma from set theory, which is due to Zorn, which is as following. So I'm going to have to recall from the last lecture what some of these words mean. So Zorn's lemma states that if every chain in a non-empty, partially ordered set E has an upper bound, then E has a maximal element. So a partially ordered set E, that means a set E with a relation that's basically like a less than or equal to. That satisfies three properties so that it's like an extended less than or equal to. And a chain is a subset of E so that any two elements in that subset can be compared. One is either bigger than or equal to the other, or one is always bigger than or equal to the other. And so this theorem says that if every chain of a partially ordered set has an upper bound, that has a pretty clear meaning. Then E has a maximal element. So a maximal element of E, that means an element that is not less than or equal to something other than itself. So anything bigger than or equal to this maximal element has to be that element. A maximal element is not necessarily an upper bound. A maximal element just means nothing can get over its head. And so as a warm up, we're going to use Zorn's lemma to prove a fact about vector spaces. So a Hamel basis, and I think I went over this at the end of class last time, of a vector space V, this is a linear independent set, H, such that every element of V is a finite linear combination of the elements from H. So for example, this set consisting of the vector 1, 0 and the vector 0, 1, this is a Hamel basis for R2. Every element in R2 can be written as a finite linear combination of these guys. But this is something, the fact that finite dimensional spaces have bases is something you discuss in linear algebra. But now we're in functional analysis, which is linear algebra in infinite dimensions. It's not so clear that every vector space has a Hamel basis. And so what we're going to do is we're going to apply Zorn's lemma to prove that every vector space does have a Hamel basis. So this is the following theorem. And this argument will kind of be a warm up for how we'll apply Zorn to prove the Hanbanac theorem. So if V is a vector space, then V has a Hamel basis. So for the proof, I am going to apply Zorn. So I need to have some ordered set. And my ordered set is going to be let E be the set of all linearly independent subsets of V. And we're going to define an order on E. So E is the set of all subsets of V that are linearly independent. And we define partial order on E by inclusion. So these are just the elements of E are subsets of V. So we'll say one subset is less than or equal to another subset if one is included in the other. So E and E prime and E, then we'll say E is less than or equal to E prime if and only if this subset of V, E, is a subset of E prime. And again, so I think I said this in a previous lecture. I'm kind of used to using this notation for a subset, not necessarily a strict subset, just from teaching 18.100a last semester. So this does not mean a strict subset. So maybe put that in there. OK, so this is my partially ordered set, which I hope to apply the Zorn's Lemma on. And then what I will show is that the maximal element of this set, once I show it exists, in fact, has to be a Hamil basis for V. OK? So now we'll apply Zorn towards finding Zorn. Let's see. So E is a chain in E. OK, that means any two elements of C can be compared. Define little c to be equal to the union over all E in capital C, E. All right, so each of these little e's, this is a subset of V consisting of linearly independent elements. And now what I'm taking little c to be is the union of all these subsets of linearly independent elements. And I claim that this is a linearly independent subset, which, since this subset of V contains every element of C, means C is bigger than or equal to all of E. Thus, C is an upper bound for C. OK? So we just need to show that little c is now a linearly independent subset. And therefore, all of these e's in this capital C are bounded above by C. And therefore, C is an upper bound for capital C. Now, to show it's a linearly independent subset, we're going to use the fact that capital C is a chain, that you can always compare two things. All right? So let's show that little c is a linearly independent subset. That's something very specific. So let V1 up to Vn be in little c. Then there exists E1, E2, En in capital C. So little c is the union of all the e's. So these have to come from somewhere such that for all j, Vj is in Ej. OK? Now, it's not difficult to show by induction that, since I can compare any two elements in C, I can compare any n elements of C, meaning I can actually order any finitely many elements in C. Right? So again, to say this is a chain means I can always order two elements. But by induction, it's not difficult to show I can always order n elements of C. So I'm just going to skip to that, and I'll leave it to you, meaning that I can always find a biggest element out of any finite collection of these guys. All right? So since C is a chain, there exists a capital J such that for all j equals 1 up to n, Ej is less than or equal to E capital J, which, again, remember, this means that Ej is a subset of E capital J, just by how we've defined this partial order. And therefore, since all of these Ej's for j from 1 to n are contained in this E sub capital J, that means that v1 up to vn are in E capital J. All right? So I had this finitely many from C. I can always compare any two of them, and therefore, I pick the biggest linearly independent subset out of this finitely many. And all of these vectors have to then come from that linearly independent subset. And therefore, since this is a linearly independent subset, that means these are linearly independent. Are linearly independent since Ej is a linearly independent subset. OK. And so we've shown every finite collection of vectors in C is linearly independent. So we've concluded that little c is a collection of linearly independent vectors. So we've now shown that the hypotheses of Zorn are verified, that every chain has an upper bound. And therefore, this set E has a maximal element, which I'll call H. OK? So I claim that H now spans the vector space V, meaning every element of V can be written as a finite linear combination of elements of H. So I claim that H spans V. So when I say H spans V, that's just a short way of saying that every element of V can be written as a finite linear combination of elements of H. So suppose not. Then there exists an element V and capital V such that V cannot be written as a finite linear combination of elements of H. Now, it's something from linear algebra. I'm sure they went over this before. But if I have a linearly independent subset and an element that can't be written as a finite linear combination of elements from that subset, then just by adding that element, I now obtain a new linearly independent subset. And therefore, I conclude that the set H union V is linearly independent, linearly independent subset of V. But then H will be less than, meaning it is less than or equal to but not equal to, which implies H is not maximal, which is a contradiction. Remember, H was supposed to be the maximal element of E. Nothing sits above H. And if we assume that H does not span V, then we can tack on to H something, making a bigger linearly independent subset of V. And that results in a contradiction. So thus, that must contradict our initial assumption that H did not span V. And therefore, by definition, it's a Hamil basis. OK, so we've seen this kind of exercise, first exercise of using this very powerful weapon, Zorn's lemma, to prove this fact that every vector space has a Hamil basis. And now we're going to use it to prove the Hanbanac theorem. So let me state the Hanbanac theorem for you. And then we're going to discuss the strategy. Actually, what I'm going to do is I'm going to state the Hanbanac theorem. I'm going to state a lemma. And then I'm going to give you what the plan is for proving the Hanbanac theorem. So the Hanbanac theorem is if V is a normed space, M is a subspace of V, and u going from M to C is linear such that, so it's a bounded linear functional, for all t and M, u of t, so this is now a complex number. Its absolute value is less than or equal to constant times norm of t. And then there exists a continuous extension of u to the entire space, and a continuous extension that has the same constant here. So remember, think of this as being the norm of little u. And so we can extend it to a bounded linear functional with the same norm, essentially. And there exists a capital U, which is a bounded linear functional from V to C. So it's an element of the dual space such that now for all t and V, u of t is less than or equal to the same constant t. And I should have said before such that capital U, when I restrict to M, gives me little u. And for all t and V, capital U of t is less than or equal to a constant times the norm of t. So this is a, I should have put this here at the start of the theorem, but this is the Hanbanac theorem. And this is a very, very useful theorem to have. In fact, in the exercises, you can use this theorem to prove that the dual of little l infinity is not little l1. So remember, from the second assignment and from what I've said in lectures, the dual of little lp is little lq, where 1 over p plus 1 over q equals 1. As long as p is bigger than or equal to 1 and less than infinity, and it doesn't work for p equals infinity. So using the Hanbanac theorem, you can show that why it doesn't work for little l infinity, and that'll be in the assignment. OK, so now just for, I'm going to, so I don't have to keep writing all of this over and over again. I'm going to refer to this as u is a continuous extension of little u, although that's not quite precise, because we are extending little u to a continuous, so a bounded linear operator on v, but we're also extending it so that the capital U satisfies the same bound as little u. So this is a little imprecise, but I think you should get my meaning. OK, so this assumption, let me denote by star, namely that we have a subspace, and we have a bounded linear functional on this subspace that satisfies this bound. So I'm not going to prove the Hanbanac theorem just yet. I'm going to prove a lemma, or I'm going to state a lemma and then tell you how we're going to use it to prove the Hanbanac theorem. So actually, you know what? We'll state it slightly differently. I'm not going to use that. So if v is a normed space, m, a subset of v, is a subspace, and u from m to c is linear such that little u of t is less than or equal to constant times the norm of t, so for all t in m. And you know what? Let me, I think the difference between capital U and little u is clear enough. Then I can extend it at least in one direction. So in other words, then, so if m is, and one last assumption, and I take something that's not in the linear subspace, then I can extend it to the subspace of v consisting of m and also the direction x. So then there exists u prime in the dual. So I shouldn't use u prime. Let's say v, OK, well, let's use u prime. u prime from m prime to c, which is linear, and here m prime is defined to be the subset or the subspace m plus, so this should be, this does not mean quotient space. We were using pluses for quotient spaces, but this is the subspace of v consisting of m plus elements of the form constant times x. So this is elements of the form t plus ax, where t is in m, a is in c, such that u prime, when restricted to m, gives me u. And for all t prime and m prime, u prime of t prime, an absolute value, is less than or equal to the same constant times the norm of t prime. So maybe I made a mess of that speaking while I was writing the lemma, but anyways. So let's say you have a bounded linear functional on a subspace of v, and you take an element that's not in m. So the way I'll draw the picture is there's m, and here's something, so x. Then I can extend this bounded linear functional, which lives on m, to now the subspace consisting of all elements of m plus elements plus scalar multiples of x. And I can do this in a continuous way, meaning I get a bounded linear functional on m prime, which satisfies the same bound as u did. So what's the strategy for using this to prove the Hanbanac theorem? So just so that we're clear on why we would be interested in such a thing, we apply Zorn's lemma to all continuous extensions of little u. So now I'm talking about how we prove Hanbanac theorem. So we define as our partially ordered set would be the set of all continuous extensions of u, and then we would put a partial order on that, where one extension is bigger than or equal to another extension if that extension extends the smaller extension. And using the argument we did for proving the vector space has a Hamel basis, we can then show that Zorn's lemma applies. And then we'll have a maximal element of this set of continuous extensions of u. Now, what we would like to conclude is that this maximal element, this maximal continuous extension, is defined on all of v. And so how would we prove that? Well, we would do it just kind of like we did for the Hamel basis case. We would suppose not. And then we would show that if it was not defined on the entire norm space, then we can extend that maximal element again using this lemma, and therefore contradicting the fact that that extension was a maximal element. So in short, we apply Zorn's lemma to all continuous extensions of u to get a maximal element capital U. Two, we use the lemma to show u is this extension is defined on all of capital V. So these extensions will come with two pieces of information. One is the subspace, which is bigger than m, and then also the functional itself. And so we'll use the lemma to show that the subspace that this capital U is defined on is all of v by showing that if it's not, then we can extend it to a slightly bigger subspace using the lemma, which would contradict the fact that this is a maximal element. So that's the plan. So in fact, since we have this lemma already here, and since I've said it so many times, let's go ahead and just prove the Hanbanac theorem, assuming this lemma holds. We don't need the proof of this lemma to actually prove the Hanbanac theorem. We just need this statement. So that's what we're going to do first. And then we'll go back and prove this lemma. So this is the proof of the Hanbanac theorem. We'll go back and prove the lemma in a second. So let E, like I said, this will be the set of all continuous extensions of little u. So v comma, let's say, n, such that n is a subspace of v. m is contained in n, not strictly, but it's a subset of n. And v is a continuous extension of u to capital N, meaning it satisfies. It's a bounded linear functional on capital N. When you restrict it to capital M, it equals u. And it satisfies the same bound that little u does on the bigger subspace N. And note, this is non-empty because, well, u and m are in this. I'm not saying m has to be a strict subspace of capital N. And so we'll define a partial order on E. So by the following definition, we will say v1, n1 is less than or equal to v2, n2. If n1 is contained in n2, and v2, when restricted to n1, gives me v1. So v2 is, if you like, a continuous extension of v1. Remember, all of these functionals are assumed to be satisfying the same bound as u did, so with the same constant. So it's not difficult to check, just like I didn't check it for inclusion. But it's not hard to check that this is, in fact, a partial order. So now we want to apply Zorn's lemma to get a maximal element of E, which we want to show is, in fact, this u that we say exists. So we have to show every chain in E has an upper bound. So let's see, which I'll denote as vi ni for i in some index, v chain in E. So this is a set of extensions. And we can always compare any two extensions in there. So let me just repeat or write down, again, what this means to be a chain. This means, then, for all i1, i2 in this index that I'm using just to index these elements of the chain, either vi1 ni1 is less than or equal to vi2 ni2 or vice versa. I can't remember if a c goes there or an s, so I'm going to put an s. So 1 is either bigger than. Whenever I have two elements, I can always compare them. Let n be the union of all these subspaces coming from this collection. OK? Now, again, it's not difficult to show that n is, in fact, a subspace. So I claim n is a subspace. And again, we're going to use the fact that c is a chain to be able to verify this. Let v1, v2 be an n. And let's take two scalars, a1, a2, and c. I want to show that a1 times v1 plus a2 times v2 remains an n. Then there exists i1, i2, two indices such that v1 is in ni1 and v2 is in ni2. Now, I can always compare any two subspaces that are appearing in this set of ordered pairs forming this chain. So one of these subspaces is bigger than the other. Then just by flipping 1 and 2 if I need to, since c is a chain, ni1 is contained in ni2 without loss of generality. So it will either be ni1 will be contained in ni2 or the other way around. And if it's the other way around, just flip the numbers 1 and 2. So I'm going to assume ni1 is contained in ni2. Then that means both of these elements are contained in ni2. v2 are both in the bigger one. And since this is a subspace, this means that a1 v1 plus a2 v2 is in ni2, which, remember, is a subset of n. And therefore, n is a subspace. So I now have a subspace which contains all of these subspaces coming from the chain. Now I need to define a linear functional on this subspace n that extends all the vi's in a continuous way. And this would give me an upper bound for this chain. But it's not difficult to guess what that linear functional will be. We define v. I don't think I use v. Yeah, I do. Well, let's not do that. So let's say, OK, so I mean, I shouldn't have used v1 and v2 when talking about this subspace business. That was poor choice of notation. So let's make that x1, x2. And the chain, blah, blah, blah, x1, x2, and therefore, x1, x2 is in, OK. So I just don't want to mix up the elements of the vector space with these functionals, which I'm labeling by v. So now we define a function v from n to c by the following. So if t is an element of this union, it has to be an element of one of these n sub i's. Then I define v of t to be simply v sub i, which is defined on this linear subspace. And so I take v of t to be the value of v sub i evaluated at t. So now one question is, is this well-defined? Because an element t in n sub i could also have been an element of a different n sub i. So is this well-defined? So we have to check. If it's in two of these, does this imply? Question mark. v i1 of t equals v i2 of t. And again, we're going to use the fact that this is a chain to verify this. So suppose t is in n sub i1 intersect n sub i2. And again, for any two elements of this chain, we can compare them. So let's assume i2 corresponds to the bigger index. So v i1 n i1 is less than or equal to v i2 n i2. OK? Now, this order not only is defined in terms of the subspaces, remember, but in terms of the functionals defined on these subspaces. And it's defined by the fact that this functional is an extension of this functional. And therefore, since v i2 is the bigger one, it extends the smaller one. This implies v i2 of t equals v i1 of t. And therefore, v is well-defined. And not only that, you can also, so I wrote this out carefully showing it's well-defined. But by similar arguments, you can then show that v is, in fact, linear. And let's see, do I do that or do I stop there? OK. So it's well-defined on n. It's also an extension of every single functional defined on each n sub i. So the last thing to check is that it's linear. And it's a continuous extension of all these vi's, meaning it satisfies the same bound. But all of the vi's satisfy that bound. v is defined in terms of the vi's. So I mean, we can just read off from here that v will satisfy that same bound. So I will leave it to you that you can check that v is an element of the dual space of this subspace n. So it's a bounded linear functional on n and a continuous extension of all vi's. OK. So for little i and capital I, we conclude vi ni is less than or equal to vn. And therefore, vn is an upper bound of C. OK. All right, so we've verified the hypotheses of Zorn's lemma, which I've already, which I just erased. So that means the set E has a maximal element. So by Zorn, the set E has a maximal element capital U in. OK. So I claim n equals v. And therefore, capital U does the job, because remember, U, capital U, so since capital U, capital N is an element of E, that means capital U is a continuous extension of little u. All right. And now we just want to conclude that for this maximal element, the subspace on which it's defined is the entire space V. OK. So suppose not. Let x be an element not in N. By the lemma, there exists a continuous extension of U, capital U, to the subspace in plus the span of x. And this is a continuous extension of capital U, which is a continuous extension of little u. And therefore, it's a continuous extension of little u. So continuous extension, let's call this something. Let's call it v, little v, v in plus. So if the subspace that capital U is defined on is not all of v, then by the lemma, we can extend capital U continuously to n plus the span of x. And therefore, this element will be a continuous extension of little u. And therefore, it's an element of E. But then, u n is smaller than v n plus the span of x. This is a bigger subspace than this, because x is not in N, which implies u n is not a maximal element. And that's a contradiction. And what do we contradict? What was the assumption that led us astray is the fact that we assume that this maximal element is not defined on all of the entire norm space. Thus, u is defined on the entire norm space. And it's a continuous of little u. And that's the proof of Hanbana. So I hope that the proof was clear. If you followed the Hamel basis argument, this should be reasonable to expect, too. It's just this argument is almost the same as the Hamel basis argument, except now instead of the Hamel basis where the elements of our partially ordered set are just subsets, we also have two pieces of data for our partially ordered set here, one being the subspace and the second being the functional that's defined on that subspace that extends the original continuous linear functional that we wanted to extend. So let's prove the lemma. And that'll conclude the proof of the Hanbana theorem. So now we're going to proof of the lemma. So that lemma up there, if v is a norm space and you take something that's not in the subspace, then you can extend u continuously to this bigger subspace. All right? So first off, even though I keep saying that this is a subspace, I mean, this is kind of something that needs to be, I mean, it's not difficult to check, but still check. So one thing we need is that every element in a subspace plus this constant times x can be written uniquely. So we first note if t prime equals t. So t prime is in m prime, which remember is m plus constant times x. Then there exists a unique t and m and a in complex numbers such that t prime equals t plus a times x. All right, so why is that? So why can an element of this space not have two different representations, not be written as two different elements of m plus two different scalars times x? Well, if t plus ax equals t tilde plus a tilde x, then this implies that a minus a tilde times x is equal to t tilde minus t, which is in m. m is a subspace, so the difference of two elements of m is in m. And therefore, if a does not equal a tilde, then that means x is equal to a constant multiple of something in m, and therefore, x is in m. So we conclude that a must equal a tilde, which implies from assuming they're equal that t equals t tilde. So every element in this larger subspace can be written uniquely as an element of m plus a scalar multiple of x. Now, why do we need this fact? We need this fact to be able to say that this linear functional that we're going to define, that we hope to say extends u continuously, is in fact well-defined. So thus, upon choosing a number lambda in the complex numbers, the map u prime of t plus ax given by u of t plus a lambda is well-defined on m prime, because we've shown every element of m prime can be written uniquely in this way, is well-defined on m prime, and u prime going from m prime to c is linear. So if the original functional u, little u, is if that constant c is equal to 0, then little u is just identically 0, and we know how to extend the 0 functional. So let's suppose capital C is non-zero, and if I divide little u by capital C, I can then extend that functional with the case capital C equals 1 and obtain an extension satisfying the bound I want. And so what I'm saying kind of poorly is that, I'll leave you a second to think about it. It's not difficult to understand why, without loss of generality, we can assume c equals 1. c is not equal to 1, so if we do the c equals 1 case, then for the case c not equal to 1, we extend u over capital C using the c equals 1 case. And then the result follows. So we'll just do the case capital C equals 1. So now our one free parameter is lambda, and this is for. And we want to be able to choose lambda so that this is already an extension of little u. If I take a equals 0, so I'm just taking elements in m, this is u prime of t is equal to u of t. So it's already an extension of little u to this bigger subspace. And now what we want to be able to choose lambda so that it extends it in a continuous way with the same constant being 1 and that inequality up there. So I keep pointing up there. I don't think the camera's looking up there, so you'll have to hopefully interpret my meaning correctly. So we want to choose lambda, complex number, such that the following holds for all t in m, a, and c. So u prime of t plus ax, which is just u of t plus a lambda, an absolute value, is less than or equal to the norm of t plus a lambda. If we're able to do that, then u prime is then our continuous extension that we're looking for. Is our continuous extension. So all that we need to do now is find a lambda so that this holds. And once we've done that, we've finished the proof. Now, that thing I boxed in a minute ago, we're going to reduce it to kind of the simplest form. OK? Now, what's in the box holds regardless what lambda is when a is equal to 0. And now what I'm going to do is basically remove the fact that a can change. So the estimate u of t plus a lambda less than or equal to t plus a lambda holds when a equals 0 regardless of how we've chosen lambda. So we just need to be able to choose lambda so that this holds for a non-zero. Consider trying to choose lambda so that this holds for all a non-zero. OK? Now, let me take this inequality here and divide it by the absolute value of a. Then that inequality for a not equal to 0, so for all a not equal to 0, this is equivalent to if I divide by the norm of a and bring this inside the norm, u of t minus a minus lambda is less than or equal to, or I should say this is the absolute value. That's the absolute value. So less than or equal to t over minus a minus lambda for all t and m. Now, if t is an m, t over minus a is also an m. So this bound here is equivalent to showing that we can choose lambda so that u of t minus lambda is less than or equal to the norm of t minus lambda for all t and m. So since t is a subspace, proving this bound, or choosing lambda so that this bound holds is equivalent to choosing lambda so that this bound holds. So in sum, or in summary, I should say in sum. I'm thinking in terms of notation. So in summary, the thing that we wanted to show originally, that we can choose lambda so that for all t and m, a complex number, that inequality holds is equivalent to showing that we can choose lambda so that this inequality holds. That's the point. And now what we're going to do is we're going to choose the real and imaginary parts of lambda. And we'll choose the real part of lambda first. So we first prove. Piece of chalk is weird. I got to get a different one. So we first prove that there exists an alpha in R such that w of t minus alpha, an absolute value, is less than or equal to t minus alpha for all t and m. And what is w of t? This is equal to the real part of u of t, which, let me remind you, this is just equal to u of t plus u of t complex conjugate over 2. Now, the real part of any complex number is always less than or equal to the absolute value of that complex number. So we haven't chosen what alpha is yet. I'll show you how to choose alpha in just a minute. Note that for all t and m, w of t, an absolute value, which, remember, is defined to be the real part of u of t, this is less than or equal to the absolute value of u of t because, I should say, the modulus of u of t. The modulus of a complex number is the square root of the sum of the real part squared and the imaginary part squared. So that's always less than or equal to that. And by assumption, this is less than or equal to the norm of t. Now, we're going to use the fact that w is real valued. Then w of t1 minus w of t2. So let me say for all t1, t2, and m, if I look at w of t1 minus w of t2, this is equal to, and since u is linear and taking the real part is linear, this is equal to w of t1 minus w of t2. This is less than or equal to its absolute value. This is where I'm using the fact that it's real valued. And as we've just shown, that this is always less than or equal to the absolute value. And we have that. OK? And now I'm going to do one more thing and add and subtract x. So this is, in the end, we want, whoa, whoa, whoa, whoa, whoa. This should have been x. This should have been x. Sorry, sorry, sorry. I hope you fast forwarded to this point and saw that this should have been x and x. So in the end, we want to somehow connect this to, and I did it again here, x to the norm of t minus x. So what I'm going to do is add and subtract x and use the triangle inequality. And this is less than or equal to t1 minus x plus t2 minus x. And therefore, w of t1 minus the norm of t1 minus x is less than or equal to w of t2 plus norm of t minus t2 minus x for all t1 and t2 and m. OK? And now, so this holds for all t1 and t2. So I could fix t2 and take the sup over all t1's, which implies that sup of, so let's not make that a t1. I could just say t is always less than or equal to w of t2 plus t2 minus x. And this holds for all t2 and m. So the fact that this holds for all t1 tells you this thing is an upper bound of this for all t and m. And therefore, its supremum is less than or equal to this thing for all t2 and m. And therefore, this quantity on the left is a lower bound for this thing on the right for all t2 and m. And therefore, we conclude that the sup of t and m of w of t minus norm of t minus x is less than or equal to the mth over all t and m w of t plus t minus x. How do I choose alpha? So I have these two numbers here, which are related in this way. I choose alpha between these two numbers, between this number and this number. So there's a less than or equal to sign, so I can pick some number in between them. Maybe these two things are equal, and therefore, alpha is equal to both of them. Or I could just choose alpha to be this one. It doesn't matter. So OK. All right. And the proof is just about completed. OK. Now I'm going to show that this alpha works. So then for all t and capital M, I have w of t minus norm of t minus x is less than or equal to alpha is less than or equal to w of t plus norm of t minus x. And therefore, it's less than or equal to alpha minus w of t. Less than or equal to norm of t minus x, which is the same as alpha minus w of t, I should say. OK. All right. So we showed how to do it for we're able to choose an alpha so that essentially this inequality holds for the real part. We can do that also for the imaginary part.