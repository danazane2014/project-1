 OK. So we're going to continue with our discussion of the spectrum of an operator, bounded linear operator. So let me just recall from last time the definition that if A, and throughout H is a Hilbert space, if A is in a bounded linear operator, then the resolvent set of A is the set of all lambdas and complex numbers such that A minus lambda times the identity, which I write as A minus lambda, is bijective, meaning it's one to one and onto, which implies by the open mapping theorem that it has a bounded inverse, or is equivalent to it having a bounded inverse, and the spectrum of A was the complement of the resolvent set within the set of complex numbers. And so the spectrum is supposed to be a generalization of, in finite dimensions, what we're called the eigenvalues. And so we just recall we called lambda an element of the spectrum, an eigenvalue if there exists a u not equal to 0 such that A minus lambda applied to u is 0. In other words, A minus lambda is not injective. So the reason for lambda being in the spectrum is that so for a number to be called an eigenvalue is that this operator A minus lambda has non-trivial null space. In other words, it has a non-zero u so that Au equals lambda u, and we call this thing an eigenvector. And we saw last time examples of an operator that has infinitely many eigenvalues and eigenvectors, and also an example of a bounded linear operator which has no eigenvalues and eigenvectors, unlike in the case in finite dimensions where the spectrum is exactly the set of eigenvalues of an operator. And we also proved at the end of last time. So what we could say about these two sets or what we could say about the spectrum is that it's a closed set, and it's contained within the ball of radius norm A in the complex numbers, which means it's a compact set. And what we could say by taking compliments about the resolvent set is that it's an open set that contains the exterior to a ball of radius norm of A in the complex numbers. And that's about all we can say about the spectrum in general for now, but we can say quite a lot about the spectrum of self-adjoint operators, and then we can say, give a pretty complete picture about the spectrum for self-adjoint compact operators. But let's first look at self-adjoint operators. So at the end of last time, we proved that if I have a self-adjoint, and this is not related to the spectrum, if I have a self-adjoint bounded linear operator on the Hilbert space, then for all u, A uu is a real number, and we could write the norm of A as this quantity sup u equals 1 of the absolute value of A u inner product u. All right, so now we have the following theorem about the spectrum for self-adjoint bounded linear operators on the Hilbert space. So the first is that the spectrum is contained in the real number line. So spectrum of A is contained in the real number line norm A, or in this interval, minus norm A to norm A, which I'm viewing as a subset of the complex numbers, so just the line segment from minus norm A to norm A as a subset of the complex numbers. And the second is that one of these two endpoints has to be in the spectrum, maybe both, but at least one. At least one of plus or minus norm A is in the spectrum of A. So to establish one, we already know since the spectrum of A is contained in those complex numbers with modulus less than or equal to the norm of A, we just need to show that the spectrum is contained in the real number line. And it must be contained in this interval, since it's contained here. So we'll show that anything off the real number line lies in the resolvent. That's how we'll go about this. So we'll show that if lambda equals S plus IT with T not equal to 0, then lambda is in the resolvent set of A. Now suppose lambda has this form, then A minus lambda is equal to A minus S plus or minus, sorry, IT, which I can write as A tilde minus IT with A tilde, a bounded linear operator given by A minus S, which is also equal to the adjoint, because S is a real number. So I should have said T is not equal to 0 and ST, real numbers. So A minus lambda I can write as A tilde minus IT, where A tilde is A minus S, again, a self-adjoint operator. So if I can do an argument for A tilde and show that A tilde minus IT is bijective, then I can conclude A minus S minus IT is bijective. Why am I doing this? Because then I can just focus on the one case that S is 0. A minus IT is bijective if and only if A minus lambda is bijective. So we only need to consider it. So I can just work on this thing. But instead of writing A tilde over and over again, I'll just switch back to A. So I only really need to consider the case S equals 0. So rather than do the argument for A tilde minus IT, I'm just going to set S equal to 0 and start doing the argument for A minus IT. OK, so since by what we proved or the result from last time, so let me just set out what we're going to prove. If A is self-adjoint, then A minus IT is bijective for all t not equal to 0. So once I've proven this claim, then I've proven my first part of the theorem. Now, since AU applied to U is real, I get that if I take the imaginary part of A minus IT applied to U, inner product U, this is equal to AUU. Taking the imaginary part of that is just 0. So then I get minus T norm U squared, which implies that since T is non-zero, we're assuming T is non-zero, A minus IT times U equals 0. If and only if U equals 0, because if this quantity here equals 0, then this thing here equals 0. And therefore, the norm of U has to be 0 since T is non-zero. So the null space of A minus IT is just the 0 vector. And therefore, it's injective, right? It is injective. It's 1 to 1. Now we just want to show it's bijective or it's surjective. OK, so similarly, I can prove that the adjoint of this operator, which is in fact A plus IT, is injective. And therefore, I get that the orthogonal complement to the range of A minus IT. So I want to show this equals H to show it's surjective. So the orthogonal complement of that, which is equal to the null space of the adjoint, which is equals. So since this equals 0, I conclude that the range of A minus IT closure, which is equal to range of A minus IT taking the orthogonal complement of the orthogonal complement. So that was part of an assignment that if I have a subspace of the Hilbert space and I take, or let me say here, and I take the orthogonal complement of the orthogonal complement, I don't get back the subspace. I get the closure of the subspace. So this is equal to the orthogonal complement of the 0 vector, which is H. So I'll be done showing that A minus IT is surjective if I can show that the range is closed, because then this will just be the range of A minus IT equals H. So we just need to show now that the range of A minus IT is closed. So to show it's closed, we have to show that if we take a sequence of elements in here converging to something, then that limit is, in fact, in the set. So suppose I have a sequence of elements UN such that A minus IT applied to UN converges to an element V. So my goal is to show that V is in the range of A minus IT. So we want to show V is in the range. And then we've shown that the range is closed, and we're done with the first part. So using this argument here, we're going to show that the UNs, which a priori we don't know converge, all we know is that the images of the UNs converge. We're going to show that the UNs actually converge. And then that will essentially finish the proof. So then we have that the absolute value of T, U minus UM norm squared. This is by this calculation we did over here equal to the absolute value of the image of, I mean, the imaginary part of A minus IT UN minus UM, UN minus UM. Take the absolute value of all of that. And now this is less than or equal to. So the absolute value of the imaginary part of a complex number is less than or equal to the absolute value of that complex number, which by Cauchy-Schwarz I can say is less than or equal to A minus IT applied to UN minus UM. But I'll write it as A minus IT UM times the norm of UN minus UM. And I started off with T, which is non-zero, times the norm of UN minus UM squared. So I get that UN minus UM. So that this is less than or equal to 1 over the absolute value of T times the norm of A minus IT applied to UN minus A minus IT applied to UM norm. OK? Now, this thing on the right, or I should say A minus IT applied to UN, this is a convergent sequence. In particular, it's a Cauchy sequence. So given epsilon, I can find capital N so that the norm of this right-hand side is less than epsilon times the magnitude of T. And therefore, for all capital N bigger than or equal to, or for all little n bigger than or equal to that capital N, this in norm will be less than epsilon. OK? So since this is Cauchy, because it's convergent, the previous estimate implies that sequence UN is Cauchy. And since we're in a Hilbert space, which means it's complete, we can find a limit of this UN. There exists a U and H such that UN converges to U. And then we're done now. Then since A is a bounded linear operator, A minus IT U, or A minus IT applied to U, this is equal to the limit as n goes to infinity of A minus IT applied to UN. But remember, we assumed that this converges to some element V. And therefore, V is equal to something in the image or in the range of A minus IT. So V is in the range. OK? And thus, the range of A minus IT is closed. And by this here, we conclude that the range of A minus T equals H, so A minus IT is bijective. OK? And that concludes the proof of the first property we wanted to do. OK. So for the second thing we wanted to show, we wanted to show that at least one of plus or minus norm of A is in the spectrum of A. OK? Now, since the norm of A is equal to the sup over norm of U equals 1 of the absolute value of AUU, so a supremum is always characterized by being an upper bound and also there existing a sequence in the set of things you're taking the supremum of converging to that supremum. So that implies that there exists a sequence of unit vectors so that AU inner product U in absolute value has to converge to the norm of A. So in particular, AU applied to U has to converge to the norm of A or minus norm of A as n goes to infinity. And there's no n here, so. OK. All right. So then what does this imply? Then this implies that for at least one of these choices, then A plus or minus norm of A applied to U in inner product U in converges to 0 as n goes to infinity, where here the plus or minus is chosen depending on whether this goes to plus or minus the norm of A. So this sign here would be the opposite of whichever sign this sequence goes to. I now claim that this property here implies that whichever sign we have that for, that this operator appearing here cannot be invertible. And therefore, whichever sign appeared here, the opposite sign. So let me, in fact, stay. So the minus corresponds to the plus sign. The plus sign corresponds to the minus sign, if we have one of those. So I claim that this property here implies that this operator is not invertible. And therefore, one of those is in the spectrum. So suppose instead that A minus plus norm of A, whichever one appeared, is invertible. So whichever one does satisfy this is invertible. OK? Then the U in's all have norm 1. So 1 is equal to the norm of U in. And I can write this as the norm of A minus plus norm A inverse applied to A minus plus norm A, because that's just the identity applied to U in. And this is less than or equal to the norm of the inverse times the norm of this quantity. And OK, so this is a fixed number. And this thing is converging to 0. So the right-hand side converges to 0. But that's 1. I have 1 is less than or equal to 0. So that's a contradiction. Thus, A minus or plus norm of A, again, where the minus or plus corresponds to which sign of the norm of A we had that sequence converging to is not invertible, which implies that plus or minus at least one of these is in the spectrum of A. OK. Now, we can, in fact, do a little bit better than, based on this argument, we can do a little bit better in bounding the spectrum of the self-adjoint operator than just the bound that we have coming from the general theory. So what do I mean by that? So if A is a self-adjoint bounded operator, and A minus is equal to the infimum over all u equals 1, Au applied to u, A plus equals the sup Au applied to u, then the spectrum of A is contained. So first off, then a couple of things, two things. Then both of these numbers are in the spectrum of A, and the spectrum is contained in this line segment. OK. So this is something of a tighter bound, because A minus is always bigger than or equal to minus the norm of A, just by this always being bounded below by the norm of A. And A plus is always bounded above by the norm of A, since this is always bounded above by the norm of A, so the sup will be bounded above by that. So this is a tighter estimate than just a regular estimate that says the spectrum is contained inside of the interval from minus norm A to norm A. And in fact, you get more information that not just one of the endpoints have to be in, but both of these endpoints are in the spectrum. So the proof of this is just kind of a trick of using what we've done already. So first note that, again, since the absolute value of Au inner product u is always less than or equal to the norm of A for all unit vectors, this implies that this quantity here is always bounded below by norm of A and bounded above by norm of A. And therefore, the infimum of this is always bounded from. So this is a lower bound for this quantity here. So this infimum is bigger than it, since it's the greatest lower bound. And the least upper bound of these quantities is always less than or equal to the norm of A. So these are actual numbers for 1. Now, by the definition of A plus or minus, there exists sequences of unit vectors u n plus or minus, such that A applied to u n plus or minus inner product u n plus or minus converges to A plus or minus. Now, by the argument we just gave with A plus or minus being the norm of A, but now we have this property, i.e. A minus A plus or minus applied to u n plus or minus u n plus or minus converges to 0. Since I have this property by the previous argument I gave, this implies that both A plus and A minus are in the spectrum of A. Since we have, for each choice of plus or minus, a sequence of unit vectors, so that this quantity here goes to 0. A minute ago, we could just assert that there was a sequence of unit vectors. So for at least one choice of plus or minus the norm of A, we had this thing going to 0. But for these two numbers, because it's the inf and because this is the sup, we can always find unit vectors so that this quantity is converging to the sup, which is A plus. This quantity is converging to the inf, which is A minus. So by the previous argument, we get that both A plus or minus are in the spectrum of A. Before, again, I just want to emphasize, before we could just say that one of the norms of A, or at least one choice of plus or minus the norm of A is in the spectrum. Here we're saying both of these numbers are in the spectrum. So now what remains is to show that the spectrum is, in fact, contained in this interval from A minus to A plus. All right, so let B be their midpoint. And B equals A minus B times I. Now, B is a real number. Because those are two real numbers. So capital B is the difference between A and is A minus a real number times the identity. So B is self-adjoint, and a bounded linear operator on H. So by the previous theorem, we get that the spectrum of B is contained in the norm of B. So minus norm of B, norm of B. And it shouldn't take much thought to realize that if the spectrum of B, which is a shift of A by little b, is contained in this interval, then the spec of A is contained in minus norm of B plus little b, norm of B plus B. So now what's left is to compute the norm of B. But this is not too difficult. We have that the norm of B, this is equal to sup of u equals 1 du applied to u. And now I take the sup over all u equals 1. And let me plug in what A is and B is. And this is A u u minus A plus minus A plus minus A minus over 2. OK? Now here's a picture. Here's A minus. Here's A plus. A plus is the sup over all of these expressions where u has unit length. A minus is the imp over all these expressions where u has unit length. A plus plus A minus is the point right in the middle of them. So what's the biggest this or what's the supremum of the difference between these numbers and the midpoint? Well, it's the distance given by the distance from A plus to the midpoint, which is equal to the distance from A minus to the midpoint, which is A plus minus A minus over 2. OK? And since that's the norm of B, when we plug that into what we had a minute ago, we conclude that the spectrum is contained in A minus A plus. So as a simple corollary of what we've done, we have this nice little statement about when exactly a self-adjoint bounded linear operator is non-negative. So let A be a self-adjoint bounded linear operator on the Hilbert space. Then for all u, Au inner product u is bigger than or equal to 0 if and only if the spectrum of A is contained in the non-negative numbers. So I'm not even going to write out the proof. I'm just going to talk my way through it. So let's suppose that Au inner product u is non-negative. Then this number A minus is non-negative. And therefore, the spectrum is contained in A minus A plus, which is a subset of the non-negative real numbers. OK? On the other hand, suppose that the spectrum of A is contained in here. Then A minus, which is in the spectrum, has to be in the set of non-negative real numbers. And therefore, Au inner product u always has to be non-negative since A minus is the mth over all of these. So now we're going to move on to the spectral theory for not just self-adjoint operators, but self-adjoint operators that are also compact. Again, a natural example is given by the inverse of taking the second derivative along with requiring 0 at the endpoints, this operator I gave last time. That is a bounded self-adjoint or a compact self-adjoint operator. So all the spectral theory we developed for that applies. And the spectrum for that operator ends up being 1 over the eigenvalues corresponding to u double prime equals say mu times u with 0 at the endpoint. And you'll see that in the assignment, or maybe I'll do it as an example. So now we're moving on to spectral theory for compact self-adjoint operators, which is one of the most, again, complete things or class of operators we can say the most about when it comes to the spectrum. And I'll go ahead and give you a preview of what we can say about the spectrum for these operators, that it essentially consists of nothing but eigenvalues with the possible exception of 0 being an accumulation point of the eigenvalues. So what we'll prove is that the spectrum of a compact self- adjoint operator consists of the eigenvalues of this operator along with possibly 0. And 0 may or may not be an eigenvalue. If it's not an eigenvalue, then it's the limit of the eigenvalues. And in fact, so kind of implicit in that statement is that the spectrum is in fact accountable for a compact self-adjoint operator. So why should we expect that? Or why should we expect such a complete picture? In the end, we'll also prove that you can find a basis for H consisting entirely of eigenvectors of the operator A, which is again a generalization to infinite dimensions of what hopefully you saw in finite dimensions. But if you didn't, our proof will still apply to finite dimensions. So why should that then apply to compact self-adjoint operators if you believe it for finite dimensions? Well, it's because again, compact self-adjoint operators are the norm limit of finite rank operators. And finite rank operators, again, these just correspond to basically matrices. We know how to compute the eigenvalues of matrices. For finite rank operators, they could have a very large null space, meaning the eigenvalue 0 could have a very large eigenspace. But that's the point of kind of why you expect maybe things to carry over to the setting of compact self-adjoint operators from what you know in finite dimensions. OK. So this is not so much a definition as just notation. If A is a bounded linear operator, I will denote E lambda to be null space of A minus lambda. In other words, the set of or the subspace of eigenvectors with eigenvalue lambda, which again is the set of u and h such that A minus lambda u equals 0. All right. So first off, before we get to classifying the spectral or the spectrum of a compact self-adjoint operator as basically consisting of eigenvalues along with 0, we'll first give some kind of general properties of eigenvalues in general about for a compact self-adjoint operator. So we have the following theorem that suppose A star A. So is a compact self-adjoint operator. Then a few things. If lambda not equal to 0 is an eigenvalue of A, then the dimension of E lambda, the eigenspace, the linear subspace of all vectors that are eigenvectors of A, this is finite. So for a given eigenvalue, the dimension of the eigenspace is finite. The second is that if I take two different eigenvalues, the corresponding eigenspaces are perpendicular to each other. Lambda 1 does not equal lambda 2. If eigenvalues of A, then E lambda 1, E lambda 2 are orthogonal or perpendicular. Every element in E lambda 1 is orthogonal to every element in E lambda 2 and vice versa. And finally, set of non-zero eigenvalues of A is either finite or countable. If it is countable, i.e. it's given by a sequence lambda n, then these are, if it is countably infinite, I should say. And I should have said countably infinite here. So if it's countably infinite, then the eigenvalues converge to 0. In particular, this implies that if I have a compact self-adjoint operator with infinitely many eigenvalues, then 0 is in the spectrum of this operator. Because the spectrum is a closed set, so it's closed under taking limits. And since these are in the spectrum, the limit has to be in the spectrum. OK? All right. So proof of 1. Suppose I have a non-zero eigenvalue, and towards the contradiction, E lambda is not finite dimensional. Then what I can do by the Gram-Schmidt process, then there exists a sequence or a countable collection, u n, over the normal elements in E lambda. So every element in the sequence has unit length, and it's orthogonal to any other element in the sequence. Now, since A is a compact operator, and all of these have unit length, it follows that A applied to u n is contained. This is a sequence in a compact set, so it has a convergent subsequence. Subsequence A u n j j. OK? OK. OK. Then A u n j is Cauchy, but let's actually look at what's the difference between two of these and norm. Let's make it squared. This is equal to norm of, because these are eigenvalues, lambda u n j minus lambda u n k squared, which equals 2 lambda squared, which is a fixed number that's positive, because lambda is not equal to 0. Let's see. Oh, I left off a part of the. So OK, so what does this imply? This implies that the distance between any, so this is, if I take any two elements in this subsequence, their distance is a constant equal to 2 times lambda squared. And therefore, this is not Cauchy, which is a contradiction. OK? Something I forgot to say in the statement of the theorem, forgive me, it's the end of a long day, is that eigenvalues have to be real for self-adjoint compact operators, or really for self-adjoint operators. I could have included it earlier. So the eigenvalues of a self-adjoint operator have to be real. Why is that? Well, since if I have something with norm 1, so if lambda is an eigenvalue, it comes with an eigenvector u with length 1, so that Au equals lambda u. Of course, it just has to be a non-zero u, but I can normalize it by dividing by its length. And therefore, I get that lambda, which is equal to lambda u inner product u. This is norm of u squared, which is 1. Lambda u, u. And this is equal to complex conjugate, or let's not do that. So this is equal to Au u, which is equal to, I take a, and it becomes a star u, but a star is equal to a, so I get U Au, since a is self-adjoint. And this is equal to u lambda u. And remember, inner products are conjugate linear in the second entry. So this lambda pops out, but now complex conjugate. So lambda. So we've shown that the complex conjugate is equal to the original number, so lambda has to be a real number. All right. So that proves part one, that the eigenvalues of a self-adjoint operator have to be real, and the eigenspaces of, which is what I have just started calling the E lambdas, the eigenspace, have to be finite dimensional for a compact self-adjoint operator. OK. So now let's show that distinct eigenspaces have to be orthogonal to each other. Suppose lambda 1 does not equal lambda 2. U1 is in E lambda 1, U2 is in E lambda 2. So now what I'd like to show is that the inner product of U1 with U2 is equal to 0. And it's going to be a trick kind of like I just did here. Lambda 1 times U1, U2, this is equal to lambda 1 U1, U2. This is equal to A applied to U1, U2. And now I move A over to here because A is self-adjoint. All right. And A applied to U2. So U2 is in the second eigenspace. So this is equal to U1 lambda 2 U2. And because lambda 1 and lambda 2 have to be real numbers, what we've done from the first part, this lambda 2 comes all the way out and remains itself. No complex conjugate because it's equal to its complex conjugate. And so I started off with lambda 1 times the inner product of U1, U2. And I've ended up with lambda 2 U1 inner product with U2. And therefore, lambda 1 minus lambda 2 times inner product of U1 minus or the inner product of U1 with U2 equals 0. And lambda 1, remember we're assuming lambda 1 and lambda 2 are non-zero or not equal. So this quantity here is non-zero. So I get that U1 U2 equals 0. And that's the, nope, that's not the end. That's the end of number 2, but not the end of the proof of this theorem. All right. So we're going to prove the last thing that the set of non-zero eigenvalues is either finite or countable. And that if I arrange them in a sequence, then the sequence converges to 0. OK. So just to have some notation running around capital lambda, let me let this denote those non-zero eigenvalues. All right. So what I'd like to claim, what I'm going to show is that if lambda n is a sequence of distinct elements or distinct eigenvalues, non-zero eigenvalues of A, then these converge to 0. OK. So this gives us, so of course, OK. So the set of non-zero eigenvalues may be finite. Fine. Suppose it's not. OK. Now we're just in the setting that A has infinitely many eigenvalues. If I can prove this claim, then I have proven two things at once. I have proven both that the set of non-zero eigenvalues is countably infinite, assuming it's infinite, and they converge to 0. So why does this? So first off, if we can show that this capital lambda is countable, then this claim then implies that we're countably infinite. Then this claim tells me that the eigenvalues converge to 0, which is the last thing I want. So all I really need to show is that this is countable using this claim. Now, why does this show that capital lambda is countable? Since then, if I define lambda sub capital N to be the set of non-zero eigenvalues, which are, let's say, even bigger than or equal to 1 over N, this has to be a finite set. If it was infinite, then I could find a sequence of distinct elements in here and obtain, or I should say, then I can find a subsequent or, hold on. Let me stop for a minute. So my claim is that this is finite for all N, which implies that lambda, which is the union of, is countable. OK, so assuming this claim, or assuming what I wrote here, that this is finite for all N, this implies this is countable, that's clear. So why do I get this is finite, this set is finite, assuming this claim? Well, if this set is infinite, then I can pick out a sequence of distinct elements in lambda sub N that converges. I could just take any sequence and then take a convergent subsequence because that sequence has to be bounded between 1 over N and the norm of A. But since they're all bigger than or equal to 1 over N, that sequence has to converge to something that's non-zero. But that would contradict the claim. Again, assuming the claim is true, we haven't proved it yet. So again, from this claim, we can then conclude that each of these sets is finite for all N. And therefore, the set of non-zero eigenvalues is countable. And if it's countably infinite, then again, from this claim, we conclude that the eigenvalues must converge to 0 when I line them up in a sequence. So the whole proof is reduced to just proving this claim. OK. So to prove the claim, let un be associated eigenvectors. So these have unit lengths. And for all n, A un equals lambda n un. We have eigenvalues, so we can find eigenvectors with unit length. Now, then lambda n, which is equal to or the absolute value of lambda n is equal to the absolute value of lambda n or the norm of lambda n applied to times un, which is equal to the norm of A applied to un. So what I'm going to show is that A applied to un converges to 0. So if you like, this is the final claim that I need to prove. So this is claim 1. Claim 1 will follow from claim 2. And this little computation right here or claim 2 is that the norm of A applied to un, again, un's are eigenvectors with unit length corresponding to the lambda n's converges to 0. So the fact that A applied to these unit vectors converges to 0 is not just specific to eigenvectors of distinct eigenvalues. It's just a property of the compactness of A and the fact that the un's are an orthonormal sequence. They're all unit length, and any one element in the sequence is orthogonal to a different element in the sequence. So suppose not. Suppose claim 2 does not hold. Then just negating the definition of convergence, there exists an epsilon positive. And we can find a subsequence A, u, and j such that for all j, length of A, u, and j is bigger than or equal to epsilon 0. If you look at the definition of convergence to 0 and then negate that, you can conclude that you can find a subsequence so that I have this. So there exists some bad epsilon 0 so that I have that. Since A is a compact operator, there exists a further subsequence. And let me call it E sub k, which is u n sub j sub k, u nj, such that, so remember, A applied to u n sub j. So u n sub j is a unit length vector, and therefore, A applied to that is contained in a compact set, assuming A is a compact operator. So this must have a convergent subsequence such that A applied to EK converges in H. And note, a EK, since this is just a subsequence of this sequence, is bigger than or equal to epsilon 0 for all k. Now, since the EKs are a subsequence of an orthonormal sequence, it's still an orthonormal sequence. So note, for all k not equal to l, inner product EK, EL, which is u nk, u nl equals 0. And what I'm using here, so of course, these are all unit vectors. Why are they orthogonal? It's because they correspond to distinct eigenvalues, distinct non-zero eigenvalues. And we proved that that was number two, that, was it number two? Yeah, that eigenvectors for distinct eigenvalues are orthogonal to each other. So assuming the negation of the claim 2, which would prove claim 1 and finish the proof of this whole theorem, I conclude that there exists a sequence of eigenvectors, or orthonormal eigenvectors of A, so that AEK is always bounded below a norm by epsilon 0. And this sequence converges. So let F be the limit as k goes to infinity of AEK. Then norm of F by continuity of the norm is equal to the limit of the norms of the EKs. And all of these are above, bigger than or equal to, epsilon 0. So F is non-zero. Right? In fact, we could say a little bit more. Then, in fact, let's see. So this is kind of useless information. I skipped. And I didn't write down what I wanted to. But OK, then, well, no, I still need that. OK, no, let me not get rid of that. So that should still be there. So norm of F is bigger than or equal to epsilon 0. So norm of F squared is bigger than or equal to epsilon 0 squared. So F inner product F. And by continuity of the inner product, that's equal to, since the AEKs converge to F, I will get F here. And using the fact that A is self-adjoint, this is equal to EK Af. So I have that this limit here is non-negative. I mean, it's a real number. And it's bigger than or equal to epsilon 0 squared. Now, here's the problem. I have here a sequence of orthonormal vectors. And I know that the sum of squares of these Fourier coefficients, which are Fourier coefficients for A applied to F, this sum of squares is finite. And therefore, this has to go to 0. And that's the contradiction to the epsilon 0 squared. So by Bessel's inequality, we get that sum over k norm EK Af squared. This is less than or equal to the norm of Af squared, which is finite. And since this is a convergent series, the individual terms have to converge to 0. And therefore, this equals 0. But this and this are a contradiction. OK. So that finishes the proof of this theorem about the eigenvalues and eigenspaces for a compact self-adjoint operator. All right, so I think we'll stop there.