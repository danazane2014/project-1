 Το επόμενο πρόγραμμα είναι προσδοκημένο από ένα δίκαιο δικαίωμα Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει MIT OpenCourseWare να προσφέρει υψηλές ποινές ειδικές πιθανότητες ελεύθερα. Για να κάνετε μια διώξη ή να δείτε περισσότερα υλικά από χιλιάδες MIT σχολείων, επισκεφτείτε MIT OpenCourseWare στηn ocw.mit.edu. Σήμερα θα τελειώσουμε με το κορυφαίο υλικό αυτής της σχέσης, το υλικό που έχει να κάνει με την πιθανότητα θεωρίας γενικά. Και μετά για το υπόλοιπο τέλος του σχολείου θα δούμε μερικά ειδικά μοντέλα, θα μιλήσουμε για εφαρμογή. Απλώς θα έρθει και ένα μικρό μοντέλο υλικών υλικών μετά. Αλλά σήμερα βασικά τελειώνουμε το πέντεο κεφάλαιο. Και θα δούμε ένα λίγο γνωστό κίνημα, το κίνημα της συνθήκης ελπίδας. Αλλά θα το δούμε από ένα διαφορετικό, λίγο διαφορετικό άγγλο, από ένα λίγο πιο σοφιστικό άγγλο. Και μαζί με την υποθέσεις συνθήκης θα μιλήσουμε επίσης για συνθήκες εφαρμογές, κάτι που θα δημιουργήσουμε αυτόν τον τρόπο. Και θα δούμε τι είναι, και υπάρχουν μερικά λεπτομέρεια που εμπληκτοποιούνται εδώ. Και θα προσδοκήσουμε μερικά από τα εργαλεία που θα αντιμετωπίσουμε για να αντιμετωπίσουμε ένα ειδικό τύπο της κατάστασης στην οποία προσθέσουμε διεγόνια, αλλά προσθέσουμε ένα διεγόνιο τόπο διεγόνιων. Ωραία, ας ξεκινήσουμε να μιλήσουμε για συνθήκες συνθήκες. Νομίζω ότι ξέρετε τι είναι. Αντιμετωπίζουμε ότι είμαστε στον διεγόνιο κόσμο, X, Y είναι διεγόνιες διεγόνιες διεγόνιες, έχουμε κατεστημένο το συνθήκες συνθήκες X, διότι σας είπα ότι το αριθμό του διεγόνιου διεγόνιου Y, και την τρόπη που το κατεστημούμε είναι την ίδια τρόπη σαν μια συγκεκριμένη ελπίδα, εκτός από το γεγονός ότι χρησιμοποιούμε το συνθήκες πραγματικό πλήρους. Λοιπόν χρησιμοποιούμε τις δυνατότητες που προσφέρουν στο νέο κόσμο, όπου μας λένε το αριθμό του διεγόνιου διεγόνιου Y. Αυτό είναι ακόμα ένα γνωστό κίνημα μέχρι τώρα. Αν αντιμετωπίζουμε το συνεχόμενο διεγόνιο διεγόνιο X, η ορισμότητα είναι η ίδια, εκτός από το γεγονός ότι έχουμε έναν ειδικό, και πρέπει να χρησιμοποιούμε το συνθήκες πλήρους, το συνθήκες πληρούς συνθήκας X. OK. Τώρα, τι θα κάνω, θα ήθελα να το παρουσιάσω λεπτομένamente μέσω του παραδείγματος που μιλήσαμε την τελευταία φορά. Λοιπόν, την τελευταία φορά μιλήσαμε για μια σκοπόλα που έχει μια συγκεκριμένη διάσταση, και πάρουμε αυτή την σκόπολα και την χτυπάμε σε κάποιο σημείο που την επιλέξουμε συγκεκριμένη, σε δίκιο. Και ας δημιουργήσουμε Y, το μέρος που επιλέξαμε να την χτυπάμε. Έχοντας επιλέξει Y, τότε είμαστε αφιερωμένοι με ένα κομμάτι της σκόπης, και θα επιλέξω ένα μέρος για να την χτυπάμε μια άλλη φορά, συγκεκριμένη, σε δίκιο, μεταξύ 0 και Y. Λοιπόν, αυτό είναι το δεύτερο μέρος που θα την χτυπάμε, και θα το ονομάσουμε αυτό το μέρος X. Οκ. Λοιπόν, τι είναι η υποθέση κατά σύγκριση του X, αν σας πω το αριθμό Y. Σας πω ότι το Y συμβαίνει να πάρει μια συγκεκριμένη αριθμότητα. Λοιπόν, αυτό το Y είναι τώρα μια συγκεκριμένη αριθμότητα. X είναι επιλέξει σε μορφή σε αυτό το μέρος. Λοιπόν, το επιθυμμένο αριθμό X θα είναι μία πάντα από αυτό το μέρος, μεταξύ 0 και Y, οπότε η υποθέση κατά σύγκριση είναι λίγο Y πάνω από 2. Το σημαντικό πράγμα να καταλάβετε εδώ είναι ότι αυτή η ποσότητα είναι ένα νούμερο. Σας είπα ότι η αριθμότητα του ρανδιού έκανε μια συγκεκριμένη αριθμότητα, ας πούμε 3.5, και τότε μου πείτε ότι, δεδομένου ότι η αριθμότητα του ρανδιού έκανε την αριθμότητα 3.5, η περιμένωτη αριθμότητα του X είναι 1.75. Λοιπόν, αυτό είναι μια αριθμότητα μεταξύ νούμερων. Στην άλλη, πριν κάνετε το εξετάσιο, δεν ξέρετε τι θα γίνει το Y. Αυτό το λίγο Y είναι το νομιμερικό αριθμό που έχει εξετάσει όταν ξεκινάτε το εξετάσιο και εξετάσετε το αριθμό του Y. Λοιπόν, σε κάποιο σημείο, αυτή η ποσότητα δεν είναι γνωστή πριν από χρόνο, είναι ο ίδιος το ρανδι, οπότε ίσως μπορούμε να ξεκινήσουμε να το σκεφτούμε ως ένας ρανδιός αριθμός. Λοιπόν, για να το βάλω διαφορετικά, πριν κάνουμε το εξετάσιο, σας ρωτώ, τι είναι το προσδοκικό αριθμό του X δεδομένου Y? Θα μου απαντήσετε, όμως, δεν ξέρω, αφορά τι Y θα γίνει. Λοιπόν, το προσδοκικό αριθμό του X δεδομένου Y μπορεί να είναι διεγραφημένο ως ένας ρανδιός αριθμός επειδή αφορά το ρανδιό αριθμό Y. Λοιπόν, κρυφτεί εδώ κάποια είδη για ρανδιό αριθμό αντί για τις τετραγωγίες. Αυτή η είδη για ρανδιό αριθμό, την γράφουμε αυτόν τον τρόπο, σκεφτώντας το προσδοκικό αριθμό, την προσδοκική ελπίδα, ως ρανδιό αριθμό αντί για ένα τετραγωγίο. Είναι ρανδιό αριθμό όταν δεν καταγραφούμε ένα συγκεκριμένο τετραγωγίο, αλλά το σκεφτούμε ως ένας διεγραφημένος οδηγίας. Το προσδοκικό αριθμό X, δεδομένο από το ρανδιό αριθμό Y, είναι το ρανδιό αριθμό Y πάνω από 2, από ό,τι δεν πεινάει το Y. Προσπαθούμε να πάρουμε ένα δημοσίο που αντιμετωπίζει την αριθμό των δύο αριθμών, και το κάνουμε ένα δημοσίο που είναι μια αριθμό μεταξύ δύο ρανδιών αριθμών. Αυτό είναι σαφώς ένα ρανδιό αριθμό, γιατί το Y είναι ρανδιό. Ποιο ακριβώς είναι αυτό το σώμα? Δεν το έχω ακριβώς οριζόμενο για εσάς. Ας δώσουμε τώρα την οριζόμενη κατεστημία αυτού του σώματος, που θα δημιουργηθεί αυτόν τον τρόπο. Το προσδοκικό αριθμό X, δεδομένο από το ρανδιό αριθμό Y, είναι ένα ρανδιό αριθμό. Ποιο ρανδιό αριθμό είναι αυτό? Είναι το ρανδιό αριθμό που πάρει αυτό το συγκεκριμένο αριθμό, όταν Y συμβαίνει να πάρει το συγκεκριμένο αριθμό, y. Συγκεκριμένamente, αυτό είναι ένα ρανδιό αριθμό, που είναι μια λειτουργία του ρανδιού αριθμού Y. Σε αυτό το σώμα, είναι δίνει από μια απλή οριθμό, με τρόπο του Y. Σε άλλες κατάστασεις, μπορεί να είναι μια πιο δύσκολη οριθμό. Λοιπόν, ξανά, για να συγκεκριμένω, είναι ένα ρανδιό, η κατασκευή εξετάσεων μπορεί να είναι σκεφτεί ως ένα ρανδιό αριθμό, αντί κάτι που είναι μόνο ένα νούμερο. Λοιπόν, σε κάθε συγκεκριμένο σύστημα, όταν είσαι δίνει το αριθμό Y, η κατασκευή εξετάσεων γίνεται ένα νούμερο. Αυτό είναι το αριθμό που κατασκευή εξετάσεων δείχνει. Αλλά πριν το εξετάσεις ξεκινήσει, πριν ξέρετε τι θα είναι Y, όλα που μπορείτε να πείτε είναι ότι η κατασκευή εξετάσεων θα είναι 1.5 από κάθε πράγμα που γίνεται Y. Αυτό είναι ένα αρκετό λεπτό κίνημα, αλλά είναι μια αρνητική αρνητική. Και θα δούμε σήμερα πώς να το χρησιμοποιήσουμε. Βεβαίως, έχω φτιάξει το σημείο ότι η κατασκευή εξετάσεων, η ρανδιό αριθμό που πάρει αυτές τις νομιματικές αξίες, είναι ένα ρανδιό αριθμό. Αν είναι ένα ρανδιό αριθμό, αυτό σημαίνει ότι έχει μια εξετάσεις της ίδιας. Λοιπόν, ας ξεκινήσουμε να σκεφτούμε τι η εξετάσεις της κατασκευής εξετάσεων θα γίνει. OK. Η κατασκευή εξετάσεων είναι μια ρανδιό αριθμό, και, γενικά, είναι κάποια λειτουργία της ρανδιό αριθμός Y που βλέπουμε. Σε περίπτωση νομιματικών αξίων, αν ο Y συμβαίνει να λυ wydaje μια ακριβής νομιματική αξία, τότε η διασκευή εκselves βλέπει μια ακριβή νομιματική αξία, και θα χρειαστούμε και αυτή η ε triggered εφαρμογή. Η διαφορά εδώ είναι ότι αυτό είναι μια καινούρια συμ 分τεαίων, αυτό είναι μια διασκευή μεταξύ  Adriα. Τώρα, αν θέλουμε να έχει απο�ψιλμadt την αλλάξεια αξίας της Syndication's παραγωγής, που συμβαίνει π religion από την αλάξηokι την αλλάξια of a random variable. And we know how to calculate expected values of a function if we are in the discrete case, for example. This would be a sum over all y's of the function whose expected value we're taking times the probability that y takes on a specific numerical value. OK, but let's remember what g is. So g is the numerical value of the conditional expectation of x and y. And now when you see this expression, you recognize it. This is the expression that we get in the total expectation theorem. Yes, in the total expectation theorem, to find the expected value of x, we divide the world into different scenarios depending on what y happens. We calculate the expectation in each one of the possible worlds, and we take the weighted average. So this is a formula that you have seen before, and you recognize that this is the expected value of x. So this is a sort of a longer, more detailed derivation of what I had written up here. But the important thing to keep in mind is the moral of the story, the punchline. The expected value of the conditional expectation is the expectation itself. So this is just our total expectation theorem, but written in more abstract notation. And it comes handy to have this more abstract notation, as we're going to see in a while. OK, we can apply this to our stick example. If we want to find the expected value of x, how much of the stick is left at the end? We can calculate it using this law of iterated expectations. It's the expected value of x. It's the iterated expectations, it's the expected value of the conditional expectation. We know that the conditional expectation is y over 2. So the expected value of y is l over 2, because y is uniform. So we get l over 4. So this gives us the same answer that we derived last time in a rather long way. All right. Now that we have mastered conditional expectations, let's raise the bar a little more and talk about conditional variances. So the conditional expectation is the mean value, or the expected value, in a conditional universe where you're told the value of y. In that same conditional universe, you can talk about the conditional distribution of x, which has a mean, the conditional expectation. But the conditional distribution of x also has a variance. So we can talk about the variance of x in that conditional universe. The conditional variance, as a number, is the natural thing. It's the variance of x, except that all the calculations are done in the conditional universe. In the conditional universe, the expected value of x is the conditional expectation. This is the distance from the mean in the conditional universe squared. And we take the average value of the squared distance, but calculate it again using the probabilities that apply in the conditional universe. This is an equality between numbers. I tell you the value of y. Once you know that value for y, you can go ahead and plot the conditional distribution of x. And for that conditional distribution, you can calculate the number, which is the variance of x in that conditional universe. So now let's repeat the mental gymnastics from the previous slide, and abstract things, and define a random variable, the conditional variance. And it's going to be a random variable because we leave the numerical value of capital Y unspecified. So ahead of time, we don't know what capital Y is going to be, and because of that, we don't know ahead of time what the conditional variance is going to be. So before the experiment starts, if I ask you, what's the conditional variance of x, you're going to tell me, well, I don't know. It depends on what Y is going to turn out to be. It's going to be something that depends on Y. So it's a random variable, which is a function of Y. So more precisely, the conditional variance, when written in this notation just with capital letters, is a random variable. It's a random variable whose value is completely determined once you learn the value of capital Y. And it takes a specific numerical value. If capital Y happens to get a realization that's a specific number, then the variance also becomes a specific number, and it's just the conditional variance of y of x in that universe. OK, so let's continue what we did in the previous slide. We had the law of iterated expectations that told us that the expected value of a conditional expectation is the unconditional expectation. Is there a similar rule that might apply in this context? So you might guess that the variance of x could be found by taking the expected value of the conditional variance. It turns out that this is not true. There is a formula for the variance in terms of conditional quantities. But the formula is a little more complicated. It involves two terms instead of one. So we're going to sort of go quickly through the derivation of this formula. And then through examples, we'll try to get some interpretation of what the different terms here correspond to. All right, so let's try to prove this formula. And the proof is sort of a useful exercise to make sure you understand all the symbols that are involved in here. So the proof is not difficult. It's 4 and 1 1 lines of algebra of just writing down formulas, but the challenge is to make sure that at each point you understand what each one of the objects is. So we want the formula for the variance of x. We know in general that the variance of x has this nice expression that we often use to calculate it, expected value of the squared of the random variable minus the mean squared. This formula for the variances, of course, it should apply to conditional universes. I mean, it's a general formula about variances. If we put ourselves in a conditional universe where the random variable Y is given to us, the same math should work. So we should have a similar formula for the conditional variances. It's just the same formula, but applied to the conditional universe. The variance of x in the conditional universe is the expected value of x squared in the conditional universe minus the mean of x in the conditional universe squared. So this formula looks fine. Now let's take expected values of both sides. Remember, the conditional variance is a random variable because its value depends on whatever realization we get for capital Y. So we can take expectations here. We get the expected value of the variance. Then we have the expected value of a conditional expectation. Here we use the fact that we discussed before. The expected value of a conditional expectation is the same as the unconditional expectation. So this term becomes this. And finally here, we just have some weird-looking random variable, and we take the expected value of it. All right. Now we need to do something about this term. Let's use the same rule up here to write down this variance. So variance of an expectation, that's kind of strange, but you remember that the conditional expectation is random because Y is random. So this thing is a random variable. So this thing has a variance. What is the variance of this thing? It's the expected value of the thing squared minus the square of the expected value of the thing. Now what's the expected value of that thing? By the law of iterated expectations once more, the expected value of this thing is the unconditional expectation. And that's why here I put the unconditional expectation. So I'm using, again, this general rule about how to calculate variances. And I'm applying it to calculate the variance of the conditional expectation. And now you notice that if you add these two expressions, c and d, we get this plus that, which is this, is equal to these two terms cancel. We're left with this minus that, which is the variance of X. And that's the end of the proof. This is one of those proofs that do not convey any intuition. There are these, as I said, it's a useful proof to go through just to make sure you understand all the symbols. It starts to get pretty confusing and a little bit on the abstract side. So it's good to understand what's going on. Now there is intuition behind this formula, some of which is better left for later in the class when we talk about inference. The idea is that one can interpret the conditional expectation, you can interpret it as an estimate of the random variable that you are trying to, an estimate of X based on measurements of Y. You can think of these variances as having something to do with an estimation error. And once you start thinking in those terms, an interpretation will come about. But again, as I said, this is better left for when we start talking about inference. Nevertheless, we're going to get some intuition about all these formulas by considering a baby example where we're going to apply the law of iterated expectations and the law of total variance. So the baby example is that we do this beautiful experiment of giving a quiz to a class consisting of many sections. And we're interested in two random variables. So we have a number of students, and they're all allocated to sections. The experiment is that I pick a student at random, and I look at two random variables. One is the quiz score of the randomly selected student, and the other random variable is the section number of the student that I have selected. We're given some statistics about the two sections. Section one has 10 students, section two has 20 students. The quiz average in section one was 90, quiz average in section two was 60. What's the expected value of X? What's the expected quiz score if I pick a student at random? Well, each student has the same probability of being selected. I'm making that assumption out of the 30 students. I need to add the quiz scores of all the students. So I need to add the quiz scores in section one, which is 90 times 10. I need to add the quiz scores in that section, which is 60 times 20, and we find that the overall average was 70. So this is the usual unconditional expectation. Let's look at the conditional expectation, and let's look at the elementary version, where we're talking about numerical values. If I tell you that the randomly selected student was in section one, what's the expected value of the quiz score of that student? Well, it's given this information, we're picking a random student uniformly from that section in which the average was 90, the expected value of the score of that student is going to be 90. So given the specific value of Y, the specific section, the conditional expectation, or the expected value of the quiz score, is a specific number, the number 90. Similarly for the second section, the expected value is 60, that's the average score in the second section. This is the elementary version. What about the abstract version? In the abstract version, the conditional expectation is a random variable, because it depends in which section is the student that I picked. And with probability 1 third, I'm going to pick a student in the first section, in which case the conditional expectation will be 90. And with probability 2 thirds, I'm going to pick a student in the second section, and in that case the conditional expectation will take the value of 60. So this illustrates the idea that the conditional expectation is a random variable. Depending on what Y is going to be, the conditional expectation is going to be one or the other value with certain probabilities. Now that we have the distribution of the conditional expectation, we can calculate the expected value of it. And the expected value of such a random variable is 1 third times 90 plus 2 thirds times 60, and comes out equal to 70, which miraculously is the same number that we got up there. So this tells you that you can calculate the overall average in a large class by taking the averages in each one of the sections, and weighing each one of the sections according to the number of students that it has. So this section had 90 students, but only 1 third of the students, so it gets a weight of 1 third. So the law of iterated expectations, once more, is nothing too complicated. It's just that you can calculate overall class average by looking at the section averages and combine them. Now since the conditional expectation is a random variable, of course it has a variance of its own. So let's calculate the variance. How do we calculate variances? We look at all the possible numerical values of this random variable, which are 90 and 60. We look at the difference of those possible numerical values from the mean of this random variable. And the mean of that random variable, we found that it's 70. And then we weigh the different possible numerical values according to their probabilities. So with probability 1 third, the conditional expectation is 90, which is 20 away from the mean. And we get this squared distance. With probability 2 thirds, the conditional expectation is 60, which is 10 away from the mean, has this squared distance, and gets weighed by 2 thirds, which is the probability of 60. So you do the numbers and you get the value for the variance equal to 200. All right, so now we want to move towards using that more complicated formula involving the conditional variances. So suppose someone goes and calculates the variance of the quiz scores inside each one of the sections. So someone gives us these two pieces of information. In section one, we take the differences from the mean in that section. And let's say that the variance turns out to be a number equal to 10. Similarly in the second section. So these are the variances of the quiz scores inside individual sections. The variance in one conditional universe, the variance in the other conditional universe. So if I pick a student in section one, and I don't tell you anything more about the student, what's the variance of the random score of that student? The variance is 10. I know why, but I don't know the student. So the score is still a random variable in that universe. It has a variance, and that's the variance. Similarly in the other universe, the variance of the quiz scores is this number 20. Once more, this is an equality between numbers. I have fixed the specific value of y, so I put myself in a specific universe. I can calculate the variance in that specific universe. If I don't specify a numerical value for capital Y and say I don't know what Y is going to be, it's going to be random, then what kind of variance, what kind of section variance I'm going to get itself will be random. With probability 1 third, I pick a student in the first section, in which case the conditional variance, given what I have picked, is going to be 10. Or with probability 2 thirds, I pick y equal to 2, and I place myself in that universe. And in that universe, the conditional variance is 20. So you see again from here that the conditional variance is a random variable that takes different values with certain probabilities. And which value it takes depends on the realization of the random variable capital Y. So this happens if capital Y is 1, this happens if capital Y is equal to 2. Once you have something of this form, a random variable that takes values with certain probabilities, then you can certainly calculate the expected value of that random variable. Don't get intimidated by the fact that this random variable is something that's described by a string of 8 symbols, or 7, instead of just a single letter. Think of this whole string of symbols there as just being a random variable. You could call it Z, for example, use one letter. So Z is a random variable that takes these two values with these corresponding probabilities. So we can talk about the expected value of Z, which is going to be 1 third times 10, 2 thirds times 20, and we get a certain number from here. And now we have all the pieces to calculate the overall variance of X. The formula from the previous slide tells us this. Do we have all the pieces? The expected value of the variance, we just calculated it. The variance of the expected value, this was the last calculation in the previous slide. We did get a number for it. It was 200. You add the 2, you find the total variance. Now the useful piece of this exercise is to try to interpret these two numbers and see what they mean. The variance of X given Y for a specific Y is the variance inside section 1. This is the variance inside section 2. The expected value is some kind of average of the variances inside individual sections. So this term tells us something about the variability of the scores, how widely spread they are within individual sections. So we have, let's say, three sections. And the scores happen to be, OK, let's say the sections are really different. So here you have undergraduates, and here you have postdoctoral students. And these are the quiz scores. That's section 1, section 2, section 3. Here's the mean of the first section. And the variance has something to do with the spread. The variance in the second section has something to do with the spread, similarly with the third spread. And the expected value of the conditional variances is some weighted average of the three variances that we get from individual sections. So variability within sections definitely contributes something to the overall variability of the scores. But if you ask me about the variability over the entire class, there's a second effect that has to do with the fact that the different sections are very different from each other. That these scores here are much spread out. They're far away from those scores. And this term is the one that does the job. This one looks at the expected values inside each class, each section. And these expected values are this, this, and that. And asks the question, how widely spread are they? It asks how different from each other are the means inside individual sections. And in this picture, it would be a large number, because the different section means are quite different. So the story that this formula is telling us is that the overall variability of the quiz scores consists of two factors that can be quantified and added. One factor is how much variability is there inside individual sections. And the other factor is how different are the sections from each other. Both effects contribute to the overall variability of the scores. Let's continue with just one more numerical example, just to get the hang of doing these kind of calculations. And apply this formula to do a divide and conquer calculation of the variance of a random variable. Just for variety, now we're going to take a continuous random variable. Somebody gives you a PDF of this form, and they ask you for the variance. And you say, oh, that's too complicated. I don't want to do integrals. Can I divide and conquer? And you say, OK, let me do the following trick. Let me define a random variable Y, which takes the value 1 if X falls in here, and takes the value 2 if X falls in the second interval. And let me try to work in the conditional worlds, where things might be easier. And then add things up to get the overall variance. So I have defined Y this particular way. In this example, Y becomes a function of X. Y is completely determined by X. And I'm going to calculate the overall variance by trying to calculate all the terms that are involved here. So let's start calculating. First observation is that this event has probability 1 third, and this event has probability 2 thirds. The expected value of X, given that we are in this universe, is 1 half, because we have a uniform distribution from 0 to 1. Here we have a uniform distribution from 1 to 2, so the conditional expectation of X in that universe is 3 over 2. How about conditional variances? In the world where Y is equal to 1, X has a uniform distribution on a unit interval. What's the variance of X? By now you've probably seen that formula. It's 1 over 12. 1 over 12 is the variance of a uniform distribution over a unit interval. When Y is equal to 2, the variance is again 1 over 12, because in this instance, again, X has a uniform distribution over an interval of unit length. What's the overall expected value of X? The way you find the overall expected value is to consider the different numerical values of the conditional expectation, and weigh them according to their probabilities. So with probability 1 third, the conditional expectation is 1 half, and with probability 2 thirds, the conditional expectation is 3 over 2, and this turns out to be 7 over 6. How about the, OK, so this is the advance work we need to do. Now let's calculate a few things here. What's the variance of the expected value of X given Y? The expected value of X given Y is a random variable that takes these two values with these probabilities. So to find the variance, we consider the probability that the expected value takes the numerical value of 1 half minus the mean of the conditional expectation. What's the mean of the conditional expectation? It's the unconditional expectation. So it's 7 over 6. We just did that calculation. So I'm putting here the number 7 over 6 squared, and then there's a second term. With probability 2 thirds, the conditional expectation takes this value of 3 over 2, which is so much away from the mean, and we get this contribution. So this way we have calculated the variance of the conditional expectation. This is this term. What is this? Any guesses what this number is? It's 1 over 12. Why? The conditional variance just happened in this example to be 1 over 12 no matter what. So the conditional variance is a deterministic random variable that takes a constant value. So the expected value of this random variable is just 1 over 12, so we got the two pieces that we need, and so we do have the overall variance of the random variable X. OK, so this was just an academic example in order to get the hang of how to manipulate various quantities. Now let's use what we have learned and the tools that we have to do something a little more interesting. OK, so by now you're all in love with probability, so over the weekend you're going to bookstores to buy probability books. So you're going to visit a random number of bookstores, and at each one of the bookstores you are going to spend a random amount of money. So let n be the number of stores that you're visiting. So n is an integer, non-negative random variable, and perhaps you know the distribution of that random variable. Each time that you walk into a store, your mind is clear from whatever you did before, and you just buy a random number of books that has nothing to do with how many books you bought earlier on the day, has nothing to do with how many stores you're visiting, and so on. So each time you enter as a brand new person and buy a random number of books and spend a random amount of money. So what I'm saying, more precisely, is that I'm making the following assumptions. That for each store i, if you end up visiting the i-th store, the amount of money that you spend is a random variable that has a certain distribution. That distribution is the same for each store, and the Xi's from store to store are independent from each other. And furthermore, the Xi's are all independent of n. So how much I'm spending at the store once I get in has nothing to do with how many stores I'm visiting. So this is the setting that we're going to look at. Y is the total amount of money that you did spend. It's the sum of how much you spent in the stores, but the index goes up to capital N. And what's the twist here? It's that we're dealing with a sum of independent random variables, except that how many random variables we have is not given to us ahead of time, but it is chosen at random. So it's a sum of a random number of random variables. We would like to calculate some quantities that have to do with Y, in particular the expected value of Y or the variance of Y. How do we go about it? OK. We know something about the linearity of expectations, that the expectation of a sum is the sum of the expectations. But we have used that rule only in the case where it's the sum of a fixed number of random variables. So expected value of X plus Y plus Z is expectation of X plus expectation of Y plus expectation of Z. We know this for a fixed number of random variables. We don't know it or how it would work for the case of a random number. Well, if we know something about the case for fixed random variables, let's transport ourselves to a conditional universe where the number of random variables we're summing is fixed. So let's try to break the problem divide and conquer by conditioning on the different possible values of the number of bookstores that we're visiting. So let's work in the conditional universe, find the conditional expectation in this universe, and then use our law of iterated expectations to see what happens more generally. If I tell you that I visited exactly little n stores, where little n now is a number, let's say 10, then the amount of money you're spending is X1 plus X2 all the way up to X10, given that we visited 10 stores. So what I have done here is that I've replaced the capital N with little n. And I can do this because I'm now in the conditional universe where I know that capital N is little n. Now, little n is fixed. We have assumed that n is independent from the Xi's. So in this universe of a fixed n, this information here doesn't tell me anything new about the values of the X's. If you're conditioning on random variables that are independent from the random variables you're interested in, the conditioning has no effect, and so it can be dropped. So in this conditional universe where you visit exactly 10 stores, the expected amount of money you're spending is the expectation of the amount of money spent in 10 stores, which is the sum of the expected amounts of money in each store. Each one of these is the same number because the random variables have identical distributions. So it's n times the expected value of money you spend in a typical store. This is almost obvious without doing it formally. If I'm telling you that you're visiting 10 stores, what you expect to spend is 10 times the amount you expect to spend in each store individually. Now let's take this equality here and rewrite it in our abstract notation in terms of random variables. This is an equality between numbers. Expected value of Y given that you visit 10 stores is 10 times this particular number. Let's translate it into random variables. In random variable notation, the expected value of money you're spending given the number of stores, but without telling you a specific number, is whatever that number of stores turns out to be times the expected value of X. So this is a random variable that takes this as a numerical value whenever capital N happens to be equal to little n. This is a random variable which, by definition, takes this numerical value whenever capital N is equal to little n. So no matter what capital N happens to be, what specific value little n it takes, this is equal to that. Therefore, the value of this random variable is going to be equal to that random variable. So as random variables, these two random variables are equal to each other. And now we use the law of iterated expectations. Law of iterated expectations tells us that the overall expected value of Y is the expected value of the conditional expectation. We have a formula for the conditional expectation. It's n times expected value of X. Now the expected value of X is a number. Expected value of something random times a number is expected value of the random variable times the number itself. We can take a number outside the expectation. So expected value of X gets pulled out. And that's the conclusion, that the overall expected amount of money you're going to spend is equal to how many stores you expect to visit on the average and how much money you expect to spend on each one on the average. You might have guessed that this is the answer. If you expect to visit 10 stores and you expect to spend $100 on each store, then yes, you expect to spend $1,000 today. You're not going to impress your Harvard friends if you tell them that story. It's one of the cases where reasoning on the average does give you the plausible answer. But you will be able to impress your Harvard friends if you tell them that I can actually calculate the variance of how much I can spend. And we're going to work by applying this formula that we have. And the difficulty is basically sorting out all those terms here and what they mean. So let's start with this term. So the expected value of Y, given that you're visiting n stores, is n times the expected value of X. That's what we did in the previous slide. So this thing is a random variable. It has a variance. What is the variance? It's the variance of n times the expected value of X. Remember, expected value of X is a number. So we're dealing with the variance of n times a number. What happens when you multiply a random variable by a constant? The variance becomes the previous variance times the constant squared. So the variance of this is the variance of n times the square of that constant that we had here. So this tells us the variance of the expected value of Y, given n. This is the part of the variability of how much money you're spending, which is attributed to the randomness or the variability in the number of stores that you're visiting. So the interpretation of the two terms is there's randomness in how much you're going to spend. And this is attributed to the randomness in the number of stores, together with the randomness inside individual stores, after I tell you how many stores you're visiting. So now let's deal with this term, the variance inside individual stores. Let's take it slow. If I tell you that you're visiting exactly little n stores, then Y is how much money you spend in those little n stores. You're dealing with the sum of little n random variables. What is the variance of the sum of little n random variables? It's the sum of their variances. So each store contributes a variance of X, and you're adding over little n stores. That's the variance of money spent if I tell you the number of stores. Now let's translate this into notation, in random variable notation. This is a random variable that takes this numerical value whenever capital N is equal to little n. This is a random variable that takes this numerical value whenever capital N is equal to little n. This is equal to that, therefore these two are always equal, no matter what happens to Y. So we have an equality here between random variables. Now we take expectations of both. Expected value of the variance is expected value of this. OK, it may look confusing to think of the expected value of a variance here, but the variance of X is a number, not a random variable. You think of it as a constant. So its expected value of n times a constant gives us the expected value of n times the constant itself. So now we got the second term as well. And now we put everything together, this plus that, to get an expression for the overall variance of Y. Which again, as I said before, the overall variability in Y has to do with the variability of how much you spend inside the typical store, and the variability in the number of stores that you are visiting. OK, so this is it for today. We'll change subjects quite radically from next time.