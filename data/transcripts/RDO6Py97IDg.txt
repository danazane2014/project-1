 OK. Let's get started. So welcome to 18.217. So this is combinatorial theory, graph theory, and additive combinatorics. So the course website is up there. So all the course information is on there. So after around the middle of the class, I'll say a bit more about various course information administrative things. But I want to jump directly into the mathematical content. So this course roughly has two parts. The first part will look at graph theory, in particular, problems in extremal graph theory. And the second part will transition to additive combinatorics. But these are not two separate subjects. So I want to show you this topic in a way that connects these two areas and show you that they are quite related to each other. And many of the common themes that will come up in one part of the course will also show up in the other. So the story between graph theory and additive combinatorics began about 100 years ago with Schur, the famous mathematician Isaac Schur. Well, he was, like many mathematicians of his era, trying to prove Fermat's last theorem. And so here's what Schur's approach. He said, well, let's look at this equation that comes up in Fermat's last theorem. And, well, one of the methods of elementary number theory to rule out solutions to an equation is to consider what happens when you mod p. If you can rule out for infinitely many values p possible non-trivial solutions to this equation mod p, then you will rule out possibilities of solutions to Fermat's last theorem. So this was Schur's approach. As you can guess, unfortunately, this approach did not work. And Schur proved that this method definitely doesn't work. So that's the starting point of our discussion. So it turns out that for every value of n, there exists non-trivial solutions for all p sufficiently large, so thereby ruling out the strategy. So let's see how Schur proved his theorem. So that will be the first half of today's lecture. So this seems like a number theory question. So what does it have to do with graph theory? So I want to show you this connection. Now, Schur deduced his theorem from another result that is known as Schur's theorem, which says that if the positive integers is colored using finitely many colors, then there exists a monochromatic solution to the equation x plus y equals to z. If you give me 10 colors and color the positive integers using those 10 colors, then I can find for you a solution to this equation where x, y, and z are all of the same color. Now, this statement, so it's a perfectly understandable statement, but let me rephrase it in a somewhat different way. And this gets to a point that I want to discuss where many statements in additive combinatorics or just combinatorics in general have different formulations, one that comes in an infinitary form, which is more qualitative, so to speak, and another form that is known as finitary, and that's more quantitative in nature. So Schur's theorem is stated in an infinitary form. So it tells you if you color using finitely many colors, then there exists a monochromatic solution. So many, but not all, statements of that form have an equivalent finitary form that is sometimes more useful. And also, once you state the right finitary form, you can ask additional questions. So here's what Schur's theorem looks like in the equivalent finitary form. You give me an r for every r. There exists some n, function of r, such that if the numbers 1 through n, so throughout this course, I'm going to use this bracket n to denote integers up to n. So if these numbers are colored using r colors, then necessarily there exists a monochromatic solution to the equation x plus y equals to z, where x, y, and z are in the set that is being colored. So it looks very similar to the first version I stated, but now there are some more quantifiers. So for every r, there exists an n. So why are these two versions equivalent to each other? So it's not too hard to deduce their equivalence, but let me do that now. So the fact that the finitary version implies the infinitary version claim should be fairly obvious. So once you know the finitary version, if you give me a coloring of the positive integers, well, I just have to look far enough up to this n, and I get the conclusion I want. But now in the other direction, suppose I fix this r. So I assume the infinitary version. I want to deduce the finitary version. So I start with this r. And let's suppose the conclusion were false. So suppose the conclusion were false, namely, for every n, there exists some coloring. So for every n, there exists some coloring, which we will call phi sub n that avoids monochromatic solutions to x plus y equals to c. So I'm going to use this chi as a shorthand for monochromatic. So suppose there exists such a coloring. And now I want to take this collection of colorings and produce for you a coloring of the positive integers. And you can do this basically by a standard diagonalization trick, namely, we see that by taking an infinite subsequence such that, so let me call this infinite subsequence phi of phi sub, well, it's an infinite subsequence of this phi sub n, such that phi sub n of k stabilizes along the subsequence for every k. All right. All right. OK. OK. So you can do this simply by a diagonalization trick. And then you see that along the subsequence, phi n converges pointwise to some coloring of the entire set of positive integers. And this coloring avoids monochromatic solutions to x plus y equals to z. Because if there were monochromatic solutions in this coloring of the entire integers, then I can look back to where that came from. And that would have been a monochromatic solution in one of my phi n's. So this is an argument that shows the equivalence between the finitary form and the infinitary form. But now when we look at the finitary form, you can ask additional questions, such as, how big does this n have to be as a function of r? It turns out those kind of questions in general are very difficult. And we know some things. For this type of questions, we know some bounds usually. But the truth is usually unknown. And there are major open problems in combinatorics of this type. So there's still a lot that we do not understand. OK. So now we have Schur's theorem in this form. Let me show you how to deduce his conclusion about ruling out this approach to proving Fermat's law theorem. All right. So the claim is the following, that if you have a positive integer n, then for all sufficiently large primes p, there exists x, y, and z all belonging to numbers, integers up to p minus 1, such that their n-th powers add up like this. So it's a solution to Fermat's equation mod p. So how can we deduce this from what we said about coloring? So what is the coloring? So here's what Schur did. So proof, assuming for now Schur's theorem. So let's look at the multiplicative group of non-zero residues mod p. So this is a cyclic group, because there's a generator. So there's a primitive root generator. Let H denote the subgroup of n-th powers. OK. Well, H is a pretty big subgroup. So what's the index of H in this multiplicative group? It's at most n. So think about representing this as a cyclic group using the generator. So H, then, would be all the elements whose exponent is divisible by n. So this is the index is at most n. Could be smaller, but it's at most n. And so in particular, I can use the H cosets to partition the multiplicative group of non-zero residues. And this is a coloring. So a partition is the same thing as a coloring. There's a bounded number of colors, but I let p get large. So by Schur's theorem, if p is sufficiently large, then one of my cosets should contain a solution to x plus y equals to z. What does that look like? So then one coset, one H coset, contains x, y, z such that x plus y equals to z as integers. They belong to the same coset. So x, y, and z belong to some coset of H, which means, then, that x equals to a times some n-th power. Little y equals to a times some n-th power. And little z equals to a times some n-th power. You have this equation. Put them together. So that is true. So now mod p, I can cancel the a's. And this produces a non-trivial solution to Fermat's equation mod p. So this was the proof of this claim that this method does not work for solving Fermat's last theorem. But we assumed this claim of Schur's theorem that every finite coloring of the positive integers contains a monochromatic solution to x plus y equals z. So we still need to prove that claim. So we still need to prove this combinatorial claim. And so that's what we're going to do now. This is where graph theory comes in. So let me state a very similar-looking theorem about graphs. And this is known as Ramsey's theorem, although Ramsey's theorem actually historically came after Schur's theorem. But Ramsey's theorem here we're going to use specifically in the case for triangles. So what does this say? That if you give me an r, the number of colors, then there exists some large N such that if the edges of the complete graph, k sub n and vertices are colored using r colors, then there exists a monochromatic triangle somewhere. Any questions so far about any of these statements? So let's see how Ramsey's theorem for triangles is proved. By the way, I want to give you a historical note about Frank Ramsey. So he's someone who made significant contributions to many different areas, not just in mathematics. So he contributed to seminal works in mathematical logic, where this theorem came from, but also to philosophy and to economics before his untimely death at the age of 26 from liver-related problems. So he's someone who in his very short life contributed tremendously to academics. So let's see how Ramsey's theorem in this case is proved. We'll do induction on r, the number of colors. So for every r, I need to show you some N such that the statement is true. In the first case, when r equals to 1, there's not much to do. Just one color, if I just have three vertices, that already is OK. Three vertices, there's already a monochromatic triangle. So from now on, let r be at least 2. And suppose the claim holds for r minus 1 colors, with N prime being the corresponding number of vertices with r minus 1 colors. So now let me pick an arbitrary vertex. So pick an arbitrary vertex, v, and look what happens. So here's v. And let me look at the outgoing edges. So let me show that. So we'll show that N being r times N prime minus 1 plus 2 works. So now we have a lot of outgoing edges. In particular, we have r times N prime minus 1 plus 1 outgoing edges. So by the pigeonhole principle, some color, so there exists at least N prime outgoing edges with the same color. Let's say yellow. So suppose yellow is the outgoing color. And let me call the set of vertices on the other end of these edges v0. So now let's think about what happens in v0. So in v0, either v0 contains a yellow edge, in which case you get a yellow triangle. Or we lose a color inside v0. So the number of colors goes down. Else v0 has, at most, r minus 1 colors. And v0 has at least N prime number of vertices. So by induction, v0 has a monochromatic triangle in the remaining colors. So that completes the proof of Ramsey's theorem, in this case, for triangles. And if you wish to find out what is the bound that comes out of this argument, well, you can chase the proof and get some doubt. The remaining question now is, what does this all have to do with Schur's theorem? So so far, we've talked about some number theory. We've talked about some graph theory and how to link these two things together. And I think this is a great example. It's a fairly simple example, which I'm about to show you, of how to link these two ideas together. And this connection we'll see many times in the rest of this course. Don't want to erase Schur's theorem. OK. Let me. All right. So let's prove Schur's theorem. OK. So let's start with a coloring. So let's start with a coloring of 1 through N. And I want to form a graph with colors on the edges that are somehow derived from this coloring on these integers. And here's what I'm going to do. So let's color the complete graph, color the edges of the complete graph on the vertex set, having N plus 1 vertices labeled by the integers up to, positive integers up to N plus 1. Well, by the Ramsey result we just proved, if N is large enough, then there exists a monochromatic triangle. So what does it look like? So here's the thing. Let me draw for you a monochromatic triangle. Suppose it. So I haven't told you what the coloring is yet. So the coloring is that I'm going to color the edge between i and j using the color derived by applying phi to the number j minus i, namely the length of that segment if I lay out all the vertices on the number line. So now I have an r-coloring of this complete graph. So Ramsey tells us that there exists a monochromatic triangle. The triangle sits on vertices i, j, and k. And the rule tells us that the colors are phi of k minus i, phi of j minus i, and phi of k minus j. So these three numbers, they have the same coloring. But look, if I set these numbers to be x, y, and z, so x being j minus i, for instance, then x plus y equals to z. And they all have the same color. So this monochromatic triangle gives us a monochromatic equation to x plus y equals to z, thereby concluding the proof of Schur's theorem. So this rounds out the discussion for now of, well, we started with some statement about number theory. And then we took this detour to graph theory, looking at Ramsey's theorem of monochromatic triangles, and then got back to number theory and proved the result that Schur did. So how does going to graphs help? So why was this advantageous? What do you guys think? Sorry, I claim that by going to graphs, we added some extra flexibility to what we can play with. For example, we started out with a problem where there were only n things being colored. And then we moved to graphs where about n choose 2, or n squared, objects are being colored. And then we did an induction argument. So remember, in the proof of Ramsey's theorem up there, there was an induction argument taking out vertices. And that argument doesn't make that much sense if you stayed within the numbers. Somehow, moving to graphs gave you that extra flexibility, allow you to do more things. And this is one of the advantages of moving from a problem about numbers to a problem about graphs. And we'll see this connection later on as well. Yeah? AUDIENCE 2 Are there better bounds known for the specific Schur's result about the nth power is non-t? Because the nth here would be pretty bad. YUFEI ZHAO So Ashwin asked, so what about bounds? So what do we know about bounds? So I don't know off the top of my head the answers to those questions. But in general, they're quite open. So there are exponential gaps between lower and upper bounds on our knowledge of what is the optimal n you can put in the theorem. Any more questions? So I think this is a good point for us to, so usually when I give 90-minute lectures, I like to take a short two-minute break in between. So I want to do that. And then in the second half, I want to take you through a tour of additive combinatorics, so tell you about some of the modern developments. Now, this is an exciting field where it started out, I think, roughly with Schur's theorem that we just discussed. That started about 100 years ago. But a lot has taken place in the past century. And there's still a lot of ongoing, exciting research developments. So in the second half of this lecture, I want to give you a tour through those developments and show you some of the highlights from additive combinatorics. So let's take a quick two-minute break, and feel free to ask questions in the meantime. So another part of the writing assignment, in addition to course notes, is a contribution to Wikipedia, which is nowadays, of course, if you hear some words like Szemeredi's regularity lemma, the first thing you do is type into Google. And more often than not, the first link that comes up is Wikipedia. And some of the articles there are all right, and some of them are really not all right. And it would be fantastic for future students and also for yourselves if there were better entry points to this area by having higher quality Wikipedia articles or articles that are simply missing about specific topics. So one of the assignments, again, this can be collaborative, so I'll give you more information how to do that later, is to contribute to Wikipedia and roughly contribute one high-quality article or edit some existing articles so that they become high-quality. Yep? AUDIENCE 2 Do you do something similar to LMFDB with creating a website that has all the information needed in combinatorics? YUFEI ZHAO So we can talk about that. So if there are other ideas about how to do this, we can definitely open the chatting about that. So the other thing is that instead of holding the usual office hours, what I like to do is, OK, so this class ends at 4 PM. So after 4, I'll go up to the math common room, which is just right upstairs, and hang out there for a bit. If you have questions, you want to chat, come talk to me. I'd be happy to chat about anything related or not related to the course. And before homeworks are due, I will try to set up some special office hours for you to, in case you want to ask about homework problems. And if you want to meet with me individually, please just send me an email. One more thing about the course notes. So because I want to do quality control, so here is the process that will happen with the course notes. So the first lecture is already online, so you can already see. So I've written up the lecture notes for the first lecture. And you can use that as an example of what I'm looking for. So I'm looking for people to sign up starting from the next lecture, and I will send out a link tonight. For future lectures, so whoever writes that lecture, write the lecture. And then within one day, so by the end of the day after the lecture, it will be good if there were already at least some sketch, some rough draft, at least containing the theorem statements and whatnot from the day's lecture, so that the next person can start writing afterwards. But once you are done, once you feel that you have a polished version of the lecture, write up, ideally within four days of the lecture. So that's in terms of expectations and timelines. Again, all of this information is online. So you're finished with polishing your lecture notes within four days. Send me an email, so both co-authors, if there are two of you, and I will schedule a appointment, about half an hour, where I will sit down with you to go through what you've written and tell you some comments, so you can go back and polish it further. And hopefully, that will just be a one-round thing. If more rounds are needed, it's not ideal, but we'll make it happen until the notes are ready to use for future generations. Any questions about any of the course logistics? All right, so in the second half of today's lecture, I want to take you through a tour of modern additive combinatorics. And this is an area of research which I am actively involved in, and it's something that I'm quite excited about. And part of the reason why I teach this course is that this course is something that I developed a couple of years ago when I taught for the first time then, because I want to introduce you guys to this very active and exciting area of research. Now, what is additive combinatorics? The term itself is actually fairly new. So the word, the term additive combinatorics, I believe, was coined by Terry Tell back in the early 2000s as somewhat of a rebranding of an area that already existed, but then got a lot of exciting developments in the early 2000s. It's a deep and far-reaching subject with many connections to areas like graph theory, harmonic analysis, or Fourier analysis, ergodic theory, discrete geometry, logic, and model theory, and has many connections all over the place, and also has many deep theorems. So let me take you through a tour, historically, of, I think, some of the major milestones and landmarks in additive combinatorics. After Schur's theorem, which we discussed in the first half of today's lecture, the next big result, I would say, is Vanderwerden's theorem, which was 1927. Vanderwerden's theorem says that every coloring of the positive integers using finitely many colors contains arbitrarily long arithmetic progressions. So we'll see arithmetic progressions come up a lot. So from now on, we'll abbreviate this word by AP. AP stands for arithmetic progressions. So instead of Schur's theorem, where you just find a single solution to x plus y equals to z, so now we're finding a much bigger structure. Keep in mind, so a novice mistake people make is to confuse arbitrarily long arithmetic progressions with infinitely long. So these are definitely not the same. So you can think about, I'll leave it to you as an exercise, also a homework exercise, that you can color the integers with just two colors in a way that destroys all possible infinitely long monochromatic arithmetic progressions. So arbitrarily long is very different from infinitely long. So this was a great result, but it provokes more questions. So Erdos and Turán in the 30s, they asked, well, they conjectured that the true reason in Vanderwerden's theorem of having long arithmetic progressions, it's not so much that you're coloring. It's just because if you use finitely many colors, then one of the color classes must have fairly high density. So one of the classes use r colors, has density at least 1 over r. And they conjectured that every subset of the positive integers or the integers with positive density contains long, so arbitrarily long, arithmetic progressions. You may ask, what does it mean, density? So you can define density in many different ways. And it doesn't actually really matter that much which definition you use. Let me write down one definition. So you can define, given a subset of integers, the upper density, or rather, let me just say that it has positive upper density. So if when we take the lim sup as n goes to infinity, and look at, well, take a scaling window, and look at what fraction of that window is a, that this number, this limit sup, is positive. So that's one definition of positive density. There are many other definitions, sometimes known as Banach density, or you can take variations. But they're all, for the purpose of this discussion, they're all roughly equivalent. So let's not worry too much about which definition of density we use here. All right, so Erdos and Turán conjectured that the true reason for Van der Waals' theorem is that one of the color classes has positive density. And this turned out to be an amazingly impressive question, and that one had to wait several decades. So this conjecture was made in the 30s, 1936. So you had to wait several decades before finding out what the answer is. So in a foundational theorem in the subject, known as Roth's theorem, so Roth proved it in the 50s, I think, 53. So yeah, so Roth proved it, I think, 53, in the 50s, that k equals to 3 is true. So if I say that it contains k-term arithmetic progressions for every k, then Roth proved that every positive density subset contains a three-term arithmetic progression. And already, Roth introduced very important ideas that we will see in this course in two different forms. So in the first half of the course, we'll see a graph theoretic proof that was found later in the 70s of Roth's theorem. And then in the second half, we'll see Roth's original proof that used Fourier analysis. So Fourier analysis in number theory is also known as the Hardy-Littlewood circle method. It's a powerful method in analytic number theory. But there are very interesting new ideas introduced by Roth as well in developing this result. The full conjecture was settled by Szemeredi. It took another couple of decades. So in the late 70s, Szemeredi proved his landmark theorem that confirmed the Erdos-Turon conjecture. Szemeredi's theorem is a deep theorem. So this theorem is the proof, the original combinatorial proof is a tour de force. And you can look at the introduction of his paper, where there is an enormously complex diagram. So you can see this in the course notes, that lays out the logical dependencies of all the lemmas and propositions in his paper. And even if you assume every single statement is true, looking at that diagram, it's not immediately clear what is going on, because the logical dependencies are so involved. So this was a really complex proof. But not only that, Szemeredi's theorem actually motivated a lot of subsequent research. So later on, researchers from other areas came in and found also sophisticated proofs of Szemeredi's theorem from other areas and using other tools, including, and here are some of the most important perspectives, later perspectives of Szemeredi's theorem. So there was a proof using ergodic theory that followed fairly shortly after Szemeredi's original proof. This is due to Furstenberg. And initially, it wasn't clear, because all of these proofs were so involved. It wasn't clear if the ergodic theoretic proof was genuinely something new or it was a rephrasing of Szemeredi's combinatorial proof. But then very quickly, it was realized that there were extensions of Szemeredi's theorem, other combinatorial results that the ergodic theorists could establish using their methods, so using the same methods or extensions of the same methods that combinatorialists did not know how to do. And to this date, there are still theorems for which the only known proofs use ergodic theory, so extensions of Szemeredi's theorem. And I will mention one later on today. So that's one of the perspectives. The other perspective that was also quite influential is something known as higher-order Fourier analysis, which was pioneered by Tim Gowers in around 2000. So Gowers won a Fields Medal, partly for his work on Banach spaces, but also partly for this development. So higher-order Fourier analysis is, in some sense, an extension of Roth's theorem. So in other words, Roth also won a Fields Medal, although this is not his most famous theorem. I'll say his second most famous theorem. So Roth used this Fourier analysis, in the sense of Hardy and Littlewood, to control three-term arithmetic progressions. But it turns out that that method, for very good fundamental reasons, completely fails for four-term arithmetic progressions. So we'll see later in the course why that's the case, why it's that you cannot do Fourier analysis to control four-term APs. But Gowers managed to find a way to overcome that difficulty. And he came up with an extension, with a generalization of Fourier analysis, very powerful, very difficult to use, actually. But that allows you to understand longer arithmetic progressions. Another very influential approach is called hypergraph regularity. So the hypergraph regularity method was also discovered in the early 2000s, independently by a team led by Rodo and also by Gowers. So the hypergraph regularity method is an extension of what's known as Szemeredi's regularity, Szemeredi's graph regularity method. And this is the method that will be a central topic in the first half of this course. And it's a method that is quite central, or at least some of the ideas quite central, to Szemeredi's method. And he gave an alternative proof. He and Ruchat gave an alternative proof of Roth's theorem using graph theory. And for a long time, people realized that one could extend some of those ideas to hypergraphs. But working out how that proof goes actually took an enormous amount of time and effort and resulted in this amazing theorem on hypergraph. I may mention these are not the only methods that were used to extend Szemeredi's theorem or give the alternative proofs. There are many others. For example, you may have heard of something called the polymath project. Actually, raise your hand if you heard of the polymath project. OK, great. So maybe about half of you. So this is an online collaborative project started by Tim Gowers and also famous people like Terry Tao. And they were all quite involved in various polymath projects. And the first successful polymath project produced a combinatorial proof of something known as the density Hale-Stewart theorem. So I won't explain what it is here. So it's something which is related to tic-tac-toe. But let me not go into that. So it's a deep combinatorial theorem that had been known earlier using ergodic theoretic methods. But they gave a new combinatorial proof. In particular, it gave some concrete bounds on this theorem. And that, in particular, also implies Szemeredi's theorem. So this gave a new proof. And as a result, they, well, it's an online collaborative project. So they published this paper under the pseudonym DHJ polymath, where DHJ stands for density Hale-Stewart. And they kept the same name for all of the subsequent papers published by the polymath project. So as you see through all of these examples, that there were a lot of work that were motivated by Szemeredi's theorem. This is truly a foundational result, a foundational theorem that gave way to a lot of important research. And Szemeredi himself received an Apple Prize for his seminal contributions to combinatorics and also theoretical computer science. We still don't understand, in some sense, completely what Szemeredi's theorem would, for example, we don't understand the optimal bounds. And also, more importantly, conceptually, we don't really understand how these methods are related to each other. So there is some vague sense that they all have some common themes. But it's still, there's a lot of mystery as to what do these methods coming from very different areas, ergodic theory, harmonic analysis, graph theory, what do they all have to do with each other? But there is one central theme. And this is also going to be a theme in this course, which goes under the name, and I believe Terry Tao is the one who popularized this name, the dichotomy between structure and randomness, structure and pseudorandomness. Somehow, it's a really fancy way of saying signal versus noise. So I give you some object, give you some complex object. And there is some mathematical way to separate the structure from some noisy aspects, which behave random-like. So there will be many places in this course where this dichotomy will play an important role. Any questions at this point? OK. I want to take you through some generalizations and extensions of Szemeredi's theorem. So first, let's look at what happens if we go to higher dimensions. So suppose we have a subset in d dimensions, d-dimensional lattice. So we can also define some notion of density. Again, it doesn't matter precisely what is the notion you use. For example, we can say that it has positive upper density if this limb sup is positive. So Szemeredi's theorem in one dimensions tells us that if you have some set of positive density, then I can find arbitrarily long arithmetic progressions. So what should the corresponding generalization in higher dimensions? Here's a notion I can define, namely that we say that A contains arbitrary constellations to mean that, so what does that mean? So a constellation, you can think of it as some finite pattern, so a set of stars in the sky. So some pattern, and I want to find that pattern somewhere in A where I'm allowed to dilate. So I'm allowed to multiply the pattern by some number and also translate. I want to find this pattern. So what I mean precisely is that for every finite subset of the grid, there exists some translation and some dilation such that once I apply this dilation and translation to my pattern F, meaning I'm looking at the image of this F under this transformation, then this set lies inside A. So you see that arithmetic progressions is a constellation, just numbers 1 through k. So that's a definition. And the multidimensional Szemeredi theorem, so the multidimensional generalization of Szemeredi's theorem, says that for every subset, so every subset of the d-dimensional lattice of positive density contains arbitrary constellations. You give me a pattern, and I can find this pattern inside A, provided that A has positive density. So in particular, if I want to find a 10 by 10 square grid, meaning suppose I want to find a pattern which consists of something like that, a 10 by 10 square grid, where all of these lengths are equal, but I don't specify what they are, but as long as they're equal, then the theorem tells me that as long as A has positive density, then I can find such a pattern inside A. So this theorem was proved by Furstenberg and Katznelson. So you see that it is a generalization of Szemeredi's theorem. So the one-dimensional case is precisely Szemeredi's theorem. So Furstenberg and Katznelson, using ergodic theory, showed that one can generalize Szemeredi's theorem to the multidimensional setting. However, the combinatorial approaches employed by Szemeredi did not easily generalize. So it took another couple of decades, at least, for people to find a combinatorial proof of this result. And namely, that happened with the hypergraph regularity method. So this was one of the motivations of this project. And you say, OK, what's the point of having different proofs? Well, for one thing, it's nice to know different perspectives onto an important theorem. But there is also a concrete objective. In particular, it turns out that if you prove something using ergodic theory, because we will not discuss ergodic theory in this course, but roughly one of the early steps in such a proof applies compactness. And that already destroys any chance of getting concrete quantitative bounds. So you can ask, if I want to find a 10 by 10 pattern and I have density 1%, how large do I need to look? How far do I have to look in order to find that pattern? So that's a quantitative question that is actually not at all addressed by ergodic theory. So the later methods, using combinatorial methods, gave you concrete bounds. So there are some concrete differences between these methods. So this theorem reminds me of this scene from the movie A Beautiful Mind, which is one of the greatest mathematical movies, in some sense. And so there's a scene there where Russell Crowe, playing John Nash, so they were at this fancy party. And Nash was with his soon-to-be wife, Alicia. And he points to the sky and tells her, pick a shape. So pick a shape and I can find for you among the stars. And so this is what the theorem allows you to do. So if you have, so give me a shape, and I can find that constellation inside A. Let's look at other generalizations. So far, we are looking at linear patterns, so looking at linear dilations and translations. But what about polynomial patterns? So here's a question. Suppose I give you a dense subset, a positive density subset of integers. Can you find two numbers whose difference is a perfect square? So this question was asked by Lovaas. And a positive answer was given in the late 70s by Furstenberg and Sarkozy independently. Furstenberg and Sarkozy, they showed, using different methods, so one ergodic-theoretic and the other is more harmonic-analytic, that every subset of the integers, so every subset of positive integers with positive density contains two numbers differing by a perfect square. So in other words, we can always find the pattern x, x plus y squared. So what about other polynomial patterns? Instead of this y squared, suppose you just give me some other polynomial or maybe a collection of polynomials. So what can I say? Well, there are some things for which this is not true. Can you give me an example where if I put in a wrong polynomial, it's not true? What if the polynomial is a constant 1? If you take the even numbers, has density 1 half, but it doesn't contain any patterns of x and x plus 1. So I need to say some hypotheses about these polynomials. So a vast generalization of this result, known as the polynomial Szemeredi theorem, says that if A is a subset of integers with positive density, and if we have these polynomials P1 through Pk with integer coefficients and 0 constant terms, then I can always find the pattern. So there exists some x and positive integer y, such that this pattern x plus P1 of y, x plus P2 of y, and so on, x plus Pk of y, they all lie in A. So in other words, succinctly, every subset of integers with positive density contains arbitrary polynomial patterns. So this was proved. So this was an important result proved by Bergelson and Liebman using ergodic theory. And so far, for this general statement, the only known proof uses ergodic theory. So there were some recent developments, pretty exciting developments, that for some specific cases, where if you have some additional restrictions on the piece, then there are other methods coming from Fourier analytic, harmonic analytic methods that could give you a different proof that allows you to get some bounds. Remember, ergodic theoretic proof gives you no bounds. But so far, in general, the only method known is ergodic theoretic. And actually, Bergelson and Liebman proved something which is more general than what I've stated. So this is also true in a multidimensional setting. I won't state that precisely, but you can imagine what it is. Let me mention one more theorem that many of you, I imagine, have heard of. And this is the Green-Tao theorem. So the Green-Tao theorem says that the primes contain arbitrarily long arithmetic progressions. So this is a famous theorem. And it's one of the most celebrated results of the past couple of decades. And it resolved some longstanding folklore conjectures in number theory. The Green-Tao theorem, well, you see that in form, it looks somewhat like Szemeredi's theorem, but it doesn't follow from Szemeredi's theorem. Well, the primes, they don't have positive density. The prime number theorem tells us the density decays, like 1 over log n. So what about quantitative versions of Szemeredi's theorem? It is possible, although we do not know how to prove such statement. It is possible that the density of primes alone might guarantee the Green-Tao theorem, in that it is possible that Szemeredi's theorem is true for any set whose density decays like the prime numbers, like 1 over log n. But that is, we're quite far from proving such a statement. And that's not what Green and Tao did. Instead, they took Szemeredi's theorem as a black box and applied it to some variant of the primes and showed that inside this variant, Szemeredi's theorem is also true, and that the primes sit inside this variant of the primes, known as pseudoprimes, as a set of relatively positive density, somehow transferring Szemeredi's theorem from the dense setting to a sparser setting. So this is a very exciting technique. And as a result, Green-Tao proved not just that the primes contain arbitrarily long arithmetic progressions, but every relatively dense, so relatively positive density subset of the primes contains arbitrarily long arithmetic progressions. To prove this theorem, they incorporated many different ideas coming from many different areas of mathematics, including harmonic analysis, some ideas coming from combinatorics, and number theory as well. So there were some innovations at the time in number theory that were employed in this result. So this is certainly a landmark theorem. And although we will not discuss the full proof of the Green-Tao theorem, we will go into some of the ideas throughout this course. And I will show you bits and pieces that we will see throughout the course. So this is meant to be a very fast tour of what happened in the last 100 years in additive combinatorics, taking you from Schur's theorem, which was really about 100 years ago, to something that is much more modern. But now, instead of being up in the stars, let's come back down to Earth. And I want to talk about what we'll do next. So what are some of the things that we can actually prove that doesn't involve taking up 50 pages using a complex logical diagram, as Szemeredi did in his paper? So what are some of the simple things that we can start with? Well, so first, let's go back to Roth's theorem. So Roth's theorem, we stated it up there. But let me restate it in a finitary form. So Roth's theorem is the statement that every subset of integers 1 through N that avoids three-term arithmetic progressions must have size little o of N. So earlier, we gave an infinitary statement that if you have a positive density subset of the integers, then it contains a 3AP. This is an equivalent finitary statement. Roth's original proof used Fourier analysis. And a different proof was given in the 70s by Ruzsa and Szemeredi using graph theoretic methods. So how does graph theory have to do with this result? That shouldn't be surprising to you at this point, given that we already saw how we used Ramsey's theorem, graph theoretic result, to prove Schur's theorem, which is something that is number theoretic. So something similar happens. But now the question is, what is the graph theoretic problem that we need to look at? So for Schur's theorem, it was Ramsey's theorem for triangles. Well, what about for Roth's theorem? A naive guess is the following. So what's the question that we should ask? Here's a somewhat naive guess, which turns out not to be the right question, but still an interesting question, which is that what is the maximum number of edges in a triangle-free graph on n vertices? Now, this is not totally a stupid guess, because as you imagine from what we said with Schur's theorem, somehow you want to set up a graph so that the triangles correspond to the three-term arithmetic progressions. And you want to set it up in such a way that this question about what's the maximum size subset of 1 through n without 3 APs translates into some question about what's the maximum number of edges in a graph that has some property? What is that property? So this is not a totally stupid guess. But it turns out this question is relatively easy. Still, it has a name. So this was found by Mantel about 100 years ago. So it's known as Mantel's theorem. And the answer, well, we'll see a proof. So the first thing we'll do in the next lecture is prove Mantel's theorem. But I don't want to hold suspense. I mean, the answer turns out to be fairly simple to describe, namely that you split the vertices into two basically equal halves, and you join all the possible edges between the two halves. So this is a complete bipartite graph with two equal-sized parts. And it turns out this graph, you see this triangle-free. And it also turns out to have the maximum number of edges. Yeah, question? AUDIENCE 1 What are asymptotics for three arithmetic progression avoiding subsets of x? YUFEI ZHAO. Let me get to that in a second. So I'll talk about asymptotics in a second. So it turns out this is not the right graph theoretic question to ask. So what is the right graph theoretic question to ask? So I'll tell you what it is. I mean, it shouldn't be clear to you at this point. It still seems like an interesting question. But it's also somewhat bizarre to think about if you've never seen this before. What is the maximum number of edges in an n-vertex graph where every edge lies in exactly one triangle? So I want a graph with lots and lots of edges where every edge sits in exactly one triangle. You might have some difficulty even coming up with good graphs that have this property. And that's OK. These are very strange things to think about. But we'll see many examples of it later on. And we'll also see how Roth's theorem is connected to this graph theoretic question. Just to give you a hint, where does exactly one triangle come from? It's because even if you avoid three-term arithmetic progressions, there are still these trivial three-term arithmetic progressions where you keep the same number three times. And in a graph theoretic world, that comes to the unique triangle that every edge sits on. So to address the question about quantitative bounds, for Roth's theorem, it turns out that we have upper bounds and lower bounds. And it is still a wide open question as to what these things should be. And roughly speaking, the best lower bound comes from a construction, which we'll see later in this course, that has size around n divided by e to the c root log n. And the best upper bound is of the form roughly n over log n. It's maybe a little bit hard to think about how these numbers behave. So if you raise both sides to the denominator to e to the something, then it's maybe easier to compare. It's still a pretty far gap. So still a pretty big gap. There's a famous conjecture of Erdos, some of you might have heard of, that if you have a subset of the positive integers with divergent harmonic series, then it contains arbitrarily long arithmetic progressions. That's a very attractive statement. But somehow I don't like the statement so much, because it seems to make it too pretty. And the statement really is about what is the bounds on Roth's theorem and on Szemeredi's theorem. And having divergent harmonic series is roughly the same as trying to prove Roth's theorem slightly better than the bound that we currently have, somehow breaking this logarithmic barrier. So that conjecture, that having divergent harmonic series implies three-term APs, is still open. That is still open. So we're, the bound's very close to what we can prove, but it is still open. For this question, we will see later in this course, once we've developed Szemeredi's regularity lemma, that we can prove an upper bound of O to the n squared. So go to n. And that will suffice for proving Roth's theorem. Turns out that we don't know what the right answer should be. We don't know what is the best such graph. And turns out the best construction for this graph there comes from over here, the best lower bound construction of a set, of a large set, without three-term arithmetic progressions. So I'm giving you a preview of more of these connections between additive combinatorics on one hand and graph theory on the other hand that we'll see throughout this course. Any questions? So just to tell you what's going to happen next, so the next thing that we're going to discuss is basically extremal graph theory. And in particular, if you forbid some structure, such as a triangle, maybe a four-cycle, maybe some other graph, what can you say about the maximum number of edges? And there are still a lot of interesting open problems, even for that. I forbid some H. What's the maximum number of edges? So the next few lectures will be on that topic.