 All right, so let's continue with our discussion of measurable functions. So last time, we introduced the notion of measurable functions. So if I have a measurable set, f from e to the extended real numbers is measurable, or is a measurable function. If for all alpha and r, the inverse image of the half infinite open interval alpha to infinity is measurable. And then we proved that if we have a function which is measurable, then not only is the pre-image of these intervals measurable, but the pre-image of any Borel set, any member of the Borel sigma algebra, which includes open sets, closed sets, and so on, the pre-image of those sets is also measurable. And we proved that being measurable is closed under taking lim sup, lim im, limits in particular, and changing the function a little bit on a set of measure 0 also preserves measurability. And also being measurable is closed under the algebraic operations of taking linear combinations and products. Complex. OK, now this definition and properties we worked out was for extended real valued functions. Quite often, we'll be dealing with, or in general, functions that take values in the complex numbers. So let me define what it means for a complex valued function to be measurable. It's not too crazy. Let E be a subset of R be measurable. We say a function f from E now to the complex numbers is measurable if the two functions given by the real part of f, which now goes from E to R, and the imaginary part of f, which now is a function from E to R, are measurable. OK? So function into the complex numbers, you can always write as f equals real part of f plus the imaginary part of f times i. So we just say that f is measurable, just require that its real and imaginary parts are measurable. OK? Then you can verify the following simple theorem. Maybe I'll put it on an assignment or not. I haven't decided yet, or just parts of it. If f, g are measurable, and I didn't say so, but if we're talking about measurable functions, the domain E, the domain is always assumed to be a measurable subset of R. So if these are measurable functions, and alpha is a complex number, then the functions alpha times f, f plus g, f times g, and then we can do a few other things to complex numbers that change it. The complex conjugate of f and modulus of f are measurable functions. OK? And then we have the following theorem. fn from E to C is measurable for all n. And these functions converge pointwise to a function f. And then the limiting function is measurable. OK? And this follows, again, so both of these theorems follow immediately from what we know about measurable extended real value functions. So for example, this one here follows from the fact that limit n goes to infinity of fn of x equals f of x if and only if limit as n goes to infinity of the real part of f of x, fn of x equals the real part of f of x. And the limit as n goes to infinity of the imaginary part of fn of x equals the imaginary part of f of x. OK? And if we're assuming fn is measurable for all n, then the real part and imaginary parts of fn are measurable for all n. And therefore, their pointwise limits, which is the real part of f and imaginary part of f, are measurable by the theorem we proved about extended real valued measurable functions. And so we conclude that the real part of f and the imaginary part are measurable, and therefore, f is measurable. OK? So you don't have to work very hard. You can just use what you know, what we proved from the previous lecture about extended real valued functions, which are measurable. All right, so now as far as measurable functions go, we've shown that if I have a continuous function, then that is, so this is from the previous time, from the previous lecture, continuous functions are measurable. And if I have a measurable subset of E, then the indicator function of that set is measurable. And we know that linear combinations of measurable functions are measurable. So if I take linear combinations of indicator functions with, say, complex coefficients, then that will remain measurable as well. And those functions are kind of the simplest type in that they only take finitely many values. They're so simple that we glorify them by giving them that name. And we'll show that every measurable function is, in a sense, approximately a simple function. So we have the following definition. If E is measurable, the measurable function phi from E to C is simple, or we call it a simple function, we'll say is a simple function if the range of E, phi of E, is equal to finitely many values. So a measurable function is a simple function if its range is finite. So let me make a general remark about simple functions. And also, when I write that phi of E is equal to a1 up to an, this is a set. And when I write a1, a2, up to an, I am sort of implicitly writing here. I'm not saying the set. I'm saying each of these elements are different from each other. So a simple function that just takes the value 1, I would not write its range as 1, 1, 1, 1. Although that's a kind of simple and silly remark to make, I just wanted to make it now. So if phi is a simple function, then we can write it in sort of a canonical way. So if phi is a simple function with phi of E equals a1 up to an, then for all i, the set A sub i, which is equal to the inverse image of, so here phi is going from E to C, the inverse image of the single set, the singleton, which is a closed, well, this is going to be, so the inverse image of this guy here is measurable. Because it's equal to the intersection of two measurable sets. It's equal to the intersection of when the real part equals, the real part of phi equals the real part of A sub i intersect the set of all x's where the imaginary part of phi equals the imaginary part of A sub i. So that's why the set is measurable. Is measurable. And we have a few properties of this guy. If I take two different elements in the range, again, this is sort of why I made that comment, that when I write the range this way, I'm listing the distinct elements of the range or the image of E. For all i not equal to j, these two sets are disjoint. And if I take the union of i equals 1 to n of the ai's, this is equal to the total set E. Because this is just the inverse image of this set, which is just E, since E of E equals that. And finally, for all x and E, I can write phi of x as sum from i equals 1 to n of ai chi of A sub i of x. So for a simple function, I can write it in a canonical way where it's just a linear combination of indicator functions where the sets that those indicator functions are non-zero on are disjoint from each other. And their union gives me E, the domain. So these three are kind of the simple but important properties of how to represent a simple function. So it's not difficult to verify, again, just from the definition of a simple function, that scalar multiples, linear combinations, and products of simple functions are, again, simple functions. OK. So I've said that these functions are so simple that that's what we call them, and that they are somehow universal, that in a sense, any measurable function is almost a simple function. So in what sense do I mean that? So that's the content of the following theorem, which is that if f from E to n. Let's first, we're going to do this for extended real-valued functions, and then the proof will essentially carry over to the complex-valued. So I'm just going to do it for the extended real-valued non-negative functions. And again, I'll indicate what the difference is once we go to complex-valued measurable functions. So if E is from, so now this is an extended real-valued, but it's non-negative. So if this is a measurable function, then there exists a sequence of simple functions, p sub n, such that three things hold. We can do this. Let's write down. Let's go over here. Three things hold. We're all x and E. Or let me hold off on stating that. f dominates these simple functions, and these simple functions are pointwise increasing. For all x and E, 0 is less than or equal to phi 1 of, phi 0 of x is less than or equal to phi 1 of x, is less than or equal to phi 2 of x, and so on. And they all sit below f of x. For all x and E, these v's are converging to f of x. So a and b says that there exists a sequence of simple functions that increase to f of x. The last part is that if this function, if this measurable function, is bounded, or wherever it's bounded, this convergence is not just pointwise, but uniform. For all b bigger than or equal to 0, the sequence phi n converges to f uniformly on the set where f is bounded. OK? So again, the take-home is that for every non-negative extended real-value measurable function, we can find a sequence of simple functions that well approximates f. And in what sense does this well approximate f? They increase to f. And if f is bounded, then that convergence is, in fact, uniform. Or more precisely, wherever f is bounded, convergence is uniform. So this is in what sense every measurable function is almost a simple function. All right, so let's get started with the proof. And first, I'm going to draw a few pictures so that you can kind of get the idea of how we're going to do this, or how we're going to construct this sequence of simple functions, and then turn that into math, which might be a little bit jarring if I went that route first and then drew pictures. And this picture I'm going to draw kind of looks like what I was talking about where we split the range up rather than the domain when we were motivating why we would even introduce the concept of a measurable function. So let's say we have our function f. Now, how I'm going to build these phi's are that what I'm going to do is, so here I'm going to draw phi 0 now. Where's the yellow chalk? All right, what I do is this will indicate kind of the power of 2, how high up I'm going, and also the resolution. How much am I dividing how high up I'm going into smaller parts? So phi 0, you should think that my height will be, well, my height is going to be 1. And so what I do is how I define this simple function phi 0 is I look at where f is above the final value 1, and my simple function will be that final value 1 there. OK, and move this over a little bit. And that just leaves where f is less than 1. And there I set the value of my simple function to be 0. And 0 simply because that's the lower bound, or that's the smallest value of this interval 0, 1. And that's how I define phi 0. It goes up to height 1, and I only split each part into 1. So there's only one part here. Now, maybe some of that didn't make any sense to you. That's OK. We're going to draw phi 1, and then I'm going to stop there because this is going to grow exponentially, which means I'll probably draw an exponentially worse picture each time. So now we're going to draw phi 2. And what I do is there's 1, or phi 1, sorry. 1, again, should indicate the power of 2 that I'm both going up and resolving the axis. So now I go up to, let's make this a, so again, this will not be quite to scale. But hopefully that's OK. All right, so let's make this a little closer to scale. OK, so 1, now I have two parts, 2 to the 1. So this is parameterizing how the tallest I'm going and cutting up the range of my function f. And then I'm going to now resolve each part in half, 2 to the minus 1. So now I take, this is now 3 halves, and this is now 1 half, 2 to the minus 1. So why am I writing 2 to the minus 1? Again, because this 1 here corresponds to, and that 1 here corresponds to, I'm cutting the whole increments into halves. If I go on to phi 2, I'm going to be going up to 2 to the 2, which is now 4. And from 4 to 3, 3 to 2, 2 to 1, I'm going to be cutting those into fourths. And again, what I do is I look at, I cut, and now I look at where the function is in these widths. So if it's above my highest bound, then my simple function will be 2 on that set of x's where it's at its highest, or where f goes past the largest number, which I'm resolving the axis in. And then now here, for example, so you should try and draw your own picture and not just go off mine, because again, mine is looking kind of rough already. But now I look at the set of x's where the function is between 2 and 3 halves. So that's going to be this piece and this piece. And then I set my simple function to be equal to the value, the lower bound on this interval that I've cut the range into. OK? And then I do that from 3 halves to 1. And for example, that's happening here on this x. And I set it equal to, I set my simple function equal to, again, the lower bound on this interval that I've cut the range up into, which is 1, and so on. And now the function between 1 and 1 half, this is kind of only the last piece. Everywhere else is filled in. And there's no f in between here, so I don't assign a value there. OK? All right. Now that was me talking my way through how the sequence of functions look. Now I'll just write down what these functions, how these functions are defined. And so for n equals 0, 1, 2, and so on, for k between 2 to the 2n minus 1, I define sets E, k, n. This is equal to the set of all x's in E, such that f of x is between k times 2 to the minus n, is less than or equal to k plus 1, 2 to the minus n. OK? Which is just me explicitly writing out that this is the inverse image of k times 2 to the minus n, k plus 1, 2 to the minus n, closed. OK? And this is an interval. And since f is measurable, assumed to be measurable, this is a measurable. The inverse image of that interval is a measurable set. OK? And then I define fn to be the inverse image of when f exceeds my top value of how I'm cutting up the range, 2 to the n. OK? Again, which is measurable. And finally, I will take my simple function, vn, to be sum from k equals 0 to 2 to the 2n minus 1, k times 2 to the minus n, which is, again, this would correspond to the lower part of my E, k, n that I'm looking at. So for this example, if this E, k, n is the 2, 3 halves, and 3 halves is the lower part, times chi E, k, n plus 2 to the n times where f exceeds 2 to the n. OK? So I encourage you to maybe write out phi 1, OK? What that actually is. I mean, there's a fact here. I'll do that. But I drew the picture that goes over here. Let me write out what phi 1 actually looks like. Phi 1 is equal to 0 times the indicator function where f is between 0 and 1 half plus 1 half times the indicator function where f is between 1 half and 1 plus 3 halves times the indicator function of when f is between, no, that's not 3 halves, that should be 1 half. No, no, no, what am I doing? 1. Times the indicator function where f is between 1 and 3 halves plus 3 halves times chi f inverse of where f is between now 3 halves and 2. So 2 is how high up I break up the range. And then plus this last part, this fn part, which is 2 times chi where f, the indicator function of where f is bigger than 2 to the n, so bigger than 2. OK? So all of these sets are disjoint. The ekn's and fn's for k different from k prime and fixed n are disjoint. And they are disjoint from this set. So this is a simple function. The finitely many values it takes is 2 to the n along with k times 2 to the minus n, or at least the finitely many values it can take is a subset of that. So this is a simple function for each n. And by design, it's always sitting below f, right? So let me, in fact, bring it up here. Well, let me make the statement and then I'll say. So by definition, for all x and e, fin is non-negative. Fin is non-negative and always sits below f of x, right? So how do we see that? You can see it from the general formula, but I'll just indicate why. Just for, say, phi 1. Let's say, so x has to be in one of these sets. Let's say it's here where f is between 1 half and 1. Then phi 1 of x is equal to 1 half, which is less than f of x because f takes on the value between 1 half and 1, right? OK. In fact, here, I'll give the brief argument here. If x is in ekn, then by definition, this means that k 2 to the minus n is less than f of x is less than or equal to k plus 1 2 to the minus n, which implies that phi n of x, which is by definition k times 2 to the minus n. Just again, by how we've defined the phi sub n's, where did we define the phi sub n's? There, is less than f of x. OK. So that's for x in ekn. And if x is in f sub n, then that means f of x is greater than 2 to the n, which is always bigger than or equal to phi n of x. Well, I mean, this is actually equal to phi n of x. So we always have the phi n's are non-negative, and they always sit below f of x. So now, let's prove that they are, in fact, increasing. So part a. OK. So now we're proving part a. The phi n's increase to f. OK. And again, since for fixed n, ekn and fn, the ekn's and fn form a disjoint union of e, I just need to check that what I want holds on each of the ekn's and fn's. So suppose x is in ekn, then f of x is less than or equal to k plus 1 times 2 to the minus n. n is bigger than k 2 to the minus n, which, by a silly trick of just multiplying and dividing by 2, tells me that f is between 2 times k times 2 to the minus n minus 1 is less than f of x is less than or equal to 2k plus 2 times 2 to the minus n minus 1, which implies that x is in the union of e 2k n plus 1. 2k n plus 1 union 2k plus 2 n plus 1. If x is in e 2k n plus 1, then I get that phi n of x is equal to, by definition, k times 2 to the minus n, which equals 2k 2 to the minus n minus 1, which, because x is in e 2k n plus 1, this is equal to the n plus 1 of x. And if x is in e 2k plus 2 n plus 1, no, I shouldn't, this shouldn't be a 2, this should be a 1, I'm sorry. Because this goes from 2k up to 2k plus 1, and then from 2k plus 1 up to 2k plus 2. So it's either in e 2k or 2k plus 1. And if e is in a 2k plus 1, then phi n of x is still, I mean, x is still in e k n, so phi n of x is equal to still k times 2 to the minus n, which is equal to 2k times 2 to the minus n minus 1, which is less than 2k plus 1 times 2 to the minus n minus 1, which is, by definition, since x is in e 2k plus 1 n plus 1 n plus 1 of x. OK? And similarly, if x is in fn, then phi n of x is less than or equal to phi n plus 1 of x. OK, so we verified for all x, since e is equal to this union over k equals 0, 2 to the 2n minus 1 e k n union fn. This implies that for all x in e, phi n of x is less than or equal to phi n plus 1 of x. OK? All right, and this proves A. Now, how to prove B and C. These things will follow from part A in a simple estimate that we're going to prove. So B and C will follow immediately from the following claim in part A, which the claim is that for all x in set y in e, that f of y is less than or equal to 2 to the n. This part, we already know that f of x minus phi n of x is non-negative. But in fact, this is bounded by 2 to the minus n. OK? All right, so then B and C from A and this claim. OK? Why does B follow from this claim? Well, wherever x is, so let's, I don't want to have to also explain what happens if f is equal to infinity. That also follows basically from the definitions, not necessarily from this estimate. But the more important part is when f is finite. So let's assume f is just finite for every x. So then every x in e is eventually in one of these sets. So there exists let x be fixed. Then for n sufficiently large, x is in one of these sets, since f of x is finite. And therefore, for all n sufficiently large, this minus phi n of x is less than or equal to 2 to the minus n. But then f of x minus phi to the m is also less than or equal to 2 to the minus n. For every m bigger than or equal to n, right? Because the phi n's are increasing. Yeah? If phi n is this close to f, then phi m is also that close to f if m is bigger than or equal to n, right? Again, because they're increasing. So that proves that's why pointwise convergence B follows from this estimate. As far as part C, that also follows from this estimate, since if I have a fixed B, then I can choose a natural number just depending on what B is. So that set, depending on B in the original statement, I'm pointing at it, but I don't think you can see it from the camera. That set, which depends on B, is contained in one of these sets. And therefore, for all x in the set where f is bounded by B, this holds uniformly in x. And that's where the uniform convergence comes from. But the whole point is that this is the estimate that gives us B and C once we've proved A. All right? So let's prove this claim. It's not hard. It's basically because we are cutting up the range not only to height 2 to the n, but with resolution 2 to the minus n at each stage, at each n. Right, so to prove the claim, we have that the set of y's in E such that f of x is less than or equal to 2 to the n. This is equal to the union k equals 0, 2 to the 2n minus 1 of the ekn's. OK? So if I want to check that bound, I just have to check it for each if x is in one of these. OK? So suppose x is in e to the kn. Then, I mean, it really is just following from the fact that we're cutting up the range with resolution 2 to the minus n. Right? So I'm just going to draw a small little picture here. We have the axis here. And here's k plus 1 times 2 to the minus n. Here's k times 2 to the minus n. If x is in there, that means we're looking at the portion of f that sits between k 2 to the minus n and k plus 1 2 to the minus n. Then, k times 2 to the minus n is less than f of x is less than or equal to k plus 1 2 to the minus n. And remember, the simple function on this piece evaluated in here. So here's the x. Gives the value at the lower bound. Right? So and therefore, we get that fn of x minus phi n of x. This is equal to not fn, sorry, f of x minus k 2 to the minus 1. Now, x, again, is in e kn. So f of x is between these two numbers. So this is less than or equal to k plus 1 times 2 to the minus n minus k 2 to the minus n. And this equals 2 to the minus n. So whenever we have an x in one of these sets, it has to be within 2 to the minus n. The simple function evaluated at that x has to be within 2 to the minus n of f. Again, this is just by construction, by how we've cut up the y-axis, if you like, the range. We're cutting it up with resolution 2 to the minus n. All right? So that proves the claim, which, as I said, along with part a, proves b and c. So that proves that every measurable function is almost at least non-negative extended real-valued measurable function is a limit of a sequence of simple functions. Now, this theorem carries over without difficulty to complex-valued functions after I just introduced kind of a breakup of a function in general. So if E is a function from minus infinity to infinity, so an extended real-valued function now, we define its positive and negative part, f plus of x to equal the max of f of x0. So this is the positive part of f. f minus of x is equal to the min of the max. I'm sorry. Minus f of x0. This is the negative part of f. All right, so what about these positive and negative parts? Then f is equal to f plus minus f minus. You can just check that. I mean, take any x. If f is positive or non-negative on that, then I get f of x out. If it is negative, then I will get minus f of x, which is the absolute value, times minus gives me back f of x. And the absolute value of f is equal to f plus plus f minus. So let me make a comment that this is just a definition for an arbitrary function from E to the extended real numbers. If f is measurable, then each of these functions is measurable, because this is, if you like, the supremum of the sequence of functions given by f and then 0 afterwards. And this is given by the supremum of functions given by minus f and 0 afterwards. So if f is measurable, its positive and negative parts are also measurable functions. And they're also non-negative. So maybe that wasn't clear, or at least it should be clear this is the max always involving 0, so it's always non-negative. So now the construction we did a minute ago essentially carries over to the case of complex valued measurable functions. So let E be measurable and f from E to C be measurable. Then there exists sequence of simple functions vn such that analogs of those three properties hold. A is for all x and E. These are increasing in modulus, in absolute value. 0 is bigger than or equal to, of course, phi 0 of x is less than or equal to the absolute value of phi 1 of x, less than or equal to the, I say absolute value in modulus, same thing, is less than or equal to the absolute value of f of x. So these phi n's are converging to f point-wise. And finally, convergence is uniform on sets where f is bounded. So for all b bigger than or equal to 0, I say a minute ago, vn converges to f uniformly on the set x in E such that the absolute value of f of x or the modulus of f of x is less than or equal to b. So this theorem follows kind of immediately from the previous theorem because now what I do is I just take f, I split it into its real and imaginary parts, and then I split the real and imaginary parts into both positive and negative parts. So I will leave it to you to actually fill in the details, but you apply the previous theorem to the real part of f plus or minus, which are now non-negative measurable functions, and the positive and negative parts of the imaginary part of f, again, which are non-negative measurable functions. And then you just take linear combinations of these simple functions that add up to f. OK? You will take the sequence of simple functions corresponding to the real part of f and subtract the sequence of simple functions that you got for the minus for the negative part of f, real part of f. And you will take that and add i times the positive part or the sequence of simple functions converging to the positive part of the imaginary part of f minus the sequence of functions, simple functions converging to the negative part of the imaginary part of f. OK? So that's what I mean by apply previous theorem to the positive and negative parts of the real and imaginary parts of f. OK? So what's the significance of this theorem? Not only, let me just say, if also showing that somehow measurable functions are well approximated or almost simple functions, this also gives us a way of maybe defining the integral, at least of non-negative functions. That way we don't have to deal with possible deals with subtracting infinity from infinity. But by simply defining its integral to be the limit of these integrals of these simple functions. And for a simple function, we would presumably know how to define an integral. It would just be the numbers times the measure of the sets that appear in the indicator functions for these simple functions. And like I said last lecture, if you wanted to define the Lebesgue integral that way, you would run up against, well, does this number depend on the sequence of simple functions you chose to approximate f? But we're not going to define the Lebesgue integral in that way. We're going to define it a little bit differently, which is what we're going to move on to now, which is the Lebesgue integral of a non-negative function. And then we will define the Lebesgue integral or Lebesgue integrable functions. These will be complex value functions now for which we can define an integral for. And that is the full theory of Lebesgue. And that's the end of the game as far as defining Lebesgue integral. And then we'll prove some convergence theorems along the way, which make the Lebesgue integral stronger than Riemann integrals. So now we're moving on to the Lebesgue integral of a non-negative function. OK? And why start with a non-negative function? Again, because I just pulled this trick on you a minute ago, that if somehow we know how to do stuff for non-negative measurable functions, then by playing this game where we take the real and imaginary parts and split it up into positive and negative parts, hopefully we can do something for general functions. So that's why we start out with introducing or defining the Lebesgue integral of a non-negative function. So definition, if E is a measurable subset of R, we define L plus of E. This is the set of all extended real-valued functions, non-negative real-valued functions that are measurable. OK? And now what the goal is is to define the integral of a function like that's in this class. And it may be an infinite number. It may not be. And in order to do that, we're first going to define how to integrate the simplest type of functions, well, simple functions. So let phi be a simple function. And let's write phi in this kind of canonical way. OK, so phi is equal to a sum of aj chi aj, where for all i not equal to j, well, first off, for all j, aj is a subset of E. For all i not equal to j, ai intersect aj is empty. So these are disjoint. And their union gives me the set E. OK? OK, the Lebesgue integral of this simple function phi is the number which I said is kind of the simplest way, or what you would expect to define the integral of a simple function. So we know how to measure sets. And remember, we initially built up measure so that the integral, which would be a theory of area underneath the curve, should be the integral of the indicator function should be the area underneath the curve of 1, area being the measure of the set where that indicator function is 1. And therefore, by linearity, this will be how we define the Lebesgue integral of a simple function. So the Lebesgue integral of phi is the following number, E phi. This is how it's defined. Sum from j equals 1 to n, aj, measure of aj. OK? And this number could be infinite. And instead of writing just the integral over E of phi, I might add a dx in there. I'm just warning you ahead of time. All right, so this is the Lebesgue integral of a simple function. Again, we split it up into this kind of canonical way where it's just the indicator function of disjoint sets, whose union gives the set of the domain. And what we're going to do is we're going to take the Lebesgue integral of phi domain, and where these numbers out in front, these coefficients give you the numbers that go or the elements of the range. So for example, again, I mean, this is, let's say, A is from, or let's say E is the interval AB. You can check that, well, I mean, it's just from the definition that if my simple function is, in fact, these sets are just intervals. So if this is what my simple function looks like, it takes finitely many values. This one, this one, this one, this one, this one. And on these sets whose disjoint union forms AB, then as I've defined the integral and since the measure of an interval equals the length of the interval, again, this is, you should count this as some more comments. This integral equals the sum of, so this would be AJ. AJ, then how I've defined the Lebesgue integral, it spits out the area underneath this simple function that is taking these values on these intervals. I hope that's clear. It's towards the end of the day, so maybe my explanations are getting a bit wonky. But I hope it's clear. And then we're going to use this definition of how to integrate simple functions. We're going to extend it to general elements of L plus of E, the non-negative measurable functions. But first, let's prove a few properties of how we've defined the integral for simple functions. Let's take two simple functions. First is that if c is bigger than or equal to 0, then the integral of c times phi over E, this is equal to c times the integral of E phi. OK, to the integral, the Lebesgue integral over E of phi plus psi is equal to the Lebesgue integral of phi plus the Lebesgue integral of psi. And third property is if phi is less than or equal to psi on E, so I'm writing that shorthand by that. So what I'm saying in that statement is for all x in E, phi of x is less than or equal to psi of x. Then what you expect is the integral of phi is less than or equal to the integral of psi. And let me include, in fact, one more very simple property. If f is, let's add a little punctuation, if f is a measurable subset of E, then phi, which is a simple function on E, is also a simple function on f. It takes only finitely many values on f as well. And therefore, it has an integral over f. And my claim is that that is equal to the integral over E of phi times the indicator function of f. And that's less than or equal to the integral over E. Now, I will leave problem 4 to you. I might even put it on the assignment. But it will follow once you've seen how we prove 1, 2, and 3. You'll be like, OK, so I know how to do this. So number 1 is pretty easy, simply because multiplying by a non-negative constant just carries through and just changes the constant, but not the set. So phi times c times phi is equal to c times a sub j. And therefore, the integral of c times phi over E, this is by definition equal to sum from j equals 1 to n of c times a sub j, measure of a sub j. And this is equal to c times sum from j equals 1 to n of a sub j, m of a sub j. And this equals c times the integral of phi over E. So to prove 2, we write phi as, again, as in this kind of canonical form, sum over a sub j's times the indicator function of a sub j's, where, again, these sets are disjoint. And their union gives me E. And then also, I do the same thing for psi. Now, k equals 1 to m. Maybe take on different number of values, bk chi bk, where, again, the bk's are disjoint, and their union gives me E. So since the union of the aj's gives me E, and the union of the bk's give me E, this implies that if I want to look at one of these aj's, it's equal to a union of a certain type. Is equal to the union k equals 1 to m of aj intersect bk, because this is just going to be equal to aj intersect the union of the bk's, but the union of the bk's gives me E. And similarly for the bk's, because the union of aj's gives me E. And again, these unions are disjoint. The aj's are disjoint from each other. The bk's are disjoint from each other. So for all j and k, aj intersect bk is going to be disjoint from another aj prime intersect bk prime. When j or k do not equal each other. OK, so since these are disjoint unions, we have from the additivity property of Lebesgue measure, we get that the integral over phi E plus the integral over E of psi, this is equal to by definition j equals 1 to n of aj measure of aj plus k equals 1 to m bk measure of bk. Now, aj is written as this disjoint union, and therefore the measure of aj is equal to the sum of the measure of these of aj intersect bk plus. And then the same thing here. The measure of bk is equal to this disjoint union, so its measure is the sum of the measure. So this sum now includes j. So let me just rewrite this as sum over jk aj plus bk measure of aj bk. All right. But the point is that the sum of these two simple functions, you can check, this is equal to the sum over jk of aj plus bk times the indicator function of aj intersect bk. Right? So when x, so at those x's when phi equals aj, and at those x's where psi equals bk, then I'm in this set and the two sides agree. OK? This implies that the integral over e of phi plus psi is equal to the measure of aj intersect bk, which, as we just saw, is equal to the sum of the integrals. OK? OK, so that was two. Three is not too difficult either. So again, let's assume that phi and psi are written in that way, in this canonical way. Then for all x and e, phi of x is less than or equal to psi x. This is equivalent to aj is less than or equal to bk whenever aj and bk is non-empty. OK? Thus, again, we're going to use the additivity of Lebesgue measure and the fact that the unions of these bk's give me e. Then if I look at the integral of e of phi, this is sum j equals 1 to n aj measure of aj. This is equal to the sum jk aj times the measure of aj bk, because the aj is a union over aj intersect bk's, and that's a disjoint union. And now, whenever this is non-zero, that means that aj intersect bk is non-empty. And therefore, that aj appearing there is going to be less than or equal to bk. And whenever this is 0, well, whatever's there is always less than or equal to bk times the measure of aj intersect bk. So this is less than or equal to jk bk measure of aj intersect bk. OK? All right, so whenever this is, so maybe that previous explanation was not good. Whenever this is non-empty, I will always have aj less than or equal to bk. So I should have just said that. I don't know what was going on about measure 0 stuff, but ignore that. Whenever this is non-empty, like I just said a minute ago, aj is less than or equal to bk. And now we just reverse course, and this is equal to k equals 1 to m of bk measure of bk, because union over j's of these sets give me bk. And this is equal to the integral of psi v. And again, I will leave 4 to you as a very simple exercise. OK, I'm about out of time. So what we've done is we've defined the Lebesgue integral of a simple function. And as that picture shows, I hope, or at least convinces you that if the simple function takes on that of a step function, meaning it's the aj's are just intervals, then the Lebesgue integral of that step function will, in fact, be the area underneath phi. So again, you can think of that as two ways, as the Lebesgue integral is giving a theory of the area underneath the curve. You may also think of that as being the first indication that when I have a Riemann integrable function, it will be also Lebesgue integrable, because if I have a step function, like phi is in the picture, then that is a Riemann integrable function, and the Riemann integral is the area underneath the curve, which also agrees with the definition of the Lebesgue integral. So that, like I said, should maybe indicate that the Lebesgue integral reduces to the Riemann integral whenever we're integrating a Riemann integrable function. And so next time, we will define the integral of a non-negative measurable function using how we've defined the integral of simple functions and prove some basic properties, including two of the main convergence theorems that go along with this theory of integration. So we'll stop there.