 Το επόμενο πρόγραμμα είναι προσδοκημένο υπό δίκτυο Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει να προσφέρει υψηλές ειδικές παιδικοσύνης ειδικές πιθανότητες αγώνας για ελεύθερα. Για να κάνετε μια διεγραφή ή να παρακολουθήσετε προσδοκίες αυξαντικών από χιλιάδες μαθητές MIT, επισκεφτείτε MIT OpenCourseWare στηn ocw.mit.edu. Θα τελειώσουμε σήμερα τη συζήτηση μας για τα θεωρία του σύνολου. Θα σας αναφερθώ τι είναι το κεντρικό θεωρία του σύνολου, το οποίο παρουσιάσαμε μία λίγη φορά. Θα συζητήσουμε τι ακριβώς λέει και τις εμπληκτικές του. Και μετά θα το προσδοκίσουμε σε μερικές παραδείγματα, κυρίως για την διστριβή των πυροποιητών. Οκ. Η κατάσταση είναι ότι αντιμετωπίζουμε με μεγάλο τρόπο ανεξαρτητικά, ιδανικά διστριβημένα διπλώματα, και θέλουμε να δούμε την σύμμαχη των διπλώματων και να πούμε κάτι για την διστριβή των σύμμαχων. Μπορούμε να πούμε ότι η σύμμαχη είναι διστριβημένη, περίπου, ως μια καθαρή διπλώματα, αντί, πραγματικά, αυτό δεν είναι σωστό. Όσο η n πηγαίνει στην περιοχή, η διστριβή των σύμμαχων γίνεται πολύ εξελίχνη και δεν συμμετείχε σε μια διστριβή διεγραφής. Για να πάρουμε μια ενδιαφέρουσα διπλώματα, πρώτα πρέπει να πάρουμε τη σύμμαχη και να την κατηγοριζούμε. Με την κατηγορία, αυτό που εννοούμε είναι να αποτύχουμε τη διπλώματα και μετά να τη διαβάζουμε από τη διπλώματα. Τώρα, η διπλώματα είναι, φυσικά, n φορές το προσδεκτικό αριθμό κάθε ένας από τους εξ. Και η διπλώματα είναι η πλήρη πλήρη της διαφορετικής, η διπλώματα είναι n φορές σίγμα στροφό, όπου σίγμα είναι η διπλώματα της εξ. Λοιπόν, αυτό είναι η διπλώματα. Μετά από αυτό, αποτελούμε μια διπλώματα που έχει 0 μήν, είναι κεντρική. Η διπλώματα είναι εξατμώδη. Και η διπλώματα παραμένει η ίδια χωρίς να μείνει πόσο μεγάλη η n. Λοιπόν, η διστριβή του Zn συνεχίζεται να αλλάζει με την n, αλλά δεν μπορεί να αλλάζει πολύ. Μεταφέρει. Η μήνη είναι 0. Και η μεγάλωση παραμένει επίσης γύρω από το ίδιο, γιατί η διπλώματα είναι 1. Το εντυπωσιακό είναι ότι όταν η n μεγαλώσει, αυτή η διστριβή του Zn κατάλαβε σε μια συγκεκριμένη ασυμπτώδη σχέση. Και αυτή είναι η σχέση μιας διπλώματης, τετράγων διπλώματος. Λοιπόν, η διπλώματη τετράγων δημιουργία έχει 0 μήνη και εντολή διαφορετικών. είναι μια σχέση μεταξύ της διστριβής κυμηλωτικής της Zn και της σχέσης με την διστριβή κυμηλωτικής της διπλώματης. Λοιπόν, για κάθε διεθνό αριθμό, C, η πιθανότητα ότι Zn είναι λιγότερο από ή αντίο C στη διπλώματη γίνεται την ίδια πιθανότητα ότι η διπλώματη τετράγων δημιουργία γίνεται λιγότερο από ή αντίο C. Φυσικά, αυτό είναι χρήσιμο γιατί αυτές οι πιθανότητες είναι ευλογικές από τις φυσικές τάπες, ενώ η διστριβή Zn μπορεί να είναι μια πολύ συγκλονιστική εφαρμογή, αν πρέπει να την καταγραφείς ακριβώς. Λοιπόν, κάποιες σχόλια για το θεωρήμα κεντρικού σύνολου. Το πρώτο είναι ότι είναι αρκετά φανταστικό ότι είναι πανεπιστωτικό. Δεν αφορά τι είναι η διστριβή των εξ. Μπορεί να είναι καμία διστριβή αν και αν δεν έχει μειονότητα μήνωση και μειονότητα διαφορά. Και όταν κάνεις τις προστασίες χρησιμοποιώντας το θεωρήμα κεντρικού σύνολου, το μόνο που πρέπει να γνωρίσεις για τη διστριβή των εξ είναι η μηνωμή και τη διαφορά. Πρέπει να τις γνωρίσεις για να καταγραφείς Sn. Νομίζω, για να αποκλεινώ το μήνωμα, να αποκλεινώ το διαφορά με την διστριβή κεντρικής, πρέπει να γνωρίσεις τη μηνωμή και τη διαφορά, αλλά αυτά είναι τα μόνο πράγματα που πρέπει να γνωρίσεις για να τις εφαρμόσεις. Επιπλέον, είναι ένα πολύ σωστό αριστερός σύνολος. Η διστριβή των Zn, σε πρινθόν, μπορείς να την καταλήξεις με την συμβολία της διστριβή των εξ κι εκείνη τη φορά πολλές, πολλές φορές, αλλά αυτό είναι αδύνατο και αν προσπαθείς να το κάνεις αναλυτικά, μπορεί να είναι μια εξελιχιασμένη εφαρμογή. Βέβαια, αν προσπαθείς μόνο την σύνολη της σύνολής τραγουδίας για την σύνολη τραγουδική διστριβή, τα πράγματα γίνονται με μια πολύ γρήγορη τύπη, οπότε είναι ένα ωραίο σύνολο διαδικασίας, αν δεν θέλεις να λάβεις μια ακριβή απάντηση σε ένα πρόβλημα της διστριβής. Τώρα, σε ένα πιο φιλοσοφικό επίπεδο, καταστρέφει γιατί είμαστε πραγματικά ενδιαφέροντα σε φυσικά διστριβή. Όταν έχεις ένα φαινόμενο που είναι σωστό και το σωστό που ελέγχεις δημιουργείται από το να προσθέσεις πολλά μικρά κομμάτια διστριβής που είναι ανεξαρτημένα από τα άλλα, το πλήρως επίπεδο που θα ελέγχεις μπορεί να περιγράψει σε μια φυσική διστριβή. Αν πρόκειται για 100 χρόνια πριν, αφού έχεις ένα φλουίδι και μέσα σε αυτό το φλουίδι υπάρχει ένα μικρό πράγμα από χαμόνια ή κάτι άλλο που το κρατάει εκεί. Αυτό το μικρό πράγμα πηγαίνει καταστρέφοντας από μολύκες ολοκληρωτικά, και οπότε θα δεις αυτό το πράγμα κινδυνάτως μέσα σε αυτό το λίκουδο. Τώρα, αυτή η διστριβή αν ζητήσετε μετά από ένα δεύτερο σεκόντο πόσο πράγμα διστριβή ας πούμε, στο εξ-πρόοδο με το εξ-διεύθυνμα αυτό το διστριβή είναι πολύ, πολύ καλό μοντέλο από ένα φυσικό διστριβή και η λόγω είναι ότι η θέση αυτής του πράγματος είναι αποφασίστη από το κυμηλωτικό επίπτυο τόσα διστριβή από μολύκες που πήγαν αυτό το πράγμα. Λοιπόν, αυτό είναι ένα τύπωνο μοντέλο που δημιουργεί ένα διάσημο φυσικό μοντέλο που βρίσκεται υπό το όνομα του Μόρφυ Μόρφυ και είναι το ίδιο μοντέλο που κάποιοι άνθρωποι χρησιμοποιούν για να περιγράψουν το κίνημα στις οικονομικές αγορές. Το αργούματο μπορεί να πάει ότι το κίνημα των πρόγραμμων έχει να κάνει με πολλά μικρές αποφάσεις και πολλά μικρές συμβουλές από πολλές, πολλές διαφορετικές πραγματοποιητές και οπότε η διαδικασία των αγορών μπορεί να είναι καλύτερα περιγράψης από φυσικά διεγραφαίες. Από την μικρή αργή, αυτό είναι αυτό που οι άνθρωποι ήθελαν να πιστεύουν μέχρι κάποια στιγμή τώρα. Η εμπειρία είναι ότι ακριβώς αυτές οι διαδικασίες είναι λίγο πιο σκληρές στο σημαίου ότι οι ακροδεξιές είναι λίγο πιο πιθανό να συμβαίνουν από το τι φαίνεται να ενδεικνύει αλλά ως πρώτο μοντέλο, ξανά, μπορεί να είναι ένα πιθανό αργούμενο γιατί να ξεκινήσουμε, έχουμε, τουλάχιστον ως μοντέλο που ξεκινήσει, ένα που συμβαίνει με φυσικά διεγραφαίες. Λοιπόν, αυτό είναι το φιλοσοφικό πλεονέκτημα. Στο πιο ακριβό πλεονεκτικό πλεονέκτημα, είναι σημαντικό να απολαύσουμε ακριβώς τι είδος δημοσίου το κεντρικό σύνοδο θεωρίας είναι. Είναι ένα δημοσίο για την συμμετοχή του CDF αυτών των δοξαλισμένων δοξαλισμών στο CDF της κανονικής. Λοιπόν, είναι ένα δημοσίο για την συμμετοχή των CDF. Δεν είναι ένα δημοσίο για την συμμετοχή των PMF ή συμμετοχή των PDF. Τώρα, αν κάνουμε επιπλέον μαθηματικές αποφάσεις, υπάρχουν διαφορετικές του κεντρικού σύνοδου θεωρίας που μιλούν για PDF και PMF, αλλά, γενικά, αυτό δεν είναι ο καθόλου το σημείο. Και θα προσφέρω αυτό με ένα πλότο εδώ, το οποίο δεν βρίσκεται στα σκηνά σας, αλλά απλά για να κάνω το σημείο. Προσφέρετε δύο διαφορετικές διαφορετικές διαφορές. Αυτή η διαφορετική διαφορετική παίρνει αριθμούς 1, 4, 7. Αυτή η διαφορετική διαφορετική μπορεί να παίρνει αριθμούς 1, 2, 4, 6 και 7. Λοιπόν, αυτή έχει μια περιοδικότητα των 3. Αυτή είναι λίγο πιο η μείωση των αριθμών είναι λίγο πιο ενδιαφέρουσα. Οι αριθμούς σε αυτές τις δύο διαφορετικές είναι κοκκομένες, ώστε να έχουν το ίδιο μέγεθος και την ίδια διαφορετικότητα. Τώρα, αυτό που θα κάνω είναι να πάρω 8 ανεξαρτητικές κοπές της διεθνής διαφορετικής και να πλότω το PMF της κομμάτιας των 8 διεθνών διαφορετικών. Τώρα, αν πλότω το PMF της κομμάτιας των 8 διεθνών, εγώ πάρω το πλότ που αντιμετωπίζεται στις μπούλες σε αυτό το διαγράμμα. Αν πάρω 8 ανεξαρτητικές κοπές με την επομένη διαφορετικότητα και τα προσθέτω και τα πλότω το PMF που πάρω είναι το 1 που διηγείται εδώ από το πλευρό. Τα 2 PMF παρουσιάζονται πολύ διαφορετικά, τουλάχιστον όταν δείτε τα όταν τα κοιτάτε. Στην άλλη πλευρά, αν πλότωτε τα CDF από αυτά, τότε τα CDF αν τα παρακολουθείτε με με το κανονικό CDF που είναι αυτή η συνεχής κύρυξη το CDF φυσικά ανέβει στα βήματα γιατί είμαστε κοιτάμε διεθνές διεθνές διεθνές αλλά είναι πολύ κοντά στο CDF και αν αντί N εξαρτήτων 18 αν ήμασταν να πάμε 16 τότε η συμπληρωμένη θα ήταν ακόμα καλύτερα. Λοιπόν, σχετικά με τα CDF όταν προσθέσουμε 8 ή 16 από αυτά πάμε πολύ κοντά στο κανονικό CDF θα έρθουμε σύντομα την ίδια πιστή αν ήμουν πλήρως πλήρως ευχαριστώ ότι πλήρως μιλάμε μόνο για κείμενα για CDF και όχι για PMF. Τώρα, στην πρακτική πώς χρησιμοποιείτε το θεωρίαμπροσύνης κεντρικού λιμούς ενώ μας λέει ότι μπορούμε να καταγραφούμε τις ποιότητες που είναι ποιότητες. Αν εγώ παραδείχνω ότι Zn είναι ποιότητα, είναι ο ίδιος σαν αν παραδείχνουμε ότι Sn είναι ποιότητα και μπορούμε να καταγραφούμε τις ποιότητες που έχουν να γίνονται σαν αν παραδείχνουμε ότι ποιότητες είναι ποιότητες. Αν εγώ παραδείχνω ότι Zn είναι ποιότητα, μπορούμε να καταγραφούμε τις ποιότητες που έχουν να γίνονται σαν αν παραδείχνουμε ποιότητες. Αυτό είναι το σύστημα που χρησιμοποιούμε για εξετάσεις. Είναι πολύ καλή δραστηριότητα. Δεν υπάρχουν καλές θεωρίες που μας δίνουν σκληρές ασφάλειες, γιατί η ποιότητα της εξετάσεις είναι πολύ διαφορετική από την καλή δραστηριότητα. Εδώ ξεκινάμε με μια διαφορετική ανεξαρτηστική διαφορά που δεχθεί από 1 έως 8. Ας προσθέσουμε ένα ποιότητο που είναι εξετάσεις. Θα προσθέσω 2 από αυτές τις δραστηριότητες, 2 δραστηριότητες με αυτή την ποιότητα και θα βρω την ποιότητα της σύμφωνα. Αυτή είναι μια συμβολή 2 διαφορετικών ανεξαρτησίων και πιστεύω ότι έχετε δει αυτό το δραστηριότητο πριν. Ας δώσουμε το ποιότητο της συμφωνίας 4 δραστηριότητες και θα δώσουμε αυτό που ξεκινά να παραμένει σαν κανονικό. Αν πάμε στο n εξαρτητός 32 τότε παραμένει σαν κανονικό και είναι πιστεύω ότι η συμφωνία δεν είναι συμμετρική. Αυτό είναι συμμετρικό γύρω από το μήνυμα. Αλλά αν ξεκινάμε με μια συμμετρική συμφωνία όπως αυτή είναι μια γεωμετρική συμφωνία τότε δεν λειτουργούν λίγο με την κανονική αλλά μπορείτε να πείτε ότι είναι διαφορετική από την κανονική αν εσείς εγκεντρικοποιείτε τα πληροφορία εδώ και εκεί. Εδώ βασίζεται στενά, εδώ λειτουργεί λίγο πιστεύω πιο συμμετρική μεταξύ αυτής και αυτής της κόλπας. Αν βγαίνετε στο 32 υπάρχει ακόμα λίγο συμμετρική αλλά τουλάχιστον τώρα άρχισε να δείχνει σαν κανονική διστρίβηση. Ο λόγος από αυτά τα πλότια είναι ότι μπορεί να διαφορετικά λίγο να αποκλείεται μια καλή αποκλήθεια. Αυτό μας λέει η εισοπλισία αυτών των πλότων. Λοιπόν, τώρα που γνωρίζουμε ότι έχουμε μια καλή αποκλήθεια στα χέρια μας, θα το χρησιμοποιήσουμε. Θα το χρησιμοποιήσουμε με την επαναλύθμιση ενός παραδείγμα από την τελευταία φορά. Αυτό είναι η τρόπη που κάνουμε είναι με εισοπλισμό ανθρώπων σε δίκαιο, και γράφουμε τα απάντημα που δίνουν, αν έχουν το συμφωνείο ή όχι. Λοιπόν, για κάθε άνθρωπο λάβουμε μια δίκαιο εισοπλισμό με πλότια μέσα από το πλότιο που μας ζητούν. Αυτή είναι η πλότια μέσα στο σάμπλο που απάντησε ναι. Και όπως συζητούσαμε την τελευταία φορά μπορείτε να ξεκινήσετε με με κάποιες επαγγελματίες για την επιτυχημένη ακριβότητα. Οπότε, οι σημείες εδώ είναι ότι θέλουμε να είναι 95% η προσδοκία μέσα από το πλήρισμα από το σωστό απαντήσμα. Λοιπόν, το συμφωνείο είναι αυτό, ότι το αποτέλεσμα του πλότια είναι να προσδοκίσει αυτή την συγκεκριμένη προσδοκία. Λοιπόν, θέλουμε να το κάνουμε χρησιμοποιώντας το θεωρίαμα κεντρικού σύνολου. Και ένα τρόπο να προστατεύουμε τα μηχανικά αυτής της καλύψης είναι να πάρουμε το πλήρισμα ενδιαφέρον και να προστατεύουμε το θεωρίαμα κεντρικού σύνολου. Λοιπόν, το συμφωνείο ας το γράψω σε πλήρισμα. Mn είναι αυτή η ποσότητα, οπότε το βάζω εδώ, μεινώντας F, το οποίο είναι το ίδιο ως nF διαπίδει για n. Λοιπόν, αυτό είναι το ίδιο ως αυτό το συμφωνείο. Λοιπόν, πώς μπορώ να βάλω στήλη στήλη στήλη στήλη εδώ, μπορώ να διαπίδω καμία πλευρά αυτής της αξιότητας με στήλη και μετά μπορώ να πάρω ένα πλήρισμα στήλη στήλη εδώ και να το δώσω στην άλλη πλευρά. Λοιπόν, αυτό το συμφωνείο είναι ειδικό γιατί το διεφημενό που έχουμε εδώ είναι Zn, ή το αξιότητο αξιότητα του Zn. Και μιλάμε για την πιθανότητα ότι το αξιότητο αξιότητα του Zn είναι μεγαλύτερο από ένα αριθμό που θα ζητήσει Z, το αξιότητο του Z είναι μεγαλύτερο από αυτό το αριθμό. Λοιπόν, αυτή είναι η πιθανότητα που θέλουμε να καταφερθεί και τώρα Z είναι μια βασική καθαρή αξιότητα. Υπάρχει μια μικρή δύσκολη εδώ, η μια είναι F εκατομμύρια 1 μεινά F και το μόνο που ξέρουμε για το σίγμα είναι ότι θα είναι μικρό από ένα μισό μισό μισό μισό μισό μισό μισό μισό μισό μισό μισό μισό μισό μισο μισό μισό μισό μισό μισό μισό μπορούμε να procedure το χωριό των σύνδεσμων το είναι 0.02 v2 of n. And my claim is that the numbers are related to each other in this particular way. Why is this? Sigma is less than 2, so 1 over sigma is bigger than 2. So since 1 over sigma is bigger than 2, this means that this number sits to the right of that number. So here we have the probability that z is bigger than this number. The probability of falling out there is less than the probability of falling in this interval. So that's what that last inequality is saying. This probability is smaller than that probability. This is the probability that we're interested in, but since we don't know sigma, we take the conservative value and we use an upper bound in terms of the probability of this interval here. And now we are in business. We can start using our normal tables to calculate probabilities of interest. So for example, let's say that we take n to be 10,000. How's the calculation going to go? We want to calculate the probability that the absolute value of z is bigger than 0.2 times 1,000, which is the probability that the absolute value of z is larger than or equal to 2. And here let's do some mechanics just to stay in shape, the probability that you're larger than or equal to 2 in absolute value. Since the normal is symmetric around the mean, this is going to be twice the probability that z is larger than or equal to 2. Can we use the cumulative distribution function of z to calculate this? Well, almost. The cumulative gives us probabilities of being less than something, not bigger than something. So we need one more step and write this as 1 minus probability that z is less than or equal to 2. And this probability now you can read off from the normal tables, and the normal tables will tell you that this probability is 0.9772. And you do get an answer, and the answer is 0.0456. OK, so we tried 10,000, and we find that our probability of error is 4.5%. So we're doing better than the spec that we had. So this tells us that maybe we have some leeway. Maybe we can use a smaller sample size and still stay without our specs. Let's try to find how much we can push the envelope. How much smaller can we take n? To answer that question, we need to do this kind of calculation essentially going backwards. We're going to fix this number to be 0.05 and work backwards here to find, did I do a mistake here? 10,000, so I'm missing a 0 here. OK, but I'm taking the square root, so it's 100, right? Where did the 0.02 come in from? Ah, from here, OK. All right. 0.02 times 100, that gives us 2. OK, all right. Very good. OK, so we'll have to do this calculation now backwards. Figure out if this is 0.05, what kind of number we're going to need here and then here. And from this, we will be able to tell what value of n do we need. OK, so we want to find n such that the probability that Z is bigger than 0.02 square root n is 0.05. OK, so Z is a standard normal random variable, and we want the probability that we are outside this range. We want the probability of those two tails together. Those two tails together should have probability of 0.05. This means that this tail by itself should have probability 0.025, and this means that this probability should be 0.975. Now, if this probability is to be 0.975, what should that number be? You go to the normal tables, and you find which is the entry that corresponds to that number. I actually brought a normal table with me, and 0.975 is down here, and it tells you that the number that corresponds to it is 1.96. So this tells us that this number should be equal to 1.96. And now from here, you do the calculations, and you find that n is 9604. OK, so with a sample of 10,000, we got probability of error 4.5%. With a slightly smaller sample size of 9,600, we can get the probability of a mistake to be 0.05, which was exactly our spec. So these are essentially the two ways that you're going to be using the central limit theorem. Either you're given n, and you try to calculate probabilities, or you're given the probabilities, and you want to work backwards to find n itself. So in this example, the random variable m, the random variable that we dealt with, was of course a binomial random variable. The Xi's were Bernoulli, so the sum of the Xi's were Bernoulli, so the sum of the Xi's was binomial. So the central limit theorem certainly applies to the binomial distribution. To be more precise, of course it applies to the standardized version of the binomial random variable. So here's what we did essentially in the previous example. We fixed the number p, which is the probability of success in our experiments. p corresponds to f in the previous example. Let every Xi be a Bernoulli random variable, and our standing assumption is that these random variables are independent. When we add them, we get a random variable that has a binomial distribution. We know the mean and the variance of the binomial. So we take a send, we subtract the mean, which is this, divide by the standard deviation. The central limit theorem tells us that the cumulative distribution function of this random variable is a standard normal random variable in the limit. So let's do one more example of a calculation. Let's take n to be, let's choose some specific numbers to work with. So in this example, the first thing to do is to find the expected value of Sn, which is n times p. It's 18. Then we need to write down the standard deviation. The variance of Sn is the sum of the variances. It's np1 minus p. And in this particular example, p times 1 minus p is 1 4th, n is 36, so this is 9. That tells us that the standard deviation of Sn is equal to 3. Sn is equal to 3. Therefore, what we're going to do is to take the event of interest, which is Sn less than 21, and rewrite it in a way that involves the standardized random variable. So to do that, we need to subtract the mean. So we write this as Sn minus 3 should be less than or equal to 21 minus 3. This is the same event. And then divide by the standard deviation, which is 3, and we end up with this. So the event of interest should subtract 18, which is going to give me a much nicer number out here, which is 1. So the event of interest that Sn is less than 21 is the same as the event that a standard normal random variable is less than or equal to 1. And once more, you can look this up at the normal tables, and you find that the answer that you get is 0.43. Now it's interesting to compare this answer that we got through the central limit theorem with the exact answer. The exact answer involves the exact binomial distribution. What we have here is the binomial probability that Sn is equal to k. Sn being equal to k is given by this formula. And we add over all values for k going from 0 up to 21. We write a two-line code to calculate the sum, and we get the exact answer, which is 0.8785. So there's pretty good agreement between the two, although you wouldn't call that necessarily excellent agreement. Can we do a little better than that? Let's try it. OK. It turns out that we can. And here's the idea. So our random variable Sn has a mean of 18. It has a binomial distribution. It's described by a PMF that has a shape roughly like this, and which keeps going on. Using the central limit theorem is basically pretending that Sn is normal with the right mean and variance. So pretending that Zn has 0 mean unit variance, we approximate it with Z that has 0 mean unit variance. If you were to pretend that Sn is normal, you would approximate it with a normal that has the correct mean and correct variance, so it would still be centered at 18. And it would have the same variance as the binomial PMF. So using the central limit theorem essentially means that we keep the mean and the variance what they are, but we pretend that our distribution is normal. We want to calculate the probability that Sn is less than or equal to 21. I pretend that my random variable is normal, so I draw a line here, and I calculate the area under the normal curve going up to 21. That's essentially what we did. Now a smart person comes around and says Sn is a discrete random variable. So the event that Sn is less than or equal to 21 is the same as Sn being strictly less than 22, because nothing in between can happen. So I'm going to use the central limit theorem approximation by pretending again that Sn is normal, and finding the probability of this event while pretending that Sn is normal. So what this person would do would be to draw a line here at 22 and calculate the area under the normal curve all the way to 22. Who is right? Which one is better? Well, neither, but we can do better than both if we sort of split the difference. So another way of writing the same event for Sn is to write it as Sn being less than 21.5. In terms of the discrete random variable Sn, all three of these are exactly the same event. But when you do the continuous approximation, they give you different probabilities. It's a matter of whether you integrate the area under the normal curve up to here, up to the midway point, or up to 22. It turns out that integrating up to the midpoint is what gives us the better numerical results. So we take here 21.5, and we integrate the area under the normal curve up to here. So let's do this calculation and see what we get. What would we change here? Instead of 21, we now write 21.5. This 18 becomes, no, that 18 stays what it is, but this 21 becomes 21.5. And so this 1 becomes 1 plus 0.5 by 3. This is 117. So we now look up at the normal tables and ask for the probability that Z is less than 1.17. So this here gets approximated by the probability that the standard normal is less than 1.17. And the normal tables will tell us that this is 0.879. Going back to the previous slide, what we got this time with this improved approximation is 0.879. This is a really good approximation of the correct number. This is what we got using the 21. This is what we get using the 21.5. And it's an approximation that's sort of right on, a very good one. The moral from this numerical example is that doing this 1 and 1.5 correction actually does give us better approximations. In fact, we can use this 1.5 idea to even calculate in individual probabilities. So suppose you want to approximate the probability that Sn equal to 19. If you were to pretend that Sn is normal and calculate this probability, the probability that the normal random variable is equal to 19 is 0. So you don't get an interesting answer. You get a more interesting answer by writing this event, 19, as being the same as the event of falling between 18.5 and 19.5, and using the normal approximation to calculate this probability. In terms of our previous picture, this corresponds to the following. We are interested in the probability that Sn is equal to 19, so we're interested in the height of this bar. We're going to consider the area under the normal curve going from here to here, and use this area as an approximation for the height of that particular bar. So what we're basically doing is we take the probability under the normal curve that's assigned over a continuum of values and attribute it to different discrete values. Whatever is above the midpoint gets attributed to 19, whatever is below that midpoint gets attributed to 18. So this green area is our approximation of the height of the value of the PMF at 19. So similarly, if you wanted to approximate the value of the PMF at this point, you would take this interval and integrate the area under the normal curve over that interval. It turns out that this gives a very good approximation of the PMF of the binomial. And actually, this was the context in which the central limit theorem was proved in the first place when this business started. So this business goes back a few hundred years, and the central limit theorem was first proved by considering the PMF of a binomial random variable when P is equal to 1 half. People did the algebra, and they found out that the exact expression for the PMF is quite well approximated by that expression that you would get from the normal distribution. Then the proof was extended to binomials for more general values of P. So here we talk about this as a refinement of the general central limit theorem, but historically that refinement was where the whole business got started in the first place. All right, so let's go through the mechanics of approximating the probability that Sn is equal to 19, exactly 19. As we said, we're going to write this event as an event that covers an interval of unit length from 18 1 1 to 19 1 1. This is the event of interest. First step is to massage the event of interest so that it involves our Zn random variable. So subtract 18 from all sides, divide by the standard deviation of 3 from all sides. That's an equivalent representation of the event. This is our standardized random variable Zn. These are just these numbers. And to do an approximation, we want to find the probability of this event, but Zn is approximately normal. So we plug in here the Z, which is the standard normal. So we want to find the probability that the standard normal falls inside this interval. You find this using CDFs, because this is the probability that you're less than this, but not less than that, so it's a difference between two cumulative probabilities. Then you look up your normal tables, you find numbers for these quantities, and finally you get a numerical answer for an individual entry of the PMF of the binomial. This is a pretty good approximation, it turns out. If you were to do the calculations using the exact formula, you would get something which is pretty close, meaning an error in the third digit. This is pretty good. So I guess what we did here with our discussion of the binomial slightly contradicts what I said before, that the central limit theorem is a statement about cumulative distribution functions. In general, it doesn't tell you what to do to approximate PMFs themselves. And that's indeed the case in general. On the other hand, for the special case of a binomial distribution, the central limit theorem approximation with this 1-1 half correction is a very good approximation even for the individual PMF. All right. So we spent quite a bit of time on mechanics, so let's spend the last few minutes today thinking a bit and look at a small puzzle. So the puzzle is the following. Consider a Poisson process that runs over a unit interval and where the arrival rate is equal to 1. So this is the unit interval. And let X be the number of arrivals. And let X be the number of arrivals, and this is Poisson with mean 1. Now let me take this interval and divide it into n little pieces. So each piece has length 1 over n. And let Xi be the number of arrivals during the i-th little interval. OK. What do we know about the random variables Xi? They are themselves Poisson. It's a number of arrivals during a small interval. We also know that when n is big, so the length of the interval is small, these Xi's are approximately Bernoulli with mean 1 over n. I guess it doesn't matter whether we model them as Bernoulli or not. What matters is that the Xi's are independent. Why are they independent? Because in a Poisson process, these joint intervals are independent of each other. So the Xi's are independent. And they also have the same distribution. And we have that X, the total number of arrivals, is the sum of the Xn's. So the central limit theorem tells us that approximately the sum of independent, identically distributed random variables, when we have lots of these random variables, behaves like a normal random variable. So by using this decomposition of X into a sum of i.i.d. random variables, and by using values of n that are bigger and bigger, by taking the limit, it should follow that X has a normal distribution. On the other hand, we know that X has a Poisson distribution. So something must be wrong in this argument here. Can we really use the central limit theorem in this situation? So what do we need for the central limit theorem? We need to have independent, identically distributed random variables. We have it here. We want them to be independent of each other. We have it here. We want them to have a finite mean and finite variance. We also have it here. Means variances are finite. What is another assumption that was never made explicit but essentially was there? Or in other words, what is the flaw in this argument that uses the central limit theorem here? Any thoughts? So in the central limit theorem, we said consider, fix a probability distribution and let the Xi's be distributed according to that probability distribution, and add a larger and larger number of Xi's. But the underlying unstated assumption is that we fix the distribution of the Xi's. As we let n increase, the statistics of each Xi do not change, whereas here I'm playing a trick on you. As I'm taking more and more random variables, I'm actually changing what those random variables are. When I take a larger n, the Xi's are random variables with a different mean and a different variance. So I'm adding more of these, but at the same time, in this example, I'm changing their distributions. That's something that doesn't fit the setting of the central limit theorem. The central limit theorem, you first fix the distribution of the X's, you keep it fixed, and then you consider adding more and more according to that particular fixed distribution. So that's the catch. That's why the central limit theorem does not apply to this situation, and we're lucky that it doesn't apply, because otherwise we would have a huge contradiction destroying probability theory. But now that still leaves us with a little bit of a dilemma. Suppose that here, essentially, we're adding independent Bernoulli random variables. And if I tell you, so the issue is that the central limit theorem has to do with asymptotics as n goes to infinity. And if we consider a binomial, and somebody gives us specific numbers about the parameters of that binomial, it might not necessarily be obvious what kind of approximation do we use. In particular, we do have two different approximations for the binomial. If we fix p, then the binomial is the sum of Bernoullis that come from a fixed distribution. We consider more and more of these. When we add them, the central limit theorem tells us that we get the normal distribution. There's another sort of limit, which has the flavor of this example, in which we still deal with a binomial sum of n Bernoullis. We let that sum, the number of the Bernoullis, go to infinity. But each Bernoulli has a probability of success that goes to 0. And we do this in a way so that np, the expected number of successes, stays finite. This is the situation that we dealt with when we first defined our Poisson process. We have a very, very large number of slots, of time slots, but during each time slot, there's a tiny probability of obtaining an arrival. Under that setting, in discrete time, we have a binomial distribution, or a Bernoulli process. But when we take the limit, we obtain the Poisson process and the Poisson approximation. So these are two equally valid approximations of the binomial, but they're valid in different asymptotic regimes. In one regime, we fix p, let n go to infinity. In the other regime, we let both n and p change simultaneously. Now in real life, you're never dealing with the limiting situations. You're dealing with actual numbers. So if somebody tells you that the numbers are like this, then you should probably say that this is the situation that fits the Poisson description. Large number of slots, with each slot having a tiny probability of success. On the other hand, if p is something like this and n is 500, then you expect to get a distribution for the number of successes. It's going to have a mean of 50, and to have a fair amount of spread around there. It turns out that the normal approximation would be better in this context. As a rule of thumb, if n times p is bigger than 10 or 20, you can start using the normal approximation. If n times p is a small number, then you prefer to use the Poisson approximation. But there's no hard theorems or rules about how to go about this. OK, so from next time, we're going to switch base again, and we're going to put together everything we learned in this class to start solving inference problems.