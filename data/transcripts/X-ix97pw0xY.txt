 The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. Chapter is a natural capstone chapter for this entire course. We'll see some of the things we've seen during maximum likelihood and some of the things we've seen during linear regression, some of the things we've seen in terms of the basic modeling that we've had before. We're not going to go back to much inference questions. It's really going to be about modeling. And in a way, generalized linear models, as the word says, are just a generalization of linear models. And they're actually extremely useful. They're often forgotten about, and people just jump onto machine learning and sophisticated techniques. But those things do the job quite well. So let's see in what sense they are a generalization of the linear model. So remember, the linear model looked like this. We said that y was equal to x transpose beta plus epsilon. That was our linear regression model. And another way to say this is that if I, let's assume that those were, say, Gaussian with mean 0 and identity covariance matrix, then another way to say this is that the conditional distribution of y given x is a Gaussian with mean x transpose beta and variance, well, we had a sigma square, which I will forget as usual, x transpose beta and then sigma square. So here, we just assumed that, so what is regression? It's just saying I'm trying to explain y as a function of x given x. I'm assuming a distribution for the y. And this x is just going to be here to help me model what the mean of this Gaussian is. I mean, I could have something crazy. I could have something that looks like y given x is n0 x transpose beta. And then this guy could be some other thing, which looks like, I don't know, some x transpose gamma squared times, I don't know, x x transpose plus identity, some crazy thing that depends on x here. And we deliberately assume that all the thing that depends on x shows up in the mean. And so what I have here is that y given x is a Gaussian with a mean that depends on x and covariance matrix sigma square identity. Now, the linear model assumed a very specific form for the mean. It said, I want the mean to be equal to x transpose beta, which, remember, was the sum from, say, j equals 1 to p of beta j xj, where the xj's are the coordinates of x. But I could do something also more complicated. I could have something that looks like, instead, replace this by, I don't know, sum of beta j log of x to the j divided by x to the j squared, or something like this. I could do this as well. So there's two things that we've assumed. The first one is that when I look at the conditional distribution of y given x, x affects only the mean. I also assumed that it was Gaussian, and that it affects only the mean. And the mean is affected in a very specific way, which is linear in x. So this is essentially the things we're going to try to relax. So the first thing that we assume, the fact that y was Gaussian and had only its mean that depended on x, is what's called the random component. It just says that the response variables sort of make sense to assume that they're Gaussian. And everything was essentially captured. So there's this property of Gaussians that if you tell me if the variance is known, all you need to tell me to understand exactly what the distribution of a Gaussian is, all you need to tell me is its expected value. So that's this mu of x. And the second thing is that we had this link that says, well, I need to find a way to use my x's to explain this mu. And the link was exactly mu of x was equal to x transpose beta. OK? Now, we are talking about generalized linear models. So this part here, where mu of x is of the form, the way I want my beta, my x, to show up is linear. This will never be questioned. In principle, I could add a third point, which is just question this part, the fact that mu of x is x transpose beta. I could have some more complicated nonlinear function of x. And I will never do that, because we're talking about generalized linear model. The only thing with generalized are the random component, the conditional distribution of y given x, and the link that just says, well, once you actually tell me that the only thing I need to figure out is the mean, I'm just going to slap it exactly this x transpose beta thing without any transformation of x transpose beta. OK? So those are the two things. It will become clearer what I mean. This sounds like a tautology, but let's just see how we could extend that. So what we're going to do in generalized linear models, so when I talk about GLMs, the first thing I'm going to do with my x is turn it into some x transpose beta. And that's just the L part. This I'm not going to be able to change. That's the way it works. I'm not going to do anything nonlinear. But the two things I'm going to change is this random component, which is that y, which used to be some Gaussian with mean mu of x variance sigma squared. So y given x, sorry. This is going to become y given x follows some distribution. And I'm not going to allow any distribution. I want something that comes from the exponential family. Who knows what the exponential family of distribution is? This is not the same thing as the exponential distribution. It's a family of distribution. All right, so we'll see that. What can that be? Oh, yeah, that's actually my. I'm sorry? You can mute your laptop. OK. I'm in presentation mode. That should not happen. OK, so hopefully this is muted. So essentially, this is going to be a family of distributions. And what makes them exponential typically is that there's an exponential that shows up in the definition of the density. We'll see that the Gaussian belongs to the exponential family. But there are slightly less expected ones, because there's this crazy thing that a to the x is exponential x log a, which makes the exponential show up without being there. So if there's an exponential of some power, it's going to show up. But it's more than that. So we'll actually come to this particular family of distribution. Why this particular family? Because in a way, everything we've done for the linear model with Gaussian is going to extend fairly naturally to this family. And it actually also, because it encompasses pretty much everything, all the distributions we've discussed before. All right, so the second thing that I want to question, so before we just said, well, mu of x was directly equal to this thing. Mu of x was directly x transpose beta. So I knew I was going to have an x transpose beta. And I said, well, I could do something with this x transpose beta before I used it to explain the expected value. But I'm actually taking it like that. Here we're going to say, let's extend this to some function is equal to this thing. Now, admittedly, this is not the most natural way to think about it. What you would probably feel more comfortable doing is write something like mu of x is a function. Let's call it f of x transpose beta. But here I just decide to call f g inverse. OK, that's just my g inverse, yes. Is this different than just transforming the x's? Yeah. I mean, what transformation do you want to put on your x's? Like, is this equivalent to just applying some function to each individual x component and then multiplying that beta to get the mean? Oh, no, certainly not, right? I mean, if I force you to work with x1 plus x2, you cannot work with any function of x1 plus any function of x2, right? So yeah, this is different. So yeah, the transformation would be just the simple part of your linear regression problem, where you would take your x's, transform them, and then just apply another linear regression. This is genuinely new. Any other question? All right, so this function g, and the reason why I sort of have to stick to this slightly less natural way of defining it is because that's g that gets a name, not g inverse that gets a name. And the name of g is the link function. So if I want to give you a generalized linear model, I need to give you two ingredients. The first one is the random component, which is the distribution of y given x. And it can be anything in what's called the exponential family of distributions. So for example, I could say y given x is Gaussian with mean ux sigma squared identity. But I could also tell you y given x is gamma with shape parameter equal to alpha of x. I could do some weird things like this. And the second thing is I need to give you a link function. And the link function is going to become very clear how you pick a link function. And the only reason that you actually pick a link function is because of compatibility. This mu of x, I call it mu because mu of x is always the conditional expectation of y given x, always, which means that let's think of y as being a Bernoulli random variable. Where does mu of x live? AUDIENCE 2. 0, 1. 0, 1, right? That's the expectation of a Bernoulli. It's just the probability that my coin flip gives me 1. So it's a number between 0 and 1. But this guy right here, if my x's are anything, think of any body measurements, plus I take linear combinations with arbitrarily large coefficients, this thing can be any real number. So the link function, what it's effectively going to do is make those two things compatible. It's going to take my number, which, for example, is constrained to be between 0 and 1, and map it into the entire real line. If I have mu, which is forced to be positive, for example, in an exponential distribution, the mean is positive, right? That's the, say, I don't know, inter-arrival time for Poisson process. This thing is known to be positive for an exponential. I need to map something that's exponential to the entire real line. I need a function that takes something positive and then tickets everyone. So we'll see, by the end of this chapter, you will have 100 ways of doing this. But there are some more traditional ones than other. So before we go any further, I gave you this example of a Bernoulli random variable. Let's see a few examples that actually fit there. Yes? AUDIENCE 1 Will it come up later if we already know why the mean distribution is increasing entirely? Why can't we do it? PHILIPPE RIGOLLET Well, actually, this will not come up later. It should be very clear from here. Because if I actually have a model, I just want it to be plausible, right? I mean, what happens if I suddenly decide that my, so this is what's going to happen. You're going to have only data to fit this model. Let's say you actually forget about this thing here. You can always do this, right? You can always say, I'm going to pretend my y's just happen to be the realizations of, say, Gaussians that happen to be 0 or 1 only. You can always stuff that in some linear model, right? You will have some least squares estimator for beta. But what's going to happen, and it's going to be fine. For all the points that you see, it will definitely put some number that's actually between 0 and 1. So this is what your picture is going to look like. You're going to have a bunch of values for x. This is your y. And so these are the values of x that you will get. And for y, you will see either 0 or 1, right? That's what your Bernoulli data set would look like with a one-dimensional x. Now, if you do least squares on this, you will find this. And for this guy, this line certainly takes values between 0 and 1. But let's say now you get an x here. You're going to actually start pretending the probability that it spits out one conditionally in x is like 1.2, and that's going to be weird. OK? Any other questions? All right, so let's start with some examples. Right? I mean, you got so used to them throughout this course. So the first one is all these things are taken. So there's a few books on generalizing your models, generalize additive models, and there's tons of applications that you can see. Those are extremely versatile. And as soon as you want to do modeling to explain some y given x, you sort of need to do that if you want to go beyond linear models. So this was the disease occurring rate. So you have a disease epidemic, and you want to basically model the expected number of new cases given at a certain time. OK? So you have time that progresses for each of your reservation. Each of your relation is a timestamp, say, I don't know, 20th day. And your response is the number of new cases. And you're going to actually put your model directly on mu, right? When I looked at this, everything here was on mu itself, on the expected, right? Mu of x is always the expected, the conditional expectation of y given x. Right? So all I need to model is this expected value. So this mu, I'm going to actually say, so I look at some parameters, and it says, well, it increases exponentially. So I want to have some sort of exponential trend. I can parameterize that in several ways. And the two parameters I want to slap in is some sort of gamma, which is just the coefficient. And then there's some rate delta that's in the exponential. OK? So if I tell you it's exponential, that's a nice family of functions you might want to think about. OK, so here, mu of x, if I want to keep the notation x, is gamma exponential delta x, right? Except that here, my x are t1, t2, t3, et cetera. OK? And I want to find what the parameters gamma and delta are because I want to be able to maybe compare different epidemics and see if they have the same parameter or maybe just do some prediction based on the data that I have to extrapolate in the future. OK? So here, clearly, mu of x is not of the form x transpose beta. Right? That's not x transpose beta at all. And it's actually not even a function of x transpose beta. Right? There's two parameters, gamma and delta, and it's not of the form. So here, I have x, which is 1 and x. Right? I have two parameters. So what I do here is that I say, well, first, let me transform mu in such a way that I can hope to see something that's linear. So if I transform mu, I'm going to have log of mu, which is log of this thing. Right? So log of mu of x is equal to log of gamma plus log of exponential delta x, which is delta x. OK? And now, this thing is actually linear in x. So I have that this guy is my first beta 1. And so that's beta 1 times 1. And this guy is beta 2 times, sorry, let's say beta 0 times 1. And this guy is beta 1 times x. OK? So that looks like a linear model. I just have to change my parameters. My parameters, beta 1 becomes the log of gamma, and beta 2 becomes delta itself. And the reason why we do this is because, well, the way we put those gamma and those delta was just so that we have some parametrization. It just so happens that if we want this to be linear, we need to just change the parametrization itself. This is going to have some effects. We know that it's going to have some effect in the Fisher information. It's going to have a bunch of effect to change those things. But that's what needs to be done to have a generalized linear model. Now, here, the function that I took to turn it into something that's linear is simple. It came directly from some natural thing it would do here, which is taking the log. And so the function g, the link that I take, is called the log link, very creatively. And it's just the function that I apply to mu so that I see something that's linear and that looks like this. OK? So now, this only tells me how to deal with the link function. But I still have to deal with 0.1. And this, again, is just some modeling. Given some data, some random data, what distribution do you choose to explain the randomness? And this, I mean, unless there's no choice, it's just a matter of practice. I mean, why would it be Gaussian and not doubly exponential? There's matters of convenience that come into this. And there's just matter of experience that come into this. I remember when you chat with engineers, they have a very good notion of what the distribution should be. They have Weibull distributions. They do optics and things like this. So there's some distributions that just come up. But sometimes, you just have to work. Now, here, what do we have? The thing we're trying to measure y, as we said, so mu is the conditional expectation of y given x. But y is the number of new cases, right? Well, it's a number of. And the first thing you should think of when you think about number of, if it were bounded above, you would think binomial, baby. But here, it's just a number. So you think Poisson. That's how insurers think. I have a number of claims per year. This is a Poisson distribution. And hopefully, they can model the conditional distribution of the number of claims given everything that they actually ask you in this survey that I hear you now fill in 15 minutes. All right, so now you have this Poisson distribution. And that's just a modeling assumption. There's no particular reason why you should do this, except that that might be a good idea. And the expected value of your Poisson has to be this mu i at time i. Any question about this slide? So let's switch to another example. Another example is the so-called prey capture rate. So here, what you're interested in is the rate capture of prey's Yi for a given prey. And you have Xi, which is your explanation. And this is just the density of prey. So you're trying to explain the rate of captures of preys given the density of the prey. And so you need to find some sort of relationship between the two. And here again, you talk to experts. And what they tell you is that, well, it's going to be increasing. Animals, like predators, are going to just eat more if there's more preys. But at some point, they're just going to level off because they're just going to be completely full. And they're going to stop capturing those preys. And you're just going to have some phenomenon that looks like this. So here is a curve that sort of makes sense. As your capture rate goes from 0 to 1, you're increasing. And then you see you have this concave function that says that at some point, it levels off. So here, one way I could, I mean, there's again many ways I could just model a function that looks like this. But a simple one that has only two parameters is this one, where mu i is just this function of Xi, where I have some parameter alpha here and some parameter h here. So there's clearly, so this function, there's one that essentially tells you. So this thing starts at 0 for sure. And essentially, alpha tells you how sharp this thing is. And h tells you at which point you end here. It's not exactly what those values are equal to, but it tells you this. So simple. And well, no, OK, sorry. That's actually alpha, which is the maximum capture rate. And h represents the prey density at which the capture rate is. So that's the half time. So there's actual values for this. So now I have this function. It's certainly not a function. I don't see it as a function of x. So I need to find something that looks like a function of x. OK? So now here, there's no log. There's no, well, I could actually take a log here. But I would have log of x and log of x plus h. So that would be weird. So what we propose to do here is to look, rather than looking at mu i, we look at 1 over mu i. And so since your function was mu i, when you take 1 over mu i, you get h plus xi divided by alpha xi, which is h over alpha times 1 over xi plus 1 over alpha. And now if I am willing to make this transformation of variables and say, actually, my x, whether it's the density of prey or the inverse density of prey, it really doesn't matter. I can always make the transformation when the data comes. Then I'm actually just going to think of this as being some linear function, beta 0 plus beta 1, which is this guy, times 1 over xi. And now my new variable becomes 1 over xi. And now it's linear. And the transformation I had to take was this 1 over x, which is called the reciprocal link. You can probably guess what the exponential link is going to be and things like this. So we'll talk about other links that have slightly less obvious names. Now, again, modeling. So this was the random component. This was the easy part. Now I need to just pour in some domain knowledge about how do I think this function, this y, which is the rate of capture of preys. I want to understand how this thing is actually changing. What is the randomness of the thing around its mean? And something that comes from this textbook, the standard deviation of capture rate might be approximately proportional to the mean rate. You need to find a distribution that actually has this property. And it turns out that this happens for gamma distribution. In gamma distributions, just like, say, for Poisson distribution, for Poisson, the variance and the mean are of the same order. Here is the standard deviation that's of the same order as the mean for gammas. And it's a positive distribution as well. So here is a candidate. Now, since we're sort of constrained to work under the exponential family of distributions, then you can just go through your list and just decide which one works best for you. All right, third example. So here we have binary response. Here, essentially, the binary response variable indicates the presence or absence of post-covariative deforming for kyphosis on children. And here, rather than having one covariate, which was before, in the first example, was time, in the second example was the density, here there's three covariates. So you measure on children. The first one is age of the child. The second one is the number of vertebrae involved in the operation. And the third one is the start of the range, so where it is on the spine. So the response variable here is, did it work or not? I mean, that's very simple. And so here, it's nice, because the random component is the easiest one. As I said, any random variable that takes only two outcomes must be a Bernoulli. So that's nice. There's no modeling going on here. So you know that y given x is going to be Bernoulli, but of course, all your efforts are going to try to understand what the conditional mean of your Bernoulli, what the conditional probability of being 1 is going to be. And so in particular, so I'm just here. I'm spelling it out before we close those examples. I cannot say that mu of x is x transpose beta for exactly this picture that I drew for you here. There's just no way here. The goal of doing this is certainly to be able to extrapolate for yet unseen children whether this is something that we should be doing, and maybe the range of x's is actually going to be slightly out. And so OK, I don't want to say that I have a negative probability of outcome or a positive one, sorry, or a 1 that's lower than 1, so I need to make this transformation. What I need to do is to transform mu, which is we know only a number, all we know is a number between 0 and 1, and we need to transform it in such a way that it maps the entire real line, or reciprocally to say that, or inversely I should say, that f of x transpose beta should be a number between 0 and 1. I need to find a function that takes any real number and maps it into 0 and 1, and we'll see that again, but you have an army of functions that do that for you. What are those functions? I'm sorry? AUDIENCE MEMBER 2. Trait function. PHILIPPE RIGOLLET. Trait? AUDIENCE MEMBER 2. Trait, trait, trait. PHILIPPE RIGOLLET. Oh. Yeah, I want them to be invertible, right? AUDIENCE MEMBER 2. Yeah. PHILIPPE RIGOLLET. Yeah. AUDIENCE MEMBER 2. Longest trait. PHILIPPE RIGOLLET. I have an army of function. I'm not asking for one soldier in this army. I want the name of this army. AUDIENCE MEMBER 2. They're invertible. PHILIPPE RIGOLLET. Well, they're not really invertible either, right? So they're actually in stats textbooks, because remember, statisticians don't know how to integrate functions, but they know how to turn a function into a Gaussian integral, so we know it integrates to 1, and things like this. Same thing here. We don't know how to build functions that are invertible and map the entire real line to 0, 1, but there's all the cumulative distribution functions that do that for us. So I can use any of those guys, and that's what I'm going to be doing, actually. All right, so just to recap what I just said as we were speaking, so a normal linear model is not appropriate for those examples if only because the response variable is not necessarily Gaussian. So and also because the linear model has to be, the mean has to be transformed before I can actually apply a linear model for all these plausible nonlinear models that I actually came up with. So the family we're going to go for is the exponential family of distributions, and we're going to be able to show, so one of the nice part of this is to actually compute maximum likelihood estimators for those, right? In the linear model, maximum like, in the Gaussian linear model, maximum likelihood was as nice as it gets, right? This actually was the least squares estimator. We had a closed form, x transpose x inverse x transpose y, and that was it. We had to just take one derivative. Here, we're going to have a generally concave likelihood. We're not going to be able to actually solve this thing directly in closed form unless it's Gaussian, but we will have, we'll see actually how this is not just a black box optimization of a concave function. We have a lot of properties of this concave function, and we will be able to show some iterative algorithms. We'll basically see how, when you open the box of convex optimization, you will actually be able to see how things work and actually implement it using least squares. So each iteration of this iterative algorithm will essentially be a least square, so that's actually quite huge. It's also very demonstrative of statisticians being pretty ingenious so that they don't have to call in some statistical software, but just can repeatedly call their least squares oracle within a statistical software. OK, so what is the exponential family? I promised you the exponential family. Before we go into this, let me just tell you something about exponential families, and what's the only thing that differentiates an exponential family from all possible distributions? An exponential family has two parameters, and those are not really parameters, but there's the theta parameter of my distribution. So it's going to be indexed by some parameter. Here, I'm only talking about the distribution of, say, some random variable or some random vector. So here, in this slide, you see that the parameter theta that indexes those distribution is k-dimensional, and the space of the x's that I'm looking at, so that should really be y. So what I'm going to plug in here is the conditional distribution of y given x, and theta is going to depend on x. But this really is the y. That's the distribution of the response variable. And so this is on q. So I'm going to assume that y is q-dimensional. Clearly, soon q is going to be equal to 1, but I can define those things generally. So I have this. I have to tell you what this looks like, and let's assume that this is a probability density function. So this notation, the fact that I just put my theta in subscript, is just for me to remember that this is the variable that indicates the random variable, and this is just the parameter. But I could just write it as a function of theta and x. This is just going to be, if you were in multivariable calc, you would have two parameters, theta and x, and you would need to give me a function. Now, think of x and theta as being one-dimensional at this point. Think of all the functions that can be depending on theta and x. There's many of them. And in particular, there's many ways theta and x can interact. What the exponential family does for you is that it restricts the way these things can actually interact with each other. It's essentially saying the following. It's saying this is going to be of the form exponential. So this exponential is really not much, because I could put a log next to it. But what I want is that the way theta and x interact has to be of the form theta times x in an exponential. So that's one of the ways you can think of them interacting. You just take the product of the two. Now, clearly, this is not a very rich family. So what I'm allowing myself is to just slap on some terms that depend only on theta and depend only on x. So let's just call this thing f of x g of theta. So here, I've restricted the way theta and x can interact. So I have something that depends only on x, something that depends only on theta. And here, I have this very specific interaction. And that's all that exponential families are doing for you. So if we go back to this slide, this is much more general. If I want to go from theta and x in r to theta and x theta in r to theta in rk and x in rq, I cannot take the product of theta and x. I cannot even take the inner product between theta and x, because they're not even of compatible dimensions. But what I can do is to first map my theta into something and map my x into something so that I actually end up having the same dimensions. And then I can take the inner product. That's the natural generalization of this simple product. So what I have is if I want to go from theta to x, what I'm going to first do is I'm going to take theta eta of theta. So let's say eta 1 of theta to eta k of theta. And then I'm going to actually take x becomes t1 of x all the way to tk of x. And what I'm going to do is take the inner product. So let's call this eta. And let's call this t. And I'm going to take the inner product of eta and t, which is just the sum from j equal 1 to k of eta j of theta times tj of x. So that's just a way to say I want this simple interaction. But in higher dimension, the simplest way I can actually make those things happen is just by taking inner product. And so now what it's telling me is that the distribution, I want the exponential times something that depends only on theta and something that depends only on x. And so what it tells me is that when I'm going to take p of theta x, it's just going to be something which is exponential times the sum from j equal 1 to k of eta j theta tj of x. And then I'm going to have a function that depends only. So let me write it for now like c of theta. And then a function that depends only on x. Let me call it h of x. And for convenience, there's no particular reason why I do that. I'm taking this function c of theta, and I'm just actually pushing it in there. So I can write c of theta as exponential minus log of 1 over c of theta. And now I have exponential times exponential. So I push it in, and this thing actually looks like exponential sum from j equal 1 to k of eta j theta tj of x minus log 1 over c of theta times h of x. And this thing here, log 1 over c of theta, I call actually b of theta. Because c, I called it c, but I can actually directly call it this guy b, and I don't actually care about c itself. Now, why don't I put back also h of x in there? Because h of x is really here to just, how to put it? h of x and b of theta don't play the same role. b of theta, in many ways, is a normalizing constant. I want this density to integrate to 1. If I did not have this guy, I'm not guaranteed that this thing integrates to 1. But by tweaking this function, b of theta or c of theta, their equivalent, I can actually ensure that this thing integrates to 1. So b of theta is just a normalizing constant. h of x is something that's going to be funny for us. It's going to be something that allows us to be able to treat both discrete and continuous variables within the framework of exponential families. So for those that are familiar with this, this is essentially saying that h of x is really just a change of measure. When I actually look at the density of p of theta, this is with respect to some measure, the fact that I just multiply by a function of x just means that I'm not looking that this guy here, without h of theta, is not the density with respect to the original measure, but it's the density with respect to the distribution that has h as a density. That's all I'm saying. So I can first transform my x's and then take the density with respect to that. If you don't want to think about densities or measures, you don't have to. This is just the way. This is just the definition. Is there any question about this definition? So it looks complicated, but it's actually essentially the simplest way you could think about it. You want to be able to have x and theta interact, and you just say, I want the interaction to be of the form exponential x times theta. And if they're higher dimensions, I'm going to take the exponential of the function of x inner product for the function of theta. So I claimed since the beginning that the Gaussian was such an example, so let's just do it. Is the interaction between theta and x in a Gaussian of the form inner product? And the answer is yes. Actually, whether I know or not what the variance is. So let's start for the case where I actually do not know what the variance is. So here I have x is n mu sigma squared. This is all one dimensional. And here I'm going to assume that my parameter is both mu and sigma squared. So what I need to do is to have some function of mu, some function of sigma squared, and take the inner product of some function of x and some other function of x. So I want to show that p theta of x is what? Well, it's 1 over square root sigma 2 pi exponential minus x minus mu squared over 2 sigma squared. That's just my Gaussian density. And I want to say that this thing here, so clearly the exponential shows up already. I want to show that this is something that looks like eta 1 of mu sigma squared. So I have only two of those guys, so I'm going to need only two etas. So I want it to be eta 1 of mu and sigma times t1 of x plus eta 2 mu sigma squared times t2 of x. So I want to have something like that that shows up, and the only things that are left, I want them to depend either only on theta or only on x. So to find that out, we just need to expand. So I'm going to first put everything into my exponential and expand this guy. So the first term here is going to be minus x squared over 2 sigma squared. The second term is going to be minus mu squared over 2 sigma squared. And then the cross term is going to be plus x mu divided by sigma squared. And then I'm going to put this guy here, so I have a minus log sigma root 2 pi. OK, so this term here contains an interaction between x and the parameters. This term here contains an interaction between x and the parameters. So let me try to write them in a way that I want. This guy only depends on the parameters. This guy only depends on the parameter. So I'm going to rearrange things. And so I claim that this is of the form x squared. Well, let's say, who's getting the minus? Eta, OK. So it's x squared times minus 1 over 2 sigma squared plus x times mu over sigma squared. So that's this term here. That's this term here. Now I need to get this guy here. And that's minus. So I'm going to write it like this, minus. And now I have mu squared over 2 sigma squared plus log sigma square root 2 pi. OK? And now this thing is definitely of the form t1 of x times, did I call them the right way or not? Of course not. OK, so that's going to be t2 of x times eta 2 of x, eta 2 of theta. This guy is going to be t1 of x times eta 1 of theta. So just a function of theta times a function of x, just a function of theta times a function of x. And the way I combine this is just by summing them. And this is going to be my b of theta. What is h of x? 1. There's one thing I can actually play with. And this is something you're going to have some free choices. This is not actually completely determined here. Is that, for example, when I write the log sigma square root 2 pi, this is just log of sigma plus log square root 2 pi. So I have two choices here. Either my b becomes this guy, or so either I have b of theta, which is mu squared over 2 sigma squared plus log sigma square root 2 pi, and h of x is equal to 1. Or I have that b of theta is mu squared over 2 sigma squared plus log sigma, and h of x is equal to what? 1. Well, I can just push this guy out. I can push it out of the exponential. And so it's just square root of 2 pi, which is a function of x, technically. I mean, it's a constant function of x, but it's a function of x. So you can see that it's not completely clear how you're going to do the trade-off. So the constant terms can go either in b or in h. But why bother with tracking down b and h when you can actually stuff everything into one and just call h 1 and call it a day? So you can just forget about h. It's 1, and think about the rest. h won't matter, actually, for estimation purposes or anything like this. All right, so that's basically everything that's written. When sigma square is known, what's happening is that this guy here is no longer a function of theta, right? Agreed? This is no longer a parameter. When sigma square is known, then theta is equal to mu only. There's no sigma square going on. So everything that depends on sigma square can be thought as a constant, think 1. So in particular, this term here does not belong in the interaction between x and theta. It belongs to h, right? So if sigma is known, then this guy is only a function of h of x. So h of x becomes exponential x squared minus x squared over 2 sigma squared, right? That's just a function of x. Is that clear? So if you complete this computation, what you're going to get is that your new one parameter thing is that p theta p theta x is not equal to exponential x times mu over sigma squared minus, well, it's still the same thing, and then you have your h of x that comes out, x squared over 2 sigma squared. So that's my h of x. That's still my b of theta. And this is my t1 of x, and this is my eta 1 of theta. And remember, theta is just equal to mu in this case. So if I ask you, prove that this distribution belonged to an exponential family, you just have to work it out. Typically, it's expanding what's in the exponential and just write it in this term and identify all the components, right? So here, notice those guys don't even get an index anymore because there's just one of them. So I wrote theta 1 and t1, but it's really just eta and t. Oh, sorry. This guy also goes. This is also a constant, right? So it can actually just put sigma divided by sigma squared over 2 pi. So h of x is what, actually? AUDIENCE MEMBER 2. It's the density of? AUDIENCE MEMBER 3. It's centered. It's not standard. It's centered. It has mean 0, but it has variance sigma squared, right? But it's the density of a Gaussian. And this is what I meant when I said h of x is really just telling you with respect to which distribution, which measure you're taking the density. And so this thing here is really telling you the density of my Gaussian with mean mu is equal to this with respect to a centered Gaussian is this guy, right? That's what it means. If this thing ends up being a density, it just means that now you just have a new measure, which is this density. So it's just saying that the density of the Gaussian with mean mu with respect to the Gaussian with mean 0 is just this thing here. All right, so let's move on. So here is that I said you can actually do all these computations and forget about the fact that x is continuous. You can actually do it with PMFs and do it for x is discrete. This actually also tells you if you can actually get the same form for your density, which is of the form exponential times the product of the interaction between theta and x is just taking this product, and then a function only of theta and a function only of x for the PMF. It also works. So I claim that the Bernoulli belongs to this family. So the PMF of a Bernoulli, we say parameter p, is p to the x 1 minus p to the 1 minus x, right? Because we know, so that's only for x equals 0 or 1. And the reason is because when x is equal to 0, this is 1 minus p. When x is equal to 1, this is p. We've seen that when we were looking at likelihoods for Bernoullis. This is not clear this is going to look like this at all. But let's do it. So what does this thing look like? Well, the first thing I want to do is to make an exponential show up. So what I'm going to write is I'm going to write p to the x as exponential x log p, right? And so I'm going to do that for the other one. So this thing here, so I'm going to get exponential x log p plus 1 minus x log 1 minus p. So what I need to do is to collect my terms in x and my terms in whatever parameters I have. So here, theta is equal to p. So if I do this, what I end up having is equal to exponential. So the term in x is log p minus log 1 minus p. So that's x times log p over 1 minus p. And then the term that stays is just 1 times log 1 minus p. But I want to see this as a minus something, right? It was minus b of theta. So I'm going to write it as minus. Well, I can just keep the plus. And I'm going to do. And that's all. Aha. Well, this is of the form exponential, something that depends only on x, times something that depends only on theta, minus a function that depends only on theta. And then h of x is equal to 1 again. So let's see. So I have t1 of x is equal to x. That's this guy. Eta 1 of theta is equal to log p 1 minus p. And b of theta is equal to log 1 over 1 minus p. And h of x is equal to 1. You guys want to do Poisson, or you want to have it in homework? It's a dilemma, because that's an easy homework versus no homework at all. That may be something more difficult. OK, who wants to do it now? Who does not want to raise their hand now? Who wants to raise their hand now? All right. So let's move on. I'll just do it. Do you want to do the gammas instead in the homework? That's going to be fun. I'm not even going to propose to do the gammas. So this is the gamma distribution. It's brilliantly called gamma, because it has the gamma function, just like the beta distribution was at the beta function in there. They look very similar. One is defined over r plus, the positive real line. And remember, the beta was defined over the interval 0, 1. And it's of the form x to some power times exponential minus x to some time something. So there's a function, a polynomial in x, where the exponent depends on the parameter. And then there's the exponential minus x times something depends on the parameters. So this is going to also look like some function of x. Sorry, like some exponential distribution. Can somebody guess what is going to be t2 of x? Oh, those are the functions of x that show up in this product. Remember when we have this, we just need to take some transformations of x, so it looks linear in those things and not in x itself. Remember, we had x squared and x, for example, in the Gaussian case. I don't know if it's still there. Yeah, it's still there, right? t2 was x squared. What do you think x is going to be? t2 of x. So here's a hint. t1 is going to be x. Yeah, Arjun, what is going to be t2? Yeah, you cannot. This one is taken. This one is taken. I don't want to take it. What? Log x, right? Because this x to the a minus 1, I'm going to write it as exponential a minus 1 log x. So basically, eta 1 is going to be a minus 1. Eta 2 is going to be minus 1 over b. Well, actually, the opposite. But this is actually not too complicated. All right, then those parameters get names. a is the shape parameter. b is the scale parameter. It doesn't really matter. You have other things that are called the inverse gamma distribution, which has this form. The difference is that the parameter alpha shows negatively there. And then the inverse Gaussian distribution, just densities you can come up with. And it just happened to fall in this family. And there's other ones that you can actually put it there that we've seen before. The chi square is actually part of this family. The beta distribution is part of this family. The binomial distribution is part of this family. Well, that's easy because the Bernoulli was. The negative binomial, which is some stopping time, the first time you hit a certain number of successes when you flip some Bernoulli coins. So you can check for all of those. And you will see that you can actually write them as part of the exponential family. So the main goal of this slide is to convince you that this is actually a pretty broad range of distributions, because it basically includes everything we've seen, but not anything there. Sorry, plus more. OK? Yeah? Is there any example of a distribution which comes up pretty often that's not in the next exponential family? Yeah, like uniform. Oh, OK. Maybe a bit more complicated than that. Anything that has a support that depends on the parameter is not going to fall. It's not going to fit in there. And you can actually convince yourself why anything that has the support that depends on the parameter is not going to be part of this guy. It's kind of a hard thing to, if I ask you, prove that it's not, and you wouldn't prove this rule. It's kind of a little difficult. But the way you can convince yourself is that, remember, the only interaction between x and theta that I allowed was taking the product of those guys and then the exponential. If you have something that depends on some parameter, let's say you're going to see something that looks like this. For uniform, it looks like this. Well, this is not of the form exponential x times theta. There's an interaction between x and theta here, but it's actually certainly not of the form x exponential x times theta. So this is definitely not going to be part of the exponential family. And every time you start doing things like that, then it's just not going to happen. Actually, to be fair, I'm not even sure that all these guys, when you allow them to have all their parameters free, are actually going to be part of this. The beta probably is, but I'm not actually entirely convinced. There's books on exponential families. So let's go back. So here, we've put a lot of effort understanding how big, how much wider than the Gaussian distribution can we think of for the conditional distribution of our response y given x. So let's go back to the generalized linear models. So the generalized linear model said, OK, the random component, y, has to be part of some exponential family distribution. Check. We know what this means. So now I have to understand two things. I have to understand what is the expectation, because that's actually what I model. I take the expectation, the conditional expectation of y given x. So I need to understand, given this guy, it would be nice if it had some simple rules that would tell me exactly what the expectation is, rather than having to do it over and over again. If I told you, here's a Gaussian, compute the expectation. Every time you had to use that, it would be slightly painful. So hopefully, this thing being simple enough, we've actually selected a simple class that's simple enough. So that we can have rules, whereas as soon as I give you those parameters, t1, t2, eta 1, eta 2, b, and h, you can actually have some simple rules to compute the mean and variance and all the things. And so in particular, I'm interested in the mean. And I'm going to have to actually say, well, this mean has to be mapped into the whole real line so I can actually talk about modeling this function of the mean as x transpose beta. And we saw that for the Kefosis data set or whatever other data sets, you can actually do this using the log of the reciprocal. Or for the, actually, we didn't do it for the Bernoulli. We'll come to this. This is the most important one, and that's called the logit or logistic link. But before we go there, this was actually a very broad family. When I wrote this thing on the bottom board, it's gone now. But when I wrote it in the first place, the only thing that I wrote is I wanted x times theta. Wouldn't it be nice if I have some distribution that was just x times theta, not some function of x times some function of theta? The functions seem to be here so that they actually make things a little. So the functions were here so that I can actually put a lot of functions there. But first of all, if I actually decide to reparameterize my problem, I can always assume, if I have one dimensional, I can always assume that eta 1 of theta becomes my new theta. So this thing here, for example, I could say, well, this is actually the parameter of my Bernoulli. Let me call this guy theta. I could do that. Then I could say, well, here I have x that shows up here. And here, since I'm talking about the response, I cannot really make any transformation. So here I'm going to actually talk about a specific family for which this guy is not x square or square root of x or log of x or anything I want. I'm just going to actually look at distributions for which this is x. These exponential families are called canonical exponential families. So in the canonical exponential family, what I have is that I have my x times theta. I'm going to allow myself some normalization factor phi. And we'll see, for example, that it's very convenient when I talk about the Gaussian. Because even if I know this guy, which I actually pull into my, oh, that's over here, right? I know sigma squared, but I don't want to change my parameter to be mu over sigma squared. It's kind of painful. So I just take mu, and I'm going to keep this guy as being this phi over there. And it's called the dispersion parameter from a clear analogy with the Gaussian. That's the variance, and that's measuring dispersion. So here, what I want is I'm going to think throughout this class. So phi may be known or not. And when it's not known, this actually might turn into some exponential family, or it might not. And the main reason is because this b of theta over phi is not necessarily a function of theta over phi. If I actually have phi unknown, then y theta over phi has to be, this guy has to be my new parameter. And b might not be a function of this new parameter. So in a way, it may or may not, but this is not really a concern that we're going to have, because throughout this class, we're going to assume that phi is known. Phi is going to be known all the time, which means that this is always an exponential family. And it's just the simplest one you could think of. One dimensional parameter, one dimensional response, and I just have the product is just y times, or we used to call it x. Now I've switched to y. But y times theta divided by phi. Should I write this, or is this clear to everyone what this is? Let me write it somewhere so we actually keep track of it for the 10 minutes. OK, so this is, we have, remember we had all the distributions. And then here we had the exponential family. And now we have the canonical exponential family. It's actually much, much smaller. Well, actually, it's probably sort of a good picture. And what I have is that my density, or my PMF, is just exponential y times theta minus b of theta divided by phi. And I have plus c of, oh, yeah, plus c of y phi, which means that this is really, if phi is known, h of y is just exponential c of y phi. Actually, this is the reason why it's not necessarily a canonical family. It might not be that this depends only on y. It could depend on y and phi in some annoying way, and I may not be able to break it. But if phi is known, this is just a function that depends on y. Agreed? In particular, I hope you can convince yourself that this is just a subcase of everything we've seen before. So for example, the Gaussian, when the variance is known, is indeed of this form. So we still have it on the board. So here's my y. So let me write this as f theta of y. So every x is replaced with y. Blah, blah, blah. This is this guy. And now what I have is that this is going to be my phi. This is my parameter theta. So I'm definitely of the form y times theta divided by phi. And then here, I have a function b that depends only on theta over phi again. So b of theta is mu squared divided by 2. Then it's divided by sigma square. And then I have this extra stuff, but I really don't care what it is for now. It's just something that depends only on y and known stuff. So it's just a function of y. Just like my h, I stuff everything in there. The b, though, this thing here, this is actually what's important. Because in a canonical family, if you think about it, when you know phi, this is just y times theta scaled by a known constant. Sorry, y times theta scaled by a known constant is the first term. The second term is b of theta scaled by some known constant. But b of theta is what's going to make the difference between Gaussian and Bernoulli's and gammas and betas. This is all in this b of theta. b of theta contains everything that's idiosyncratic to this particular distribution. And so this is going to be important. And we will see that b of theta is going to capture information about the mean, about the variance, about the likelihood, about everything. Should I go through this computation? I mean, it's the same. We've just done it. So maybe it's probably better if you can redo it on your own. So the canonical exponential family also has other distributions. So there's the Gaussian, and there's the Poisson, and there's the Bernoulli. But the other ones may not be part of this. In particular, think about the gamma distribution. We had this log x was one of those things that showed up. I mean, I cannot get rid of this log x. I mean, that's part of it, except if a is equal to 1. And I know it for sure. So if a is equal to 1, then I'm going to have a minus 1, which is equal to 0. So I'm going to have a minus 1 times log x, which is going to be just 0. So log x is going to vanish from here. If a is equal to 1, then this distribution is actually much nicer. And it actually does not even deserve the name gamma. What is it if a is equal to 1? It's an exponential, right? Gamma of 1 is equal to 1. x to the a minus 1 is equal to 1. b, so I have exponential x over b divided by b. So 1 over b, call it lambda. And this is just an exponential distribution. And so every time you're going to see something, so all these guys that don't make it to this table, they could be part of those guys. But they're just to have another name in this thing. So you can compute the value of theta for different values. So again, you still have some continuous or discrete ones. This is my b of theta. And I said this is actually really what captures my theta. This b is actually called cumulant generating function. I don't have time. I could write five slides to explain to you. But it would just only tell you why it's called cumulant generating function. It's also known as the log of the moment generating function. And the way it's called cumulant generating function is because if I start taking successive derivatives and evaluate them at 0, I get the successive cumulants of this distribution, which are some transformation of the moment. What is the function b? The function b. So this is just normalization. So this is just to tell you I can compute this, but I really don't care. And obviously, I don't care about stuff that's complicated. This is actually cute. And this is what computes everything. And the rest is just some general description. You don't need me to tell you that the range of y is 0 to infinity. And that is essentially telling me this is going to give me some hints as to which link function I should be using. Because the range of y tells me what the range of expectation of y is going to be. Here it tells me that the range of y is between 0 and 1. So what I want to show you is that this captures a variety of different ranges that you can have. So I'm going to want to go into the likelihood. And the likelihood I'm actually going to use to compute the expectations. But since I actually don't have time to do this now, let's just go quickly through this and give you a spoiler alert to make sure that you all wake up on Thursday and really, really want to think about coming here immediately. So the thing I'm going to want to do, as I said, is it would be nice if, at least for this canonical family, when I give you b, you would be able to say, oh, here is a simple computation of b that would actually give me the mean and the variance. The mean and the variance are also known as moments. b is called cumulant generating function. So it sounds like moments being related to cumulants might have a path to finding those. And it might involve taking derivatives of b, as we'll see. The way we're going to prove this is by using this thing that we've used several times. So this property we use when we're computing, remember, the Fisher information. We had two formulas for the Fisher information. One was the expectation of the second derivative of the likelihood. And one was negative expectation of the square. Sorry, expectation of the square. And the other one was negative the expectation of the second derivative. The log likelihood is concave. So this number is negative. This number is positive. And the way we did this is by just permuting some derivative and integral here. And we used the fact that something that looked like this, the log likelihood is log of f theta. And when I take the derivative of this guy with respect to theta, then I have something that looks like the derivative divided by f theta. And if I start taking the integral against f theta of this thing, so the expectation of this thing, those things would cancel. And then I had just the integral of a derivative, which I would make a leap of faith and say that it's actually the derivative of the integral. But this was equal to 1. So this derivative was actually equal to 0. And so that's how you got that the expectation of the derivative of the log likelihood is equal to 0. And you do it once again, and you get this guy. There's just some nice things that happen with taking the derivative of the log. We've done that. We'll do that again. But once you do this, you can actually apply it. And missing a parenthesis over there. So when you write the log likelihood, it's just log of an exponential. That's actually pretty nice. Just like the least squares came naturally, the least squares criterion came naturally when we took the log likelihood of the Gaussians. We're going to have the same thing that happens. When I take the log of the density, the exponential is going to go away. And then I'm going to use this formula. But this formula is going to actually give me an equation directly. Oh, that's where it was. So that's the one that's missing it there. So the expectation minus this thing is going to be equal to 0, which tells me that the expectation is just the derivative. So it's still a function of theta, but it's just the derivative of b. And the variance is just going to be the second derivative of b. But remember, this was some sort of a scaling. It's called the dispersion parameter. So if I had a Gaussian, and the variance of the Gaussian did not depend on the sigma square, which I stuffed in this phi, that would be certainly weird. And it cannot depend only on mu. And so for the Gaussian, this is definitely going to be equal to 1. And this is just going to be equal to my variance. So this is just by taking the second derivative. So basically, the take-home message is that this function b captures, by taking one derivative of the expectation and by taking two derivatives, captures the variance. Another thing that's actually cool, and we'll come back to this and I want you to think about, is if this second derivative is the variance, what can I say about this thing? What do I know about a variance? Yeah, it's positive. So I know that this is positive. So what does that tell me? Positive? That's convex, right? A function that has positive second derivative is convex. So we're going to use that as well. So yeah, I'll see you on Thursday. Have your homework.