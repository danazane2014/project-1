 Το επόμενο κοινό είναι προσδοκημένο στη δικαιοσύνη Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει να προσφέρει υψηλές ειδικές ειδικές πιθανότητες για ελεύθερα. Για να κάνετε μια δονάση ή να παρακολουθείτε περισσότερα υλικά από χιλιάδες μαθητές MIT, επισκεφτείτε MIT OpenCourseWare στηn ocw.mit.edu. Σήμερα θα τελειώσουμε την συζήτηση για το πρόοδο του Poisson. Θα δούμε μερικά από τις προσωπικές του, κάποιοι θα κάνουν μερικά ενδιαφέρουσες προβλήματα, κάποιες περισσότερα ενδιαφέρουσες από τις άλλες. Θα δούμε μερικά παραδείγματα, και μετά θα μιλήσουμε για κάποιες λίγο στενές πράγματα που συνέβη με το πρόοδο του Poisson. Το πρώτο είναι να θυμήσετε τι είναι το πρόοδο του Poisson. Είναι ένα μοντέλο, ας πούμε, προς προσφέρεις των κατοικητών, που είναι σε κάποιο σημείο, κλειδί-κλειδί, τελείως αρκετά. Δηλαδή, ένας κατοικητής μπορεί να έρθει σε κάθε σημείο, όλες οι σημεία είναι αρκετά σχεδόν πιθανότητες, και διαφορετικά σημεία σημεία είναι, λοιπόν, ανεξαρτημένα από άλλες σημεία σημεία. Οπότε, το γεγονός ότι έχω ένας προσφέρεις τώρα, δεν μου λέει τίποτα για το αν θα υπάρχει ένα προσφέρεις σε κάποιο άλλο σημείο. Σε κάποιο σημείο, είναι μια συνεχής εφερμενότητα του πρόοδου του Bernoulli. Ο καλύτερος τρόπος για να σκεφτείτε το πρόοδο του Poisson είναι να διαχωριστείτε χρόνο σε πολύ μικρά σημεία, και σε κάθε σημεία χρόνου υπάρχει μια αξιωματική πιθανότητα να υπάρχει ένας προσφέρεις. Διάφορες σημεία χρόνου είναι αξιωματικά από τα άλλα. Στην άλλη πλευρά, όταν η σημεία είναι μικρή, η πιθανότητα να καταφέρει ένα προσφέρεις κατά τη διάρκεια αυτής της μικρής σημείας θα είναι μικρή. Οπότε, καταφέρουμε αυτές τις πραγματικές σε μια δεδομένη καταφέρνεια του πρόοδου του Poisson. Είμαστε σε μια διευθυντική δραστηριότητα για το χρόνο προς το οποίο έρχεται k, κατά μια σημεία με μια δεδομένη διάρκεια. Αυτή είναι η βασική περιγραφή της διαδίκτυα του χρόνου προς το οποίο έρχεται. Οπότε τετράγωνο τετράγωνο, και k είναι το παραμήνωμα, οπότε όταν προσθέσουμε πάνω σε όλες τις k, η σωματή αυτών των πιθανότητών πρέπει να είναι εξατμώς 1. Υπάρχει μια αξία χωμόγενητης τεράστιου, η οποία είναι κρυωμένη αυτή. Δηλαδή, το μόνο που σημαίνει είναι η διάρκεια του χρόνου, όχι όπου το χρόνο τεράστιο καθίστεται στην πραγματική αξία. Τότε έχουμε μια αξία χωμόγενητης. Οι τεράστιες που είναι αξιωμένες είναι στατιστικά αξιωμένες από τα άλλα. Οπότε, κάθε πληροφορία που μου δώσεις για προσθέσεις κατά αυτό το χρόνο τεράστιου δεν αλλάζει τις πιστεύωσές μου για αυτό που θα συμβεί κατά ένα άλλο χρόνο τεράστιου. Οπότε, αυτό είναι μια γενικότητα της ιδέα που είχαμε στις πρόοδες Bernoulli, ότι οι διαφορετικές στιγμές ειναι αξιωμένες από τα άλλα. Και τότε, για να δοκιμάσουμε αυτή τη δραστηριοποίηση, τη διαδίκτυα του τόπου εφαρμογένειων, πάντα πάνε σε στάγια. Πρώτα δοκιμάσαμε αυτή τη δραστηριοποίηση για το σημείο όπου η στιγμή τεράστιου είναι πολύ μικρή, και σας λέω τι θα είναι αυτές τις πιστεύωσες. Και βασίλεια σε αυτές, τότε κάνουμε κάποιες καταγραφήσεις και βρούμε μια ορισμότητα για τη διαδίκτυα του τόπου εφαρμογένειων για εφαρμογές με μια γενική διάρκεια. Λοιπόν, για μια μικρή διάρκεια, Δ, η πιθανότητα να λάβουμε ένας έτοιμος είναι λαμδα Δ. Η υπόλοιπη πιθανότητα είναι προσδοκίματος για το πράγμα ότι λάβουμε κανέναν έτοιμος, κατά αυτήν την στιγμή. Η πιθανότητα να λάβουμε πάνω από ένα έτοιμος, σε μικρή στιγμή, είναι, σύντομα, 0. Και όταν λέμε σύντομα, σημαίνει μόδιλο τερματά που είναι εφαρμογένειων Δ2. Και όταν Δ είναι πολύ μικρό, κάτι που είναι Δ2 μπορεί να είναι αφιερωμένο. Λοιπόν, μέχρι και τα τερματά Δ2, αυτό είναι αυτό που συμβαίνει κατά μικρή διάρκεια. Τώρα, αν γνωρίζουμε την πιθανότητα διαδίκτυα για το ποσό εφαρμογών σε μικρή διάρκεια, μπορούμε να χρησιμοποιήσουμε αυτό για να λάβουμε τη διαδίκτυα για το ποσό εφαρμογών πάνω από πολλά διάρκεια. Πώς το κάνουμε? Το μεγάλο εφαρμογόνι είναι συγκεντρωμένο από πολλά μικρά εφαρμογένεια. Κάθε μικρό εφαρμογόνι είναι ανεξαρτημένο από κάθε άλλο μικρό εφαρμογόνι. Λοιπόν, είναι σαν να έχουμε μια συνταγή τριαλών Bernoulli. Κάθε τριαλό Bernoulli είναι συνδεδεμένο με μικρό εφαρμογόνι και έχει μικρή πιθανότητα να λάβουμε ένα επιτυχώς ή μια έρθωση κατά αυτήν την μικρή σλότα. Στην άλλη, όταν η δελτα είναι μικρή και παίρνεις ένα μεγάλο εφαρμογόνι και το κόβεις, λάβεις ένα μεγάλο τροχόμετρο μικρών εφαρμογών. Λοιπόν, αυτό που έχουμε εδώ είναι ένα Bernoulli-πρόβλημα, στο οποίο ο τρόπος εφαρμογών είναι μεγάλο, αλλά η πιθανότητα ευεργοσύνης κατά κάθε τροχόμετρο είναι μικρή. Το μεγαλύτερο τροχόμετρο εφαρμογών αποτελεί να είναι προστατευτικό στον διάσταση του εφαρμογού. Αν έχετε δύο φορές ένα μεγάλο εφαρμογόνι, είναι σαν να έχετε δύο φορές πολλά από αυτές τις μικρές εφαρμογές. Λοιπόν, το προστατευτικό τρόπο εφαρμογών θα αυξηθεί προστατευτικά. Υπάρχει επίσης αυτό το παραμήνωμα λ, το οποίο εφαρμόζουμε ως προστατευτικό τρόπο εφαρμογών εφαρμογών εφαρμογών, και βρίσκεται εδώ σε αυτές τις προστατευτικές. Όταν διδάσκετε λ, αυτό σημαίνει ότι ένα μικρό εφαρμογόνι είναι δύο φορές πιο σχεδόν αυξηθεί για να γίνει εφαρμογός. Λοιπόν, θα εξετάζετε να γίνει δύο φορές όσες εφαρμογές. Αυτό είναι για αυτό που το προστατευτικό τρόπο εφαρμογών κατά μία εφαρμογή της λεπτομέρειας τών λαμβάνομαι πλήρως σε αυτό το παράμετρο λ. Αυτό είναι ένα τρόπο που σκεφτούμε το πρόοδο του Poisson. Σε όρια λίγες εφαρμογές, κάθε μια από τις οποίες έχει μικρή πιθανότητα ευκαιρίας, και σκεφτούμε την διστρίβλωση που έχει με αυτό το πρόοδο, ως το οποίο ονομάζεται αυτό το ΠМФ. Λοιπόν, αυτό είναι το ΠМФ για το ποσό εφαρμογών κατά μία εφαρμογή τών λεπτομέρειας τών. Είναι ένα ΠМФ που εξετάζει όλη την οικονομική λίγη αρχή αντίδρατων. Οπότε, το ποσό εφαρμογών που μπορείτε να λάβετε κατά μία εφαρμογή μιας συγκεκριμένης διάστασης μπορεί να είναι κάτι. Μπορείτε να λάβετε όσες εφαρμογές θέλετε. Βέβαια, η πιθανότητα να λάβετε 1 δις εφαρμογών θα είναι μικρή, αλλά, στο πρινθόν, αυτό είναι πιθανό. Και αυτό είναι γιατί ένα επίπεδο, ακόμα και αν είναι με κομμένη διάσταση, συμβαίνει από μία αρχή εφαρμογών με μικρές σλότες, σε κάποιο σημείο. Μπορείτε να το κοψτείτε σε όσες μικρές σλότες θέλετε. Λοιπόν, στο πρινθόν, είναι πιθανό ότι κάθε μικρή σλότα λάβει ένα εφαρμογό. Στο πρινθόν, είναι πιθανό να λάβετε ένα αρνητικά μεγάλο ποσό εφαρμογών. Λοιπόν, αυτή η συγκεκριμένη οριθμή εδώ δεν είναι πολύ αυτοκίνητη όταν την κοιτάτε, αλλά είναι ένα αληθινό πμφ και ονομάζεται το ποσόν πμφ. Είναι το πμφ που οριθμίζει το ποσό εφαρμογών. Λοιπόν, αυτό είναι ένα τρόπο να σκεφτείτε για το ποσόν πρόγραμμα, όπου το βασικό αντικείμενο ενδιαφέρον θα είναι αυτό το πμφ και να προσπαθείτε να δουλεύετε με αυτό. Υπάρχει ένα άλλο τρόπο να σκεφτείτε για τι συμβαίνει με το προσόν πρόγραμμα, και αυτό έχει να κάνει με το να αφήσουμε τα πράγματα να εξελίξουν με τον χρόνο. Ξεκινάτε με χρόνο 0. Θα υπάρχει ένα χρόνο, στο οποίο θα συμβαίνει η πρώτη έρθωση, και θα ονομάζεται αυτό το χρόνο T1. Αυτό το χρόνο, φαίνεται, θα έχουν μια εξωτερική διαδίκτυα με οριθμό λ. Μετά από την έρθωση, είναι σαν αν η διαδικτυακή αρχή ξανά. Το καλύτερο τρόπο να καταλάβετε γιατί αυτό είναι το πρόβλημα είναι από το να σκεφτείτε με την ανάλογη με την διαδικτυακή αρχή του Bernoulli. Αν πιστεύετε σε αυτό το σύγχρονο για την διαδικτυακή αρχή του Bernoulli, καθώς αυτό είναι ένα λιμιντικό πρόβλημα, θα πρέπει να είναι αλήθεια. Λοιπόν, ξεκινάμε από αυτό το χρόνο. Θα περιμένουμε μια αρκετή στιγμή μέχρι να λάβουμε την δεύτερη έρθωση, αυτή την αρκετή στιγμή, ας το ονομάσουμε T2. Αυτή τη στιγμή, T2 θα έχει επίσης μια εξωτερική διαδικτυακή αρχή με την ίδια αριθμή λ, και αυτοί οι δύο θα είναι ανεξαρτημένοι από τα άλλα. Οπότε, ο πρόβλημας του Poisson έχει όλες τις ίδιες πραγματικές αρχές της ανάλογης που έχει ο πρόβλημας του Bernoulli. Ποιο είναι ένα άλλο τρόπο να σκεφτείτε σε αυτό το πρόβλημα? Λοιπόν, σκεφτείτε έναν πρόβλημα που έχει λαμπρόβλημα. Το χρόνο μέχρι που το λαμπρόβλημα φωτίζεται, μπορείτε να το μοντελίσετε με μια εξωτερική δίκαιη αριθμή λ. Και ας πούμε ότι μέχρι τώρα, είμαστε σε κάποια στιγμή T, και σας πω ότι το λαμπρόβλημα δεν έχει ακόμα φωτίζει. Τι σας αυτό πει για το μέλλον του λαμπρόβλημα? Είναι το γεγονός ότι δεν έχει ακόμα φωτίζει. Είναι καλή νεύρα ή κακή νεύρα? Θα ήθελα να κρατήσετε αυτό το λαμπρόβλημα που έχει δουλεύει για τεράστιες στέπεις και είναι ακόμα καλά, ή θα ήθελα να χρησιμοποιήσετε ένα νέο λαμπρόβλημα που ξεκινά νέο σε αυτό το σημείο. Επειδή του ανάλογου αρχαίου, το παρελθόν αυτού του λαμπρόβλημα δεν αφορά. Οπότε, η μέλλοντας αυτού του λαμπρόβλημα είναι στατιστικά το ίδιο ως η μέλλοντας μιας νέας λαμπρόβλημας. Για αυτούς δύο, η χρόνος μέχρι που φωτίζουν θα είναι περιγράφημενος από μια διεκσύνθετη διαδίκτυα. Λοιπόν, ένας τρόπος που οι άνθρωποι περιγράφουν αυτή η κατάσταση είναι να πούμε ότι χρησιμοποιημένο είναι ακριβώς τόσο καλό όσο νέο. Οπότε, ένα χρησιμοποιημένο δεν είναι καλύτερο από ένα νέο. Ένα χρησιμοποιημένο λαμπρόβλημα που δεν έχει ακόμα φωτίζει είναι ακριβώς τόσο καλό όσο ένα νέο λαμπρόβλημα. Αυτό είναι ένα άλλο τρόπο να σκεφτούμε για την αμυνότητα που έχουμε στο πρόοδο του Poisson. Πάλι σε αυτή τη φωτογραφία. Η χρόνο μέχρι την δεύτερη έρθω είναι η χρόνος δύο ειδικές διεκσύνθετες δίκαιες διαδικασίας. Λοιπόν, στο πρινθόν, μπορείτε να χρησιμοποιείτε την συμβολική λογική για να βρείτε την διστρίπη T1 πλώς T2. Και αυτό θα ήταν το Y2, η χρόνο μέχρι την δεύτερη έρθω. Αλλά υπάρχει επίσης ένα διεκτικό τρόπο να καταφέρνουμε την διστρίπη Y2. Και αυτή είναι η καθορισμό που κάναμε την τελευταία φορά στον πλαίσιο. Και, πραγματικά, το κάναμε περισσότερο γενικά. Βρήκαμε την χρόνο μέχρι την ερθώση K. Υπάρχει μια δεκτική λογική, η οποία λέγεται ερλάνγκ διστρίπη με K-δεξιότητες ελευθερίας. Ας δούμε τι συμβαίνει εδώ. Είναι μια διστρίπη, από ποια είδη? Είναι μια συνεχής διστρίπη. Είναι μια διεκτική λογική για την πιθανότητα. Αυτό είναι γιατί η χρόνο είναι μια συνεχής διεκτική λογική. Η χρόνο είναι συνεχής, οι έρθως μπορούν να συμβαίνουν σε κάθε στιγμή. Λοιπόν, μιλάμε για ένα PDF. Αυτό το K είναι μόνο ένα παράμετρο της διστρίπης. Μιλάμε για το K-ης έρθος, οπότε K είναι ένα συνεχής λογική. Λαμβά είναι ένα άλλο παράμετρο της διστρίπης, το οποίο είναι η έρθος διεκτικής. Λοιπόν, είναι ένα PDF για τα Y, ενώ λαμβά και K είναι παράμετρος της διστρίπης. Αυτό ήταν αυτό που ήξερα από την τελευταία φορά. Ας κάνουμε κάποια εξετάσεις. Ας κάνουμε ένα πρόβλημα που δεν είναι πολύ δύσκολο, αλλά μόλις για να δούμε πώς χρησιμοποιούμε τα διάφορα ορισμότατα που έχουμε. Ο Poisson ήταν μαθηματικός, αλλά Poisson επίσης σημαίνει φίσκο στην Φρανκία. Οπότε, ο Poisson πάει να φίσκει και ας υποσχεθούμε ότι οι φίσκοι είναι κρατές με την οικονομική διαδικασία. Αυτό δεν είναι πολύ κακό ένα υποσχεδόν. Σε οποιοδήποτε σημείο, έχεις μικρή πιθανότητα ότι ένα φίσκο θα φάει κρατάς, και αν φάτε ένα τώρα είναι λοιπόν ανεξαρτημένο από το ότι μετά θα φάει ένα φίσκο ή όχι. Ας κάνουμε μόνο αυτό το υποσχεδόν. Και ας υποσχεδόμαστε ότι οι ρυθμίσεις του παιχνιδιού είναι ότι οι φίσκοι φάνεται σε μια συγκεκριμένη ασκήση, 0,6 ώρα. Φάτε 2 ώρες, δεν πειράζει τι. Και τότε υπάρχουν 2 ευθύνες. Αν έχω φάει ένα φίσκο, σταμάτω και πάω σπίτι. Αν κάποια φίσκο έχει φάει, οπότε υπάρχει τουλάχιστον ένα έτος, κατά αυτήν την στιγμή, πάω σπίτι. Ή αν δεν έχει φάει τίποτα, συνεχίζω να φάω μέχρι να φάω κάτι, και τότε πάω σπίτι. Αυτό είναι η περιγραφή του τι θα συμβεί. Και τώρα ας ξεκινήσουμε να ρωτήσουμε ερωτήματα όλων των εξετάσεων. Ποιο είναι η πιθανότητα ότι θα φάω περισσότερο από 2 ώρες? Θα φάω περισσότερο από 2 ώρες, αν και μόνο αν κανένα φίσκο δεν έβλεπε κατά αυτές τις 2 ώρες, σε οποίο πληθυσμό θα πρέπει να συνεχίσω. Φυσικά, αυτό είναι απλά αυτή η ποσότητα. Η πιθανότητα που θα φάω 2 φίσκους, που θα φάω 0 φίσκους, σε τα επόμενα 2 ώρες. Και ακόρυντας τη φορμάδα που έχουμε, αυτό θα είναι e-λλ, εκατομμύρια από πόσο χρόνο έχουμε. Υπάρχει ένα άλλο τρόπο να σκεφτούμε για αυτό. Η πιθανότητα ότι θα φάω περισσότερο από 2 ώρες είναι η πιθανότητα ότι το πρώτο φάγμα συμβαίνει μετά τη διάρκεια 2, η οποία θα είναι η πλήθυνση από 2 στο αλήθεια της δύναμης του πρώτου φάγματος. Και αυτή η δύναμη είναι εξωτερική, οπότε κάνεις την πλήθυνση εξωτερικής, και φυσικά θα έρθεις με την ίδια απάντηση. OK, αυτό είναι εύκολο. Λοιπόν, τι είναι η πιθανότητα που θα φάω περισσότερο από 2, αλλά λιγότερο από 5 ώρες? Τι κρατάει για να συμβαίνει αυτό? Για να συμβαίνει αυτό, πρέπει να πάρουμε 0 φαγματα από ημέρα 0-2, και να πάρουμε το πρώτο φάγμα κάποια στιγμή μεταξύ 2 και 5. Λοιπόν, ένας τρόπος να σκεφτώ τι συμβαίνει εδώ μπορεί να είναι να πω ότι υπάρχει ένα πρόοδο που συνεχίζει να συμβαίνει πάντα, αλλά όσο πιο γρήγορα παίρνω το πρώτο φαγμα, αντί να συνεχίσω να φάω και να συμβαίνω αυτά τα άλλα φαγματα, πάω σπίτι, πάω σπίτι τώρα. Τώρα, το γεγονός ότι πάω σπίτι πριν την ώρα 5 σημαίνει ότι αν ήθελα να παραμείνω μέχρι την ώρα 5, θα είχα κρατήσει τουλάχιστον ένα φαγμα. Μπορεί να είχα κρατήσει περισσότερο από ένα. Λοιπόν, το πρόβλημα ενδιαφέρον εδώ είναι ότι το πρώτο φαγμα συμβαίνει μεταξύ πολλών και 5. Λοιπόν, ένας τρόπος που θα δημοσιευόμουν αυτό το αριθμό θα ήταν η οποίοτητα ότι το πρώτο φαγμα συμβαίνει μεταξύ 2 και 5. Ένας άλλος τρόπος να το αντιμετωπίσω είναι να πω, ότι αυτή είναι η οποίητητα ότι κρατηθήκα 0 φαγματα στις πρώτες 2 ώρες. Και τώρα η οποίητητα ότι θα κρατηθήκαmax τουλάχιστον 1 φαγμα την επόμενη 3 ώρες. So what is this? The probability of 0 fish in the next 3 hours is the probability of 0 fish during this time. 1 minus this is the probability of catching at least 1 fish, of having at least 1 arrival, between times 2 and 5. If there's at least 1 arrival between times 2 and 5, then I will have gone home by time 5. So both of these, if you plug in numbers and all that, of course, are going to give you the same answer. Now next, what's the probability that I catch at least 2 fish? In which scenario are we? Under this scenario, I go home when I catch my first fish. So in order to catch at least 2 fish, it must be this case. So this is the same as the event that I catch at least 2 fish during the first 2 time steps. So it's going to be the probability from 2 to infinity, the probability that I catch 2 fish, or that I catch 3 fish, or I catch more than that. So it's this quantity. k is the number of fish that I catch, at least 2. So k goes from 2 to infinity. These are the probabilities of catching a number k of fish during this interval. And if you want a simpler formula without an infinite sum, this would be 1 minus the probability of catching 0 fish minus the probability of catching 1 fish during a time interval of length 2. Another way to think of it. I'm going to catch 2 fish, at least 2 fish, if and only if the second fish caught in this process happens before time 2. So that's another way of thinking about the same event. So it's going to be the probability that the random variable Y2, the arrival time of the second fish, is less than or equal to 2. OK. The next one is a little trickier. Here we need to do a little bit of divide and conquer. Overall, in this expedition, what's the expected number of fish to be caught? One way to think about it is to try to use the total expectation theorem and think of expected number of fish given this scenario or expected number of fish given this scenario. That's a little more complicated than the way I'm going to do it. The way I'm going to do it is to think as follows. Expected number of fish is the expected number of fish caught between times 0 and 2 plus expected number of fish caught after time 2. So what's the expected number caught between time 0 and 2? This is lambda t. So lambda is 0.6 times 2. This is the expected number of fish that are caught between times 0 and 2. Now let's think about the expected number of fish caught afterwards. How many fish are being caught afterwards? Well, it depends on the scenario. If we're in this scenario, we've gone home and we catch 0. If we're in this scenario, then we continue fishing until we catch 1. So the expected number of fish to be caught after time 2 is going to be the probability of this scenario times 1. And the probability of that scenario is the probability that I caught 0 fish during the first two time steps times 1, which is the number of fish that I'm going to catch if I continue. The expected total fishing time, we can calculate exactly the same way. I'm jumping to the last one. My total fishing time has a period of two time steps. I'm going to fish for two time steps no matter what. And then if I have caught 0 fish, which happens with this probability, my expected time is going to be the expected time from here onwards, which is the expected value of this geometric random variable with parameter lambda. So the expected time is 1 over lambda. And in our case, this is 1 over 0.6. Finally, if I tell you that I have been fishing for four hours and nothing has been caught so far, how much do you expect this quantity to be? Here is the story. That's, again, that for the Poisson process, used is as good as new. The process does not have any memory. Given what happens in the past doesn't matter for the future. It's as if the process starts new at this point in time. So this one is going to be, again, the same exponentially distributed random variable with the same parameter lambda. So expected time until an arrival comes has an exponential distribution with parameter lambda no matter what has happened in the past. Starting from now and looking into the future, it's as if the process has just started. So it's going to be 1 over lambda, which is 1 over 0.6. OK. Now our next example is going to be a little more complicated or subtle. But before we get to the example, let's refresh our memory about what we discussed last time about merging Poisson, independent Poisson processes. Instead of drawing the picture that way, another way we could draw it could be this. We have a Poisson process with rate lambda 1, Poisson process with rate lambda 2. Each one of these have their arrivals. And then we form the merged process. And the merged process records an arrival whenever there's an arrival in either of the two processes. This process and that process are assumed to be independent of each other. Now different times in this process and that process are independent of each other. So what happens in these two time intervals is independent from what happens in these two time intervals. These two time intervals determine what happens here. These two time intervals determine what happens there. So because these are independent from these, this means that this is also independent from that. So the independence assumption is satisfied for the merged process. And the merged process turns out to be a Poisson process. And if you want to find the arrival rate for that process, you argue as follows. During a little interval of length delta, we have probability lambda 1 delta of having an arrival in this process. We have probability lambda 2 delta of an arrival in this process, plus second order terms in delta, which we're ignoring. And then you do the calculation, and you find that in this process, you're going to have an arrival probability, which is lambda 1 plus lambda 2 delta. Again, ignoring terms that are second order in delta. So the merged process is a Poisson process whose arrival rate is the sum of the arrival rates of the individual processes. And the calculation we did at the end of the last lecture. If I tell you that an arrival happened here, where did that arrival come from? Did it come from here or from there? If lambda 1 is equal to lambda 2, then by symmetry, you would say that it's equally likely to have come from here or to come from there. But if this lambda is much bigger than that lambda, the fact that I saw an arrival is more likely to have come from there. And the formula that captures this is the following. This is the probability that my arrival has come from this particular stream, rather than that particular stream. So when an arrival comes, and you ask what is the origin of that arrival, it's as if I'm flipping a coin with these odds. And depending on the outcome of that coin, I'm going to tell you it came from there or it came from there. So the origin of an arrival is either this stream or that stream. And this is the probability that the origin of the arrival is that one. Now, if we look at two different arrivals, and we ask about their origins. So let's think about the origin of this arrival and compare it with the origin of that arrival. The origin of this arrival is random. It could be either this or that, and this is the relevant probability. The origin of that arrival is random. It could be either here or there, and again, with the same relevant probability. Question. The origin of this arrival, is it dependent or independent from the origin of that arrival? And here's how the argument goes. Separate times are independent. Whatever has happened in the process during this set of times is independent from whatever happened in the process during that set of times. Because different times have nothing to do with each other, the origin of an arrival here has nothing to do with the origin of an arrival there. So the origins of different arrivals are also independent of random variables. So if I tell you that, yeah. OK. So it's as if that each time that you have an arrival in the merged process, it's as if you're flipping a coin to determine where did that arrival came from, and these coins are independent of each other. OK. Now we're going to use this, what we know about merged processes, to solve a problem that would be harder to do if you were not using ideas from Poisson processes. So the formulation of the problem has nothing to do with the Poisson process. The formulation is the following. We have three light bulbs, and each light bulb is independent and is going to die out at the time that's exponentially distributed. So three light bulbs, they start their lives, and then at some point they die or burn out. So let's think of this as x, this as y, and this as z. And we're interested in the time until the last light bulb burns out. So we're interested in the maximum of the three random variables, x, y, and z. And in particular, we want to find the expected value of this maximum. So you can do derived distributions, use the expected value rule, anything you want. You can get this answer using the tools that you already have in your hands. But now let us see how we can connect this picture with a Poisson picture and come up with the answer in a very simple way. What is an exponential random variable? An exponential random variable is the first act in a long play that involves a whole Poisson process. So an exponential random variable is the first act of a Poisson movie. Same thing here. You can think of this random variable as being part of some Poisson process that has been running. So it's part of this bigger picture. We're still interested in the maximum of these three. The other arrivals are not going to affect our answers. It's just conceptually speaking, we can think of the exponential random variable as being embedded in a bigger Poisson picture. So we have three Poisson processes that are running in parallel. Let us split the expected time until the last burnout into pieces, which is time until the first burnout, time from the first until the second, and time from the second until the third. And find the expected values of each one of these pieces. What can we say about the expected value of this? This is the first arrival out of all these three Poisson processes. It's the first event that happens when you look at all these processes simultaneously. So three Poisson processes running in parallel. We're interested in the time until one of them, any one of them, gets an arrival. Rephrase. We merge the three Poisson processes, and we ask for the time until we observe an arrival in the merged process. When one of the three gets an arrival for the first time, then the merged process gets its first arrival. So what's the expected value of this time until the first burnout? It's going to be the expected value of a Poisson random variable. So the first burnout is going to have an expected value, which is a Poisson process. The merged process of the three has a collective arrival rate, which is 3 times lambda. So this is the parameter of the exponential distribution that describes the time until the first arrival in the merged process. And the expected value of this random variable is 1 over that. When you have an exponential random variable with parameter lambda, the expected value of that random variable is 1 over lambda. Here we're talking about the first arrival time in a process with rate 3 lambda. The expected time until the first arrival is 1 over 3 lambda. All right. So at this time, this arrival happened. This bulb has been burned. So we don't care about that bulb anymore. We start at this time, and we look forward. This bulb has been burned. So let's just look forward from now on. What have we got? We have two bulbs that are burning. We have a Poisson process. That's the bigger picture of what could happen to that light bulb if we were to keep replacing it. Another Poisson process. These two processes are again independent. From this time until that time, how long does it take? It's the time until either this process records an arrival or that process records an arrival. That's the same as the time that the merged process of these two records an arrival. So we're talking about the expected time until the first arrival in a merged process. The merged process is Poisson. It's Poisson with rate 2 lambda. So that extra time is going to take the expected value is going to be 1 over the rate of that Poisson process. So 1 over 2 lambda is the expected value of this random variable. So at this point, this bulb now is also burned. So we start looking from this time on. That part of the picture disappears. Starting from this time, what's the expected value until that remaining light bulb burns out? Well, as we said before, in a Poisson process or with exponential random variables, we have memorylessness. A used bulb is as good as a new one. So it's as if we're starting from scratch here. So this is going to be an exponential random variable with parameter lambda. And the expected value of it is going to be 1 over lambda. So the beauty of approaching this problem in this particular way is, of course, that we managed to do everything without any calculus at all, without writing any integral, without trying to calculate expectations in any form. Most of the non-trivial problems that you encounter in the Poisson world basically involve tricks of this kind. You have a question, and you try to rephrase it in trying to think in terms of what might happen in a Poisson setting, use memorylessness, use merging, et cetera, et cetera. Now we talked about merging. It turns out that the splitting of Poisson processes also works in a nice way. The story here is exactly the same as for the Bernoulli process. So I'm having a Poisson process. And each time with some rate lambda, and each time that an arrival comes, I'm going to send it to that stream and record an arrival here with some probability p. And I'm going to send it to the other stream with some probability 1 minus p. So either this will happen or that will happen, depending on the outcome of a coin flip that I do. Each time that an arrival occurs, I flip a coin, and I decide whether to record it here or there. This is called splitting a Poisson process into two pieces. What kind of process do we get here? If you look at the little interval of length delta, what's the probability that this little interval gets an arrival? It's the probability that this one gets an arrival, which is lambda delta, times the probability that after I get an arrival, my coin flip came out to be that way, so that it sends me there. So this means that this little interval is going to have probability lambda delta p. Or maybe more suggestively, I should write it as Lp times lambda p times delta. So every little interval has a probability of an arrival proportional to delta. The proportionality factor is lambda p. So lambda p is the rate of that process. And then you go through the mental exercise that you went through for the Bernoulli process to argue that different intervals here are independent and so on. And that completes checking that this process is going to be a Poisson process. So when you split a Poisson process by doing independent coin flips each time that something happens, the process that you get is again a Poisson process, but of course with a reduced rate. So instead of the word splitting, sometimes people also use the words thinning out. That is, out of the arrivals that came, you keep a few but throw away a few. OK. So now sort of the last topic of this lecture is a quite curious phenomenon that goes under the name of random incidents. So here's the story. Buses have been running on Mass Ave from time immemorial. And the bus company that runs the buses claims that they come as a Poisson process with some rate, let's say, of 4 buses per hour. So that the expected time between bus arrivals is going to be 15 minutes. All right. So people have been complaining that they've been showing up there, they think the buses are taking too long. So you're asked to investigate. Is the company, does it operate according to its promises or not? So you send an undercover agent to go and check the inter-arrival times of the buses. Are they 15 minutes or are they longer? So you put your dark glasses and you show up at the bus stop at some random time. And you go and ask the guy in the falafel truck, how long has it been since the last arrival? So of course that guy works for the FBI, right? So they tell you, well, it's been, let's say, 12 minutes since the last bus arrival. And then you say, oh, 12 minutes. Average time is 15, so a bus should be coming any time now. Is that correct? No. You wouldn't think that way. It's a Poisson process. It doesn't matter how long it has been since the last bus arrival. So you don't go through that fallacy. Instead of predicting how long it's going to be, you just sit down there and wait and measure the time. And you find that this is, let's say, 11 minutes. And you go to your boss and report, well, it took, I went there and the time from the previous bus to the next one was 23 minutes. It's more than the 15 that they said. So go and do that again. You go day after day. You keep these statistics of the length of this interval. And you tell your boss it's a lot more than 15. It tends to be more like 30 or so. So the bus company is cheating us. Does the bus company really run Poisson buses at the rate that they have promised? Well, let's analyze the situation here and figure out what the length of this interval should be on the average. The naive argument is that this interval is an interarrival time. And interarrival times on the average are 15 minutes if the company runs, indeed, Poisson processes with these interarrival times. But actually, the situation is a little more subtle. Because this is not a typical interarrival interval. This interarrival interval consists of two pieces. Let's call them T1 and T1 prime. What can you tell me about those two random variables? What kind of random variable is T1? Starting from this time with a Poisson process, the past doesn't matter. It's the time until an arrival happens. So T1 is going to be an exponential random variable with parameter lambda. So in particular, the expected value of T1 is going to be 15 by itself. How about the random variable T1 prime? What kind of random variable is it? And this is like the first arrival in a Poisson process that runs backwards in time. What kind of process is a Poisson process running backwards in time? Let's think of coin flips. Suppose you have a movie of coin flips. And for some accident, that fascinating movie, you happen to watch it backwards. Will it look any different statistically? No, it's going to be just a sequence of random coin flips. So a Bernoulli process that runs in reverse time is statistically identical to a Bernoulli process in forward time. The Poisson process is a limit of the Bernoulli, so same story with the Bernoulli process. If you run it backwards in time, it looks the same. So looking backwards in time, this is a Poisson process. And T1 prime is the time until the first arrival in this backward process. So T1 prime is also going to be an exponential random variable with the same parameter lambda. And the expected value of T1 prime is 15. Conclusion is that the expected length of this interval is going to be 30 minutes. And the fact that this agent found the average to be something like 30 does not contradict the claims of the bus company that they're running Poisson buses with a rate of lambda equal to 4. OK, so maybe the company can this way defend themselves in court, but there's some puzzling here. How long is the inter-arrival time? Is it 15 or is it 30 on the average? The issue is, what do we mean by a typical inter-arrival time? When we say typical, we mean some kind of average. But average over what? And here's two different ways of thinking about averages. You number the buses, and you have bus number 100. You have bus number 101, bus number 102, bus number 110, and so on. One way of thinking about averages is that you pick a bus number at random. I pick, let's say, that bus, all buses being sort of equally likely to be picked. And I measure this inter-arrival time. So for a typical bus, then starting from here until there, the expected time has to be 1 over lambda for the Poisson process. But what we did in this experiment was something different. We didn't pick a bus at random. We picked a time at random. And if the picture is, let's say, this way, I'm much more likely to pick this interval, and therefore this inter-arrival time, rather than that interval. Because this interval corresponds to very few times. So if I'm picking a time at random, and in some sense, let's say, uniformly, so that all times are equally likely, I'm much more likely to fall inside the big interval, rather than a small interval. So a person who shows up at the bus stop at a random time, they're selecting an interval in a biased way, with a bias in favor of longer intervals. And that's why what they observe is a random variable that has a larger expected value than the ordinary expected value. So the subtlety here is to realize that we're talking between two different kinds of experiments. Picking a bus number at random versus picking an interval at random with a bias in favor of longer intervals. Many of lots of paradoxes that one can cook up using Poisson processes and random processes in general, often have to do with the story of this kind. The phenomenon that we had in this particular example also shows up in general whenever you have other kinds of arrival processes. So the Poisson process is the simplest arrival process there is, where the inter-arrival times are exponential random variables. There's a larger class of models, they're called renewal processes, in which, again, we have a sequence of successive arrivals. Inter-arrival times are identically distributed and independent, but they may come from a general distribution. So to make the same point of the previous example, but in a much simpler setting, suppose that bus inter-arrival times are either 5 or 10 minutes apart. So you get some intervals that are of length 5, you get some that are of length 10. And suppose that these are equally likely, so we have exactly as many 5, not exactly, in the long run we have as many 5-minute intervals as we have 10-minute intervals. So the average inter-arrival time is 7 and 1.5. But if a person shows up at a random time, what are they going to see? We have as many 5's as 10's, but every 10 covers twice as much space. So if I show up at a random time, I have probability 2 thirds of falling inside a 10 interval of duration 10, and I have 1 third probability of falling inside an interval of duration 5. That's because out of the whole real line, 2 thirds of it is covered by intervals of length 10, just because they're longer, 1 third is covered by the smaller intervals. Now, if I fall inside an interval of length 10, and I measure the length of the interval that I fell into, that's going to be 10. But if I fall inside an interval of length 5, and I measure how long it is, I'm going to get a 5. And that, of course, is going to be different than 7.5. And which number should be bigger? It's the second number that's bigger, because this one is biased in favor of the longer intervals. So that's, again, another illustration of the different results that you get when you have this random incidence phenomenon. So the bottom line, again, is that if you talk about a typical interarrival time, one must be very precise in specifying what we mean typical. So typical means sort of random. But to use the word random, you must specify very precisely what is the random experiment that you are using. And if you're not careful, you can get into sort of apparent puzzles such as the following. Suppose somebody tells you the average family size is 4, but the average person lives in a family of size 6. Is that compatible? Family size is 4 on the average, but typical people live on the average in families of size 6. Well, yes. There's no contradiction here. We're talking about two different experiments. In one experiment, I pick a family at random, and I tell you the average family is 4. In another experiment, I pick a person at random, and I tell you that this person on the average will be in a family of size 6. And what's the catch here? That if I pick a person at random, large families are more likely to be picked. So there's a bias in favor of the large families. Or if you want to survey, let's say, are trains crowded in your city, or are buses crowded? One choice is to pick a bus at random and inspect how crowded it is. Another choice is to pick a typical person and ask them, did you ride the bus today? Was it crowded? Well, suppose that in this city, there's one bus that's extremely crowded, and all the other buses are completely empty. If you ask a person, was your bus crowded? They will tell you, yes, my bus was crowded. There's no witness from the empty buses to testify in their favor. So by sampling people instead of sampling buses, you're going to get a different result. And in the process industry, if your job is to inspect and check cookies, you will face the big dilemma. You want to find out how many chocolate chips there are on a typical cookie. Are you going to interview cookies, or are you going to interview chocolate chips and ask them how many other chips were there on your cookie? And you're going to get different answers in these cases. So moral is one has to be very precise on how you formulate the sampling procedure that you have, and you'll get different answers.