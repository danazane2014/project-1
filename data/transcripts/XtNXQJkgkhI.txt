 Το επόμενο πρόγραμμα είναι προσδοκημένο υπό δίκτυο Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει να προσδοκημένων πραγματικών ειδικών ειδικών πραγματικών πραγματικών πράγματων για ελεύθερη. Για να κάνετε μια διεθνή ή να παρακολουθείτε προσδοκίες από χιλιάδες μαθητές MIT, επισκεφθείτε MIT OpenCourseWare στηn ocw.mit.edu. Θα τελειώσουμε σήμερα με την συζήτηση για την εφαρμογή Bayesian, που ξεκίνησαμε την τελευταία φορά. Όπως πιθανόν είδατε, δεν υπάρχει πολλή κοινωνία κοντέπτων που παρουσιάζουμε στις στιγμές αυτής με τέτοιες ειδικές δυνατές για να καταγραφείς τις πιθανότητες, αλλά πάνω από μια εφαρμογή και να κατασκευάσει το πλαίσιο. Ο πλαίσιο στην εφαρμογή Bayesian είναι ότι υπάρχει κάποια παραμετώρηση, και προσπαθείς να δοκιμάσεις την εφαρμογή. Αυτές είναι οι πιστεύως για το τι μπορεί να είναι αυτή η εφαρμογή. Και μετά αποτελούμε μερικές μεταγραφές, και αυτές οι μεταγραφές εφαρμογονται από το ποιότητα αυτής της παραμετώρησης, που δεν γνωρίζουμε. Και αυτό το πράγμα, το γεγονός ότι η X είναι εφαρμογμένη από θ, καταγραφείται από την παρουσία μιας διεθνής δυνατότητας. Η διεθνή διεθνή του X είναι μια διεθνή διεθνή διεθνή διεθνή. Έτσι, έχουμε φορμούλες για αυτές τις δύο δυνάμεις, την προηγούμενη δυνάμη και την διεθνή δυνάμη. Και διότι έχουμε αυτές, αν τις πολλαγούμε, μπορούμε επίσης να πάρουμε την κοινή δυνάμη του X και του θ, οπότε έχουμε όλα που πρέπει να γνωρίζουμε σε αυτό το στήριο. Και τώρα παρατηρούμε το διεθνό διεθνό X. Σε μια διεθνή διεθνή διεθνή, τι μπορούμε να πούμε για το θ? Τι μπορούμε να κάνουμε είναι να μπορούμε πάντα να καταφέρουμε την κατασκευή διεθνών του θ σε μια διεθνή διεθνή διεθνή, και τώρα που έχουμε το συγκεκριμένο αριθμό του X, μπορούμε να το πλούτσουμε ως ένα λειτουργικό θ. Και αυτό είναι η ολοκληρωμένη απάντηση σε ένα πρόβλημα εφημερισμού. Ακόμα και το X που έχουμε παρατηρήσει, το θ είναι ακόμα αριθμός, είναι ακόμα αξιωμένο, και μπορεί να είναι εδώ, εδώ ή εδώ, με πολλές προφιλότητες. Στην άλλη πλευρά, αν θέλετε να πληρώσετε ένα μόνο αριθμό για το θ, τότε κάνετε κάποια εξωτερική δουλειά, συνεχίζετε από εδώ, και κάνετε κάποια διαδικασία δεξιού σε X. Διαδικασία δεξιού σημαίνει ότι προσθέσετε μια συγκεκριμένη λειτουργία στο δαίτημα, και αυτή η λειτουργία είναι κάτι που σχεδιαζόμαστε. Είναι ο λόγος εξοπλισμός, και μόλις αυτή η λειτουργία εφαρμόζεται, βάζει ένα εξοπλισμό του θ, το οποίο λέμε θ-. Αυτό είναι το μεγάλο πλαίσιο του τι συμβαίνει. Τώρα, ένα πράγμα να κρατήσετε στο σκοπό είναι ότι ακόμα και αν γράφω μόνες αριθμούς εδώ, γενικά, θ ή X μπορεί να είναι δεξιούς, δεξιούς διεφόρους. Λοιπόν, πιστεύτε ότι μπορεί να είναι μια συλλογή θ1, θ2, θ3. Και ίσως θα καταφέρουμε διάφορες μεταγραφές. Λοιπόν, αυτό το X είναι πραγματικά ένα δεξιό, X1, X2, μέχρι και Xn. Ωραία, τώρα πώς επιλέγουμε θ για να δημιουργήσουμε. Υπάρχουν διάφορες τρόπες να το κάνουμε. Η πρώτη είναι να δούμε την αριθμή διεφόρου και να δημιουργήσουμε το αριθμό του θ, στο οποίο η δύναμη ή το πιο μεγάλο πλίσιο είναι το πιο μεγάλο. Αυτό λέγεται την αριθμή πιστεύουμε ότι εκτός βαθμούς. Οπότε επιλέγουμε ένα ποιοτιό θ, το οποίο είναι η αριθμή πιστεύουμε και τα βγάλουμε. Μια άλλη εφαρμογή είναι να προσπαθήσουμε να είναι οπτικό με συσχόλους για μια εφαρμογή στη μίση πλισί. Λοιπόν, τι είναι αυτό. Αν υπάρχει ένα σχετικό αριθμός Γ, αυτό είναι το πιστεύουμε ότι θα προωθήσει. Αυτό είναι ο πραγματικός αριθμός του θ, Λοιπόν, αυτό είναι η αριθμή αριθμής μας. Βλέπουμε την εσάρτηση της αριθμής αριθμής, και βλέπουμε το αξιολόγημα. Θα ήθελα να είναι η εισάρτηση αυτής της εισάρτησης τόσο μικρή όσο μπορεί. Πώς μπορούμε να σχεδιαστούμε την αριθμητή G για να κάνουμε αυτήν την αριθμή τόσο μικρή όσο μπορεί. Ξέρει ότι η απαντάση είναι να παραγγίσουμε ως αριθμή την συνδρομητική ελπίδα θ στις x. Η απαντάση είναι η καλύτερη αριθμή που μπορείτε να παραγγίσετε αν το στόχο σας είναι να κρατήσετε την ελπίδα θ ελπίδα τόσο μικρή όσο μπορείτε. Αυτή η αριθμή εδώ είναι μια αριθμή του τι συμβαίνει στην αριθμή πάνω από όλες τις θ και όλες τις x που μπορεί να συμβαίνουν στο εξετάσιο μας. Ακριβώς η απαντάση ως αριθμή έχει μια ακόμα πιο στήριξη πράγματος. Όχι μόνο είναι οπτική στην αριθμή, αλλά είναι επίσης οπτική διότι έχετε κάνει μια συγκεκριμένη συμβάση. Δεν πειράζονται τι συμβάζετε, ας πούμε ότι συμβάζετε μια συγκεκριμένη αριθμή για το ρανδιστικό εξ, μετά από αυτό το σημείο, αν ζητήσετε να παράγετε μια καλύτερη αριθμή θ- που μειώνει αυτό το εργό με τη μείωση, η καλύτερη αριθμή σας θα είναι η συνδεδεμένη αντιστοιχή διότι η συγκεκριμένη αριθμή που έχετε συμβάσει. Αυτά τα δύο αριθμής λένε πάνω κάτω το ίδιο, αλλά αυτή είναι λίγο στροντότερη. Αυτή σας λέει, όσο μεταφέρει το συγκεκριμένο εξ, η συνδεδεμένη αντιστοιχή είναι η καλύτερη αριθμή. Αυτή σας λέει, σε μισή, σε όλα τα εξ που μπορεί να συμβεί, η συνδεδεμένη αντιστοιχή είναι η καλύτερη αριθμή. Τώρα, αυτό είναι πραγματικά μια συνέπεια. Αν η συνδεδεμένη αντιστοιχή είναι η καλύτερη για κάποιο συγκεκριμένο εξ, τότε είναι η καλύτερη, ακόμα και όταν το εξ είναι αφιερωμένο και εσείς επικοινωνείτε την εφαρμογή σας πάνω σε όλα τα εξ που μπορεί να συμβεί. Ωραία, τώρα ότι γνωρίζουμε τι είναι το οπτιμικό τρόπο να παραγωγήσουμε ένα αριθμό, ας κάνουμε ένα απλό παράδειγμα για να δούμε πώς λειτουργούν τα πράγματα. Άρα, ξεκινάμε με ένα αριθμό αριθμό, θ, που είναι ανίσθητον διαδίκτυο μεταξύ 4 και 10. Και τότε έχουμε ένα μοντέλο παραγωγής που μας λέει ότι, δεδομένου το αριθμό θ, ο εξ θα είναι ένα αριθμό αριθμό που διαφθορίζεται μεταξύ θ-1 και θ1. Λοιπόν, πιστεύω ότι ο εξ είναι ένας τρομακτικός μεταγραφής θ πλώς κάποια φωνή, η οποία είναι μεταξύ θ-1 και θ-1. Λοιπόν, πραγματικά, το μοντέλο που χρησιμοποιούμε εδώ είναι ότι ο εξ είναι αριθμός θ-1, όπου η U είναι ανίσθητη μεταξύ θ-1 και θ-1. Λοιπόν, έχουμε το αλήθειαστο αριθμό θ, αλλά ο εξ μπορεί να είναι θ-1 ή μπορεί να είναι πάνω μέχρι θ-1. Και ο εξ είναι ανίσθητος μεταγραφής σε αυτό το αριθμό. Αυτό είναι το ίδιο που λένε ότι η U είναι ανίσθητη μεταγραφή σε αυτό το αριθμό. Λοιπόν, τώρα έχουμε όλη την πληροφορία που χρειαζόμαστε. Μπορούμε να κατασκευάσουμε την κοινωνική δυνατότητα. Και η κοινωνική δυνατότητα είναι, φυσικά, η προηγούμενη δυνατότητα χρησιμοποιώντας την συνδεδεμένη δυνατότητα. Έχουμε αυτά δύο. Αυτά δύο είναι συστηματικές, οπότε η κοινωνική δυνατότητα θα είναι επίσης συστηματική. 1,6 x 1,5. Αυτό είναι 1 πάνω από 12. Αλλά είναι συστηματική όχι σε όλες τις περιοχές, μόνο σε το μήκος των δυνατών εξ και θ. Οπότε, θ μπορεί να πάρει κάποιο αριθμό μεταξύ 4 και 10. Αυτά είναι οι αριθμότητες του θ. Και για κάθε αριθμό διότητας του θ, x μπορεί να πάρει αριθμότητες από θ-1 μέχρι θ1. Άρα εδώ, αν μπορείτε να φανταστείτε μια στραφή που πάει με σλόπι 1, τότε x μπορεί να πάρει αυτό το αριθμό του θ πλούς ή μειών 1. Αυτό το σώμα εδώ είναι το σύστημα δυνατών εξ και θ. Λοιπόν, η δυνατότητα είναι εκ 1 εξαρτάς από 12 πάνω από αυτό το σώμα. Και είναι 0 σε όλα τα άλλα περιοχές. Λοιπόν, εκεί πάνω, η δυνατότητα είναι 0. Η δυνατότητα απαιτεί μόνο σε αυτό το σώμα. Αυτά λοιπόν, τώρα χρειαζόμαστε να αριθμόμαστε θ σε τερμάδι εξ. Λοιπόν, θέλουμε να φτιάξουμε έναν αριθμότηταρ, το οποίο θα είναι μια λειτουργία από τις εξ με τις θ. Αυτό λόγω λοιπόν, χωρίς το αριθμό του θ, το χωρίς το θ να είναι σ' αυτό το σώμα, θ σ' αυτό το σώμα, γιατί το αριθμότηταρ που χτίζουμε είναι μια λειτουργία από το εξ. Σχετικά με την παρατηρία που έχουμε δημιουργηθεί, θ θέλουμε να αριθμούμε. Λοιπόν, γνωρίζουμε ότι ο αριθμότητας είναι η υποθέτηση υποθέτης, δεδομένη από το αριθμό του εξ. Λοιπόν, τι είναι η υποθέτηση υποθέτησης? Αν αφιερώσετε ένα συγκεκριμένο αριθμό του εξ, ας πούμε, σε αυτή την αριθμό. Λοιπόν, αυτό είναι το εξ μας, τότε τι γνωρίζουμε για το θ? Γνωρίζουμε ότι το θ βρίσκεται σε αυτή την αριθμό. Το θ μπορεί να είναι μόνο κάπου μεταξύ αυτών των δύο αριθμών. Και τι είδους αριθμό δημιουργία έχει το θ? Ποιο είναι το υποθέτημα αριθμότητας του θ, δεδομένη από το εξ? Λοιπόν, θυμάστε πώς φτιάχνουμε υποθέτατες αριθμότητας από συγκεκριμένες αριθμότητες. Το υποθέτημα αριθμότητας είναι μόνο μια buldος του electronic joint distribution, ανεπιτεχνωμένου steady-state της εργασίας, όποτε η μαχαρινή είναι χρυσή απέναντι σε την αριθμότητα. Δηλαδή, το κλειστό τηςlementsθητραρης του θ travail ως σύγειπον κατά αυτή τηνよろしくτερειότητα. Λοιπόν, ενάντια πως το κλειστό του θ ειναι σύγειπος κατά αυτή την χρυσότητα η προσδοκή αξίας του θητά θα είναι το κεντροπόινγκο αυτής της μεταρρυθμίδας. Λοιπόν, η αισθηματική, με την οποία εγγραφείτε, αν παρατηρείτε αυτό το θητά, θα είναι αυτό το συγκεκριμένο σημείο εδώ. Είναι το κεντροπόινγκο. Το ίδιο αργουμέντρο συμβαίνει ακόμα και αν παρατηρείτε ένα x κάπου εδώ. Δεδομένου αυτό το x, το θητά μπορεί να πάρει ένα αριθμό μεταξύ αυτούς των δύο αριθμών. Το θητά θα έχει μια ανεξαρτημένη διαδίκτυα πάνω από αυτό το μεταρρυθμίδα, και η υποθέτηση υποθέτησης του θητά δεδομένου x θα είναι το κεντροπόινγκο αυτής του μεταρρυθμίδα. Άρα αν πλούσουμε το κατασκευάσμα μας με το να παραδείξουμε το κεντροπόινγκο σε αυτό το διαγράμμα, θα καταφέρουμε μια κύρια που ξεκινά αυτό, μετά να αλλάξει την σύνοδο, ώστε να κρατήσει τραγούδι το κεντροπόινγκο, και μετά να ξεκινά αυτό ξανά. Άρα αυτή η κύρια κύρια εδώ είναι η g of x, η οποία είναι η υποθέτηση υποθέτησης του θητά δεδομένου ότι x είναι αρκετή από x. Άρα είναι μια κύρια, στο παράδειγμα μας συμβαίνει από τρεις σωστές στρατιώτες, αλλά ολοκληρώνων είναι αρκετή. Δεν είναι μόνη στρατιώτα μέσα από αυτό το διαγράμμα. Και αυτό είναι το πώς είναι τα πράγματα. G of x, η υποθέτηση μας, δεν έχει λόγου να είναι μια λινεαρή λειτουργία x. Συνήθως θα είναι κάποια συγκλονική κύρια. Ωραία. Λοιπόν, πόσο καλή είναι η υποθέτησή μας? Δηλαδή, εσείς έγραψατε το x, το υποθέτημα σας του θητά βασισμένος στο x, και ο αφεσάς σας σας ρωτάει ποιο τύπο εχθρούς εσείς ανεπιστεύετε να πάρετε. Ενώ έχουμε παρατηρήσει ένα συγκεκριμένο αριθμό x, τι μπορείτε να ρωτάτε στον αφεσάς σας είναι τι πιστεύετε ότι θα είναι η εφαρμογή δεσμός εφθορμών. Παρατηρήσαμε ένα συγκεκριμένο αριθμό x. Οπότε, εμείς συνδεδεύουμε και ζούμε σε αυτό το κόσμο. Βεβαιώς ότι έχουμε κάνει αυτή την παρατηρή, αυτό είναι το πραγματικό αριθμό θητά. Αυτό είναι το αποδείξιμο που έχουμε παραγωγήσει. Αυτό είναι το πιστευόμενο Isaacson δοξά shock δ Arkian παράδειγμα με το ότι φτιάχτα με αυτή τη φραντίδα μοιάζουμε. Στην κα 201 το έκπρωπά Gesetz, αυτό είναι το πιστευόμενο ριθμά θητά- χρηστή x οπότε αυτό είναι το πιστευόμενο τρόπο του λειτουργίου μέσα στον γεωφορείο Συνδεδικείω κα Non-G RH- Οπότε όσο αφεσάσατε στο br2 σαν πιστευόμενο λειτουργίο το ισχύετε λειτουργικό は ιδιαίτερα και αυτό είναι τουτό ο display same thing as the variance of that random variable, except that it is the variance inside the conditional universe. Having observed X, Theta is still a random variable. It's distributed according to the posterior distribution. Since it's a random variable, it has a variance. And that variance is our mean squared error. So this is the variance of the posterior distribution of Theta, given the observation that we have made. So what is the variance in our example? If X happens to be here, then Theta is uniform over this interval, and this interval has length 2. Theta is uniformly distributed over an interval of length 2. This is the posterior distribution of Theta. What is the variance? Then you remember the formula for the variance of a uniform random variable. It is the length of the interval squared divided by 12. So this is 1 third. So the variance of Theta, the mean squared error, is going to be 1 third whenever this kind of picture applies. This picture applies when X is between 5 and 9. If X is less than 5, then the picture is a little different, and Theta is going to be uniform over a smaller interval. And so the variance of Theta is going to be smaller as well. So let's start plotting our mean squared error. Between 5 and 9, the variance of Theta, the posterior variance, is 1 third. Now when X falls in here, Theta is uniformly distributed over a smaller interval. The size of this interval changes linearly over that range. And so when we take the square size of that interval, we get a quadratic function of how much we have moved from that corner. So at that corner, what is the variance of Theta? Well, if I observe an X that's equal to 3, then I know with certainty that Theta is equal to 4. Then I'm in a very good shape. I know exactly what Theta is going to be. So the variance in this case is going to be 0. If I observe an X that's a little larger, then Theta is now random, takes values on a little interval, and the variance of Theta is going to be proportional to the square of the length of that little interval. So we get a curve that starts rising quadratically from here and goes up towards 1 third. At the other end of the picture, the same is true. If you observe an X which is 11, then Theta can only be equal to 10. And so the error in Theta is equal to 0. There's 0 error variance. But as we obtain X's that are slightly less than 11, then the mean squared error again rises quadratically. So we end up with a plot like this. What this plot tells us is that certain measurements are better than others. If you're lucky and you see X equal to 3, then you're lucky because you know Theta exactly what it is. If you see an X which is equal to 6, then you're sort of unlucky because it doesn't tell you Theta with great precision. Theta could be anywhere on that interval. And so the variance of Theta, even after you have observed X, is a certain number, 1 third in our case. So the moral to keep out of that story is that the error variance, or the mean squared error, depends on what particular observation you happen to obtain. Some observations may be very informative. And once you see a specific number, then you know exactly what Theta is. Some observations might be less informative. You observe your X, but it could still leave a lot of uncertainty about Theta. So conditional expectations are really the cornerstone of Bayesian estimation. They're particularly popular, especially in engineering contexts. They're used a lot in signal processing, in communications, control theory, and so on. So that makes it worth playing a little bit with their theoretical properties and get some appreciation of a few subtleties involved here. No new math in reality in what we're going to do here, but it's going to be a good opportunity to practice manipulation of conditional expectations. So let's look at the expected value of the estimation error that we obtain. So Theta hat is our estimator. It's the conditional expectation. Theta hat minus Theta is what kind of error do we have. If Theta hat, if our estimate is bigger than Theta, then we have made a positive error. If not, if it's on the other side, we have made a negative error. Then it turns out that on the average, the errors cancel each other out on the average. So let's do this calculation. Let's calculate the expected value of the error given X. Now by definition, the error is expected value of Theta hat minus Theta given X. We use linearity of expectations to break it up as expected value of Theta hat given X minus expected value of Theta given X. And now what? Our estimate is made on the basis of the data of the X's. If I tell you X, then you know what Theta hat is. Remember that the conditional expectation is a random variable, which is a function of the random variable on which you're conditioning on. If you know X, then you know the conditional expectation given X. You know what Theta hat is going to be. So Theta hat is a function of X. If it's a function of X, then once I tell you X, you know what Theta hat is going to be, so this conditional expectation is going to be Theta hat itself. Here, this is just by definition Theta hat. And so we get equality to 0. So what we have proved is that the conditional, no matter what I have observed, and given that I have observed something, on the average, my error is going to be 0. This is a statement involving equality of random variables. Remember that conditional expectations are random variables because they depend on the thing you're conditioning on. 0 is sort of a trivial random variable. This tells you that this random variable is identically equal to the 0 random variable. More specifically, it tells you that no matter what value for X you observe, the conditional expectation of the error is going to be 0. And this takes us to this statement here, which is an equality between numbers. No matter what specific value for X you have observed, your error on the average is going to be equal to 0. So this is a less abstract version of this statement. This is an equality between two numbers. It's true for every value of X, so it's true in terms of this random variable being equal to that random variable. Because remember, according to our definition, this random variable is the random variable that takes this specific value when capital X happens to be equal to little x. Now this doesn't mean that your error is 0. It only means that your error is as likely, in some sense, to fall on the positive side as to fall on the negative side. So sometimes your error will be positive, sometimes negative, and on the average, these things cancel out and give you a 0 on the average. So this is a property that's sometimes given the name. We say that theta hat is unbiased. So theta hat, our estimate, does not have a tendency to be on the high side. It does not have a tendency to be on the low side. On the average, it's just right. So let's do a little more playing here. Let's see how our error is related to an arbitrary function of the data. Let's do this in a conditional universe. And look at this quantity. Now when you know x in a conditional universe where x is known, then h of x is known. And so you can pull it outside the expectation. In the conditional universe where the value of x is given, this quantity becomes just a constant. There's nothing random about it. So you can pull it out the expectation. And you can pull it out the expectation. And you can pull it out the expectation. There's nothing random about it, so you can pull it out the expectation and write things this way. And we have just calculated that this quantity is 0. So this number turns out to be 0 as well. Now having done this, we can take expectations of both sides. And now let's use the law of iterated expectations. Expectation of a conditional expectation gives us the unconditional expectation. And this is also going to be 0. So here we use the law of iterated expectations. Why are we doing this? We're doing this because I would like to calculate the covariance between Theta tilde and Theta hat. That is, ask the question, is there a systematic relation between the error and the estimate? So to calculate the covariance, we use the property that we can calculate its covariances by calculating the expected value of the product minus the product of the expected values. And what do we get? This is 0 because of what we just proved. And this is 0 because of what we proved earlier, that the expected value of the error is equal to 0. So the covariance between the error and any function of X is equal to 0. Let's use that to the case where the function of X we're considering is Theta hat itself. Theta hat is our estimate. It's a function of X. So this 0 result would still apply, and we get that this covariance is equal to 0. So that's what we proved. Let's see, what are the morals to take out of all this? First is you should be very comfortable with this type of calculation involving conditional expectations. The main two things that we're using are that when you condition on a random variable, any function of that random variable becomes a constant and can be pulled out the conditional expectation. The other thing that we're using is the law of iterated expectations. So these are the skills involved. Now on the substance, why is this result interesting? This tells us that the error is uncorrelated with the estimate. What's a hypothetical situation where this would not happen? Whenever Theta hat is positive, my error tends to be negative. Suppose that whenever Theta hat is big, then you say, oh, my estimate is too big. Maybe the true Theta is on the lower side, so I expect my error to be negative. That would be a situation that would violate this condition. This condition tells you that no matter what Theta hat is, you don't expect your error to be on the positive side or on the negative side. Your error will still be 0 on the average. So if you obtain a very high estimate, this is no reason for you to suspect that the true Theta is lower than your estimate. If you suspected that the true Theta was lower than your estimate, you should have changed your Theta hat. If you make an estimate, and after obtaining that estimate you say, I think my estimate is too big, and so the error is negative. If you thought that way, then that means that your estimate is not the optimal one, that your estimate should have been corrected to be smaller. So that would mean that there's a better estimate than the one you used, but the estimate that we are using here is the optimal one in terms of mean squared error. There's no way of improving it. And this is really captured in that statement. That is, knowing Theta hat doesn't give you a lot of information about the error, and gives you therefore no reason to adjust your estimate from what it was. Finally, a consequence of all this. This is the definition of the error. Send Theta to this side, send Theta tilde to that side, you get this relation. The true parameter is composed of two quantities, the estimate. And then the error that I got with a minus sign. These two quantities are uncorrelated with each other. Their covariance is 0. And therefore, the variance of this is the sum of the variances of these two quantities. So what's an interpretation of this equality? There is some inherent randomness in the random variable Theta that we're trying to estimate. Theta hat tries to estimate it, tries to get close to it. And if Theta hat always stays close to Theta, since Theta is random, Theta hat must also be quite random. So it has uncertainty in it. And the more uncertain Theta hat is, the more it moves together with Theta. So the more uncertainty it removes from Theta. And this is the remaining uncertainty in Theta. The uncertainty that's left after we've done our estimation. So ideally, to have a small error, we want this quantity to be small, which is the same as saying that this quantity should be big. In the ideal case, Theta hat is the same as Theta. That's the best we could hope for. That corresponds to 0 error. And all the uncertainty in Theta is absorbed by the uncertainty in Theta hat. Interestingly, this relation here is just another variation of the law of total variance that we have seen at some point in the past. I will skip that derivation, but it's an interesting fact. And it gives you an alternative interpretation of the law of total variance. OK, so now let's return to our example. In our example, we obtained the optimal estimator, and we saw that it was a nonlinear curve, something like this. I'm exaggerating the corner a little bit to show that it's nonlinear. This is the optimal estimator. It's a nonlinear function of X. Which means nonlinear generally means complicated. Sometimes the conditional expectation is really hard to compute, because whenever you have to compute expectations, you need to do some integrals. And if you have many random variables involved, it might correspond to a multidimensional integration. We don't like this. Can we come up maybe with a simpler way of estimating Theta, of coming up with a point estimate, which still has some nice properties. It has some good motivation, but is simpler. What does simpler mean? Perhaps linear. Let's put ourselves in a straitjacket and restrict ourselves to estimators that are of this form. My estimate is constrained to be a linear function of the X's. So my estimator is going to be a curve, a linear curve. It could be this, it could be that. Maybe it would want to be something like this. I want to choose the best possible linear function. What does that mean? It means that I write my Theta hat in this form. If I fix a certain a and b, I have fixed the functional form of my estimator, and this is the corresponding mean squared error. That's the error between the true parameter and the estimate of that parameter. We take the square of this. Now the optimal linear estimator is defined as one for which this mean squared error is smallest possible over all choices of a and b. So we want to minimize this expression over all a's and b's. How do we do this minimization? Well, this is a square. You can expand it, write down all the terms in the expansion of the square. So you're going to get the term expected value of Theta squared, you're going to get another term a squared, expected value of x squared, another term which is b squared, and then you're going to get various cross terms. What you obtain, or what you have here, is really a quadratic function of a and b. So think of this quantity that we're minimizing as some function h of a and b, and it happens to be quadratic. How do we minimize a quadratic function? We set the derivative of this function with respect to a and b to 0, and then do the algebra. After you do the algebra, you find that the best choice for a is this one. So this is the coefficient next to x. This is the optimal a. And the optimal b corresponds to the constant terms. So this term and this times that together are the optimal choices of b. So the algebra itself is not very interesting. What is really interesting is the nature of the result that we get here. If we were to plot the result on this particular example, you would get a curve that's sort of something like this. Sort of it goes through the middle of this diagram and is a little slanted. In this example, x and theta are positively correlated. Bigger values of x generally correspond to bigger values of theta. So in this example, the covariance between x and theta is positive. And so our estimate consists. It can be interpreted in the following way. The expected value of theta is the estimate that you would come up with if you didn't have any information about theta. If you don't make any observations, this is the best way of estimating theta. But I have made an observation, x, and I need to take it into account. I look at this difference, which is the piece of news contained in x. That's what x should be on the average. If I observe an x which is bigger than what I expected it to be, and since x with theta are positively correlated this tells me that theta should also be bigger than its average value. Whenever I see an x that's larger than its average value, this gives me an indication that theta should also probably be larger than its average value. And so I'm taking that difference and multiplying it by a positive coefficient. And that's what gives me a curve here that has a positive slope. So this increment, the new information contained in x, as compared to the average value we expected a priori, that increment allows us to make a correction to our prior estimate of theta. And the amount of that correction is guided by the covariance of x with theta. If the covariance of x with theta were 0, that would mean there's no systematic relation between the two. And in that case, obtaining some information from x doesn't give us a guide as to how to change the estimates of theta. If that were 0, we would just stay with this particular estimate. We're not able to make a correction. But when there's a non-zero covariance between x and theta, that covariance works as a guide for us to obtain a better estimate of theta. How about the resulting mean squared error? In this context, it turns out that there's a very nice formula for the mean squared error obtained from the best linear estimate. What's the story here? The mean squared error that we have has something to do with the variance of the original random variable. The more uncertain our original random variable is, the more error we're going to make. On the other hand, when the two variables are correlated, we exploit that correlation to improve our estimate. And the bigger that correlation is, this rho here is the correlation coefficient between the two random variables. When this correlation coefficient is larger, this factor here becomes smaller, and our mean squared error becomes smaller. So think of the two extreme cases. One extreme case is when rho is equal to 1. So x and theta are perfectly correlated. When they're perfectly correlated, once I know x, then I also know theta. And the two random variables are linearly related. In that case, my estimate is right on the target, and the mean squared error is going to be 0. The other extreme case is if rho is equal to 0. The two random variables are uncorrelated. In that case, the measurement does not help me estimate theta, and the uncertainty that's left, the mean squared error, is just the original variance of theta. So the uncertainty in theta does not get reduced. So moral, the estimation error is a reduced version of the original amount of uncertainty in the random variable theta. And the larger the correlation between those two random variables, the better we can remove uncertainty from the original random variable. I didn't derive this formula, but it's just a matter of algebraic manipulations. We have a formula for theta hat. Subtract theta from that formula. Take square. Take expectations. And do a few lines of algebra that you can read in the text, and you end up with this really neat and clean formula. Now I mentioned in the beginning of the lecture that we can do inference with theta and X's not just being single numbers, but they could be vector random variables. So for example, we might have multiple data that give us information about X. This discussion here, there are no vectors here. So this discussion was for the case where theta and X were just scalar, one-dimensional quantities. What do we do if we have multiple data? Suppose that theta is still a scalar. It's one-dimensional. But we make several observations. And on the basis of these observations, we want to estimate theta. The optimal least mean squares estimator would be, again, the conditional expectation of theta given X. That's the optimal one. And in this case, X is a vector. So the general estimator we would use would be this one. But if we want to keep things simple, and we want our estimator to have a simple functional form, we might restrict to estimators that are linear functions of the data. And then the story is exactly the same as we discussed before. I constrain myself to estimating theta using a linear function of the data. So my signal processing box just applies a linear function. And I'm looking for the best coefficients, the coefficients that are going to result in the least possible squared error. This is my squared error. This is my estimate minus the thing I'm trying to estimate, squared, and then taking the average. How do we do this? Same story as before. This quantity, the X's and the theta's get averaged out because we have an expectation. Whatever is left is just a function of the coefficients of the a's and of b. As before, it turns out to be a quadratic function. Then we set the derivatives of this function of a's and b's with respect to the coefficients. We set it to 0. And this gives us a system of linear equations. It's a system of linear equations that's satisfied by those coefficients. It's a linear system because this is a quadratic function of those coefficients. So to get closed form formulas in this particular case, one would need to introduce vectors and matrices and matrix inverses and so on. The particular formulas are not so much what interests us here, rather the interesting thing is that this is simply done just using straightforward solvers of linear equations. The only thing you need to do is to write down the correct coefficients of those nonlinear equations. And the typical coefficient that you would get would be what? Let's say a typical coefficient would be, let's take a typical term of this quadratic when you expand it. You're going to get the term such as a1 X1 times a2 X2. When you take expectations, you're left with a1 a2 times expected value of X1 X2. So a typical, OK, so this would be, it would involve terms such as a1 squared, expected value of X1 squared. You would get terms such as a1 a2, expected value of X1 X2. And lots of other terms here. Actually, we would have a 2. So you get something that's quadratic in your coefficients. And the constants that show up in your system of equations are things that have to do with the expected values of squares of your random variables or products of your random variables. To write down numerical values for these, the only thing you need to know are the means and variances of your random variables. If you know the mean and variance, then you know what this thing is. And if you know the covariances as well, then you know what this thing is. So in order to find the optimal linear estimator in the case of multiple data, you do not need to know the entire probability distribution of the random variables that are involved. You only need to know your means and covariances. These are the only quantities that affect the construction of your optimal estimator. We could see this already in this formula. The form of my optimal estimator is completely determined once I know the means, variance, and covariance of the random variables in my model. I do not need to know the detailed distribution of the random variables that are involved here. So as I said, in general you find the form of the optimal estimator by using a linear equation solver. There are special examples in which you can get closed form solutions. The nicest, simplest estimation problem one can think of is the following. You have some uncertain parameter, and you make multiple measurements of that parameter in the presence of noise. So the Wi's are noises. i corresponds to your i-th experiment. So this is the most common situation that you encounter in the lab. If you're dealing with some process, you're trying to measure something, you measure it over and over. Each time your measurement has some random error, and then you need to take all your measurements together and come up with a single estimate. So the noises are assumed to be independent of each other, and also to be independent from the value of the true parameter. Without loss of generality, we can assume that the noises have 0 mean, and they have some variances that we assume to be known. Theta itself has a prior distribution with a certain mean and a certain variance. So the form of the optimal linear estimator is really nice. Well, maybe you cannot see it right away, because this looks messy. But what is it really? It's a linear combination of the X's and the prior mean. And it's actually a weighted average of the X's and the prior mean. Here we collect all the coefficients that we have at the top. So the whole thing is basically a weighted average. 1 over sigma i squared is the weight that we give to Xi. And in the denominator, we have the sum of all the weights, so in the end, we're dealing with a weighted average. If mu was equal to 1, and all the Xi's were equal to 1, then our estimate would also be equal to 1. Now the form of the weights that we have is interesting. Any given data point is weighted inversely proportional to the variance. What does that say? If my i-th data point has a lot of variance, if Wi is very noisy, then Xi is not very useful, is not very reliable. So I'm giving it a small weight. Large variance, a lot of error in my Xi, means that I should give it a smaller weight. If two data points have the same variance, they're of comparable quality, then I'm going to give them equal weight. The other interesting thing is that the prior mean is treated the same way as the X's. So it's treated as an additional observation. So we're taking a weighted average of the prior mean and of the measurements that we're making. The formula looks as if the prior mean was just another data point. So that's a way of thinking about Bayesian estimation. You have your real data points, the X's that you observe. You also had some prior information. This plays a role similar to a data point. Interesting note that if all random variables are normal in this model, this optimal linear estimator happens to be also the conditional expectation. That's a nice thing about normal random variables, that conditional expectations turn out to be linear. So the optimal estimate and the optimal linear estimate turn out to be the same. And that gives us another interpretation of linear estimation. Linear estimation is essentially the same as pretending that all random variables are normal. So that's sort of a side point. Now I'd like to close with a comment. You do your measurements and you estimate Theta on the basis of X. Suppose that instead you have a measuring device that measures X cubed instead of measuring X. And you want to estimate Theta. Are you going to get a different estimate? Well, X and X cubed contain the same information. Telling you X is the same as telling you the value of X cubed, so the posterior distribution of Theta given X is the same as the posterior distribution of Theta given X cubed. And so the means of these posterior distributions are going to be the same. So doing transformations to your data does not matter if you're doing optimal least squares estimation. On the other hand, if you restrict yourself to doing linear estimation, then using a linear function of X is not the same as using a linear function of X cubed. So this is a linear estimator, but where the data are the X cubes. And we have a linear function of the data. So this means that when you're using linear estimation, you have some choices to make. Linear on what? Sometimes you want to plot your data on an ordinary scale and try to plot a line through them. Sometimes you plot your data on a logarithmic scale and try to plot a line through them. Which scale is the appropriate one? Here it would be a cubic scale. And you have to think about your particular model to decide which version would be a more appropriate one. Finally, when we have multiple data, sometimes these multiple data might contain the same information. So X is one data point. X squared is another data point. X cubed is another data point. The three of them contain the same information, but you can try to form a linear function of them. And then you obtain a linear estimator that has a more general form as a function of X. So if you want to estimate your Theta as a cubic function of X, for example, you can set up a linear estimation model of this particular form and find the optimal coefficients, the a's and the b. All right, so the last slide just gives you the big picture of what's happening in Bayesian inference. It's for you to ponder. Basically, we talked about three possible estimation methods, maxima posteriori, where we mean squared error estimation and linear mean squared error estimation, or least squares estimation. And there's a number of standard examples that you will be seeing over and over, recitation tutorial, homework, and so on, perhaps on exams even, where we take some nice priors on some unknown parameter. We take some nice models for the noise or the observations. And then you need to work out posterior distributions and the various estimates and compare them.