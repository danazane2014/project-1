 Okay. So today we're going to be discussing orthonormal bases of a Hilbert space. So let me just recall what we did at the end of last time. We introduced maximal orthonormal sets, so a collection of vectors in a, we could say a pre-Hilbert space, but let's say in a Hilbert space. So this is maximal if u and h and u e lambda equals zero for all lambda in the index implies that u equals zero. Okay, so a collection of, so I should have said this, a collection of orthonormal vectors is maximal if the only thing that's orthogonal to all of them is a zero vector. And last time we proved that h be a separable Hilbert space, meaning it has a countable dense subset. Most, I mean, I think all of the Hilbert spaces you've come into contact with are separable, you know, c in, r in, also little l2, big l2, this is what you're doing in the assignment, that's also separable. Then h has a countable maximal orthonormal subset. Okay so we proved this at the end of last time via the Gram-Schmidt process. We took a countable collection of, a countable collection of elements in the Hilbert space which were dense and then we formed this countable orthonormal subset. I shouldn't put N in, capital N because this could be a finite collection or it could be a countably infinite collection but then we applied the Gram-Schmidt process to that collection of dense elements and came up with this maximal orthonormal subset. Okay, now we have a special name for countable maximal orthonormal subsets, kind of for a good reason, so as we'll see, so let H be the Hilbert space and orthonormal basis of H is a countable maximal orthonormal subset, I shouldn't say N and N again, of H. Okay, so orthonormal basis is just a special name that we give to those maximal orthonormal subsets which are countable, meaning they can be either finite or countably infinite. Okay, so again, all of the Hilbert spaces we've encountered in practice, for example, Cn, little l2, big l2 which are all separable meaning they do have a countable maximal orthonormal subset meaning they have a orthonormal basis so they have these objects. Now why do we call a countable maximal orthonormal subset an orthonormal basis? So a basis is supposed to be something where, you know, you can write every vector in the space as some sort of linear combination of the elements of the basis, right? Now we dealt with Hamil basis or bases which are, you can write every element as a finite linear combination of the elements in this subset. Now in this setting, in what sense is this a basis or what is, I shouldn't say is it a basis but in what sense does this connect to what we've encountered, say, in finite dimensions? In orthonormal basis, so as stated in the next theorem, every element can be written now as an infinite linear combination of elements of an orthonormal basis, okay, not necessarily finite. So statement is the following, if E n is an orthonormal basis in the Hilbert space then for all u and h, if I look at the partial sum u inner product E sub n, E sub n, this converges as m goes to infinity to the element u, okay, in the space h. Written kind of in shorter form is that u is equal to sum from n equals 1 to infinity of u inner product E sub n, E sub n, okay? Because this is referred to as a Fourier Bessel series, all right? So you know, just like in finite dimensions, if you have an orthonormal basis consisting of only finitely many vectors, then you can expand every vector in that, say, C n in this way, okay? Now, the statement is in a Hilbert space, if you have an orthonormal basis in this sense, meaning it's a countable maximal orthonormal subset, then you can expand every element as a infinite linear combination of these elements, okay? Okay. So to prove this, we will use Bessel's inequality and the completeness of h, all right? This is where we're using the fact that, you know, h is not a pre-Hilbert space but a Hilbert space, all right? What we're going to do is we're going to be able to show that the right-hand side of this equality, so we're going to be able to show that this series here converges in h, okay? That uses Bessel's inequality and the fact that h is a Hilbert space, converges to some element, and then we're going to use the fact that this collection is maximal to show that the inner product of whatever this defines with each element e sub n is the same as the inner product of this thing which with each element e sub n and then conclude that this thing on the right side has to equal this thing, okay? All right. So if we first prove that the sequence of partial sums, so M, is Cauchy, okay? So let epsilon be positive. So by Bessel's inequality, we have that the sum of n equals 1 to infinity of u squared, this thing converges. So the only thing we have to check is that since this is a series involving non-negative terms that this thing is bounded above and we have by Bessel's inequality, this is always bounded above by the norm of u squared. So this sum, this series converges to a finite number, okay? In particular, the series, the partial sums corresponding to this series is a Cauchy sequence of real numbers, of non-negative real numbers, okay? Thus, there exists an M, natural number, such that for all, let's see, for all n bigger than or equal to M, we have that the tail is small, meaning n equals n plus 1 to infinity less than epsilon, okay? You can just look back into your, you know, 18-100 notes or whatever that if I have a series of non-negative terms which converges, then for every epsilon, I can find a capital M so that the tail, so starting the sum at, you know, a large enough entry will be small, okay? Then for all M greater than L greater than this capital M, if I compute the norm of n equals 1 to M, u inner product E sub n, E sub n minus n equals 1 to L, u E sub n, E sub n squared, and let's make this a square, I can do that. This you can just compute, you know, expanding this out as, you know, the inner product of this whole thing with itself, this gives you sum from n equals L plus 1 to M of u E n squared. And since L is bigger than or equal to M, this is certainly less than or equal to, well, I can put infinity here, n equals L plus 1, u inner product E sub n squared, and that's less than since L is bigger than or equal to capital M, we can use this inequality and that's less than epsilon squared, okay? So we've shown that for M and L bigger than or equal to capital M that the norm squared of the difference is less than epsilon squared, and therefore the norm of the difference is less than epsilon, proving that the sequence of partial sums is Cauchy. Okay, so we've proven that the sequence of partial sums is Cauchy. So since H is complete, there exists element u and H such that u bar is equal to limit as n goes to infinity equals 1 M of these partial sums, where this limit means that the norm of the difference in H converges to zero. Okay, and so just in shorthand, again, this means, okay? Now what I'd like to do is show that u bar equals u, all right? I don't mean complex conjugate, I just mean an element of H. And now how we're going to do that is show that the inner product of u minus u bar against every element of this maximal orthonormal subset is zero, and therefore conclude u equals u bar. Now we have this result that the inner product is continuous with respect to, you know, the entries. So by continuity of the inner product, we have that the inner product of u, so let me so then for all L natural number, the inner product of u minus u bar with EL, this is equal to, u bar is equal to the limit as M goes to infinity of this partial sum in H. So this inner product is equal to the limit as M goes to infinity of u minus sum from N equals one to M of u, EN, EN, inner product EL. And you know, this is also, I mean, I'm sure you've seen this at some point, but this is also why the coefficients appearing in front of the ENs are the way they are. So this is equal to the limit as M goes to infinity of u inner product EL minus sum from N equals one to M of u, EN, EN, inner product EL. And when N does not equal L, so remember these are orthonormal, when N does not equal L, I get zero, and when N equals L, I get one, so all I pick up is u, this just reduces to u inner product EL, which cancels with that one, and therefore I get zero. All right. So I've shown that for every L, u minus u bar inner product with EL is zero, and since this collection is maximal, anything that inner product with, so the only element that's orthogonal to every element in this collection is zero, that implies that u minus u bar equals zero, and therefore u equals u bar, which means u is equal to this series. Okay? Okay. Okay. So, we've shown that if a Hilbert space has an orthonormal basis, then every element can be expanded in what's typically referred to as a Fourier Bessel series in this way, in terms of the elements of the orthonormal basis. Now let me just kind of tie one thing up. So we know that every separable Hilbert space does have a orthonormal basis, right, a countable maximal orthonormal subset, all right? And so if H is separable, that implies H has an orthonormal basis. Now what this theorem also proves is that if H has an orthonormal basis, then H is separable. So let me just state that as kind of a simple theorem that follows from this. So we've shown that if H, that was the first theorem I stated at the beginning, that if H is separable, then it has an orthonormal basis. If H has an orthonormal basis, H is a Hilbert space, so I should have said that at the beginning, but H is a Hilbert space, then H is separable, meaning it has a countably, a countable dense subset. So what is this countable dense subset? I'm just going to give you the subset and then talk through why this subset works. So suppose E n is an orthonormal basis for H, again a Hilbert space, then if I define S to be the union over all, let's say m, a natural number of elements of the form sum from n equals 1 to m of Q n, E n, where Q 1, these are just rational numbers. So first off, this is a countable subset of H. Why is that? Well, each of these is in one-to-one correspondence with the m-fold Cartesian product of the rational numbers. Now, the rational numbers are countable, and you proved back in 18100 that any, well, any Cartesian product, finite Cartesian product of countable sets is again countable. And then we're taking a countable union. Another thing you prove in 18100 is that a countable union of countable subsets is countable, so that's why S is countable. And then, so now I'm just going to state by the previous theorem, S is dense in H, and then I'm going to put a box here and explain why. So every element, so if H has an orthonormal basis, by the theorem we proved, every element can be expanded as, you know, in one of these Fourier Bessel series, as coefficients times the, as the infinite linear combination of the orthonormal vectors, of these orthonormal vectors. Now, this means the partial sums are converging to, you know, a given element U. So what we have to show for this thing to be dense, we have to show for every epsilon there exists, something from the set within epsilon distance of that given vector. Now give yourself a vector. Its Fourier Bessel series converges to it. So we can cut off, we can cut the series off at a certain point and still be within epsilon over 2 to that element we're trying to get close to, okay? Then that finite, that finite sum will be in one of these, well it won't be in one of these, but it will just be a sum from n equals 1 to m of some coefficients times the e sub n's. So the rational numbers, I should say, there, now that's correct. Now any complex number here can be approximated by a rational number here plus i times a rational number here. This is still, you know, in one to one correspondence with Q squared, the Cartesian product of Q with itself, and therefore this is still countable, and so I should have said 2m here. I was thinking about real numbers. So that you can get close to the actual Fourier Bessel coefficients that appear in that sum by now just rational or complex numbers with rational, real, and imaginary part, okay? So I hope that explanation was clear, maybe sit down and think about it and actually write down carefully, you know, the epsilon argument, but that's essentially why this is true. So what we've shown is that a Hilbert space is separable if and only if it has an orthonormal basis. So let me make a remark that what we've shown up to this point is that if H is a Hilbert space, then H is separable if and only if H has an orthonormal basis. Okay. All right, so we've proven that in a Hilbert space, if a Hilbert space has an orthonormal basis, then every element can be expanded in this kind of infinite series involving the orthonormal vectors. I say infinite, that's only if the orthonormal basis is countably infinite. If it was finite, then that's actually not an infinite sum, it's a finite sum. Now what follows from that is that, so we have Bessel's inequality which says that the sum of squares of the coefficients appearing in this Fourier Bessel series is always less than or equal to the norm of U squared. That's no matter what you assume about the orthonormal subset, that's for any orthonormal subset. But now we have that if it's a orthonormal basis, then in fact we have equality. So if H is a Hilbert space and this is a countable basis, then for all U and H, we have that the sum, N equals 1, I'll just put sum over N because this may be a finite sum, U, E, N, which by Bessel's inequality, we always had less than or equal to the norm of U squared, in fact equals norm of U squared. And this is sometimes referred to as Percival's identity. All right, so what's the proof of that? We have that U equals sum of U, E, N, E, N, and therefore, kind of immediately by the continuity of the inner product, we can write norm of U squared as, so this is for, you know, the case that we have countably infinite. If it's a finite orthonormal basis, this follows immediately. But sum from M equals, or the sum as M goes to infinity of N equals 1 to M, U, E, N, E, N, sum from, say, L equals 1 to M, U, E, L, E, L, and this is equal to the limit as M goes to infinity of sum of N equals, say, N, L equals 1 to M of U, E, N. And now this constant here comes out with a complex conjugate, U, E, L times E, N, inner product E, L. And now we only pick up, so N and L are going from 1 to M. For a fixed N, we only pick up the L where L equals N, right, because these vectors are orthonormal. So when N equals L, this gives me 1. So I only pick up when L equals N, and I get U, E, N times the complex conjugate of U, inner product E, N, which is just the norm squared when I multiply by that. And I'm taking the limit as M goes to infinity, so I pick up the whole sum, the infinite sum, if it's infinite. So we've seen a couple of simple applications of the theorem. We proved that if I have a orthonormal basis, then the Hilbert space must be separable. And also we have equality in vessels and equality in terms of the orthonormal basis. What's more is that the previous actually gives us a way to identify every separable Hilbert space with the one you were introduced to in the first week, although I didn't call it a Hilbert space. So this is the following theorem that if H, so if H is a finite dimensional Hilbert space, that means I can find finitely many orthonormal vectors that span the space, and it's quite easy to show that then that is isomorphic to Cn in an isometric way. So I'm just going to state the infinite dimensional version. If H is an infinite dimensional separable Hilbert space, then H is isometrically isomorphic and I'll spell out what these words mean to L2, little l2, meaning what? Meaning there exists a bijective map, T, going from H to little l2. So it's 1 to 1 and onto. So that for all u, v, and H, we have that the norm of Tu, I should say bijective linear map, bijective linear map, or I should even say I mean bijective linear operator. So it's going to be a bounded linear map, and this follows immediately from what I'm about to write down, such that if I take the norm of the image in little l2, this is equal to the norm of the vector in H. So that's the isometric part here is that the map is not changing links. And basically, if I have a map between two Hilbert spaces that preserve links, then it also preserves inner products by not the parallelogram law, it's the polarization identity, which you see in the assignment. But anyways, and also we have Tu, Tv, taking this inner product in l2, because these are elements now of little l2, this is the same as the inner product in H of u and v. And it really just follows kind of immediately from what we've done once I just write down the map. So what's the proof? So since H is a separable Hilbert space, it has an orthonormal basis En, which is countably infinite since we're in the infinite dimensional setting. And by the previous theorem, we have for all u and H, u is equal to sum from n equals 1 to infinity, u inner product En, En, and with the norm of u squared equals, if you'd like, let me remove the squares and I can write this as sum from n equals 1 to infinity of u En norm squared 1 half. So now this should just jump at you. How do I define my map from H to little l2? And I define T of u to simply be the sequence of coefficients appearing here. And this is an element of little l2 by this identity here, Parseval's identity. Then T does the job. So I didn't go through and check all the properties that I needed to check. I mean, it's clear that it's going to be linear in u because these coefficients are linear in u. And that's clear. It's one to one. Sort of follows from the fact that every u is expanded this way. And therefore, if the coefficients are the same for two different u's, then those two u's have to be the same. So that makes it injective. The fact that it's surjective, again, doesn't take too much to prove, although you just show that for every choice of sequence in little l2 that forming such a sum. So label these cn. So now you have just an element of little l2. Now if I put cn here, en, now you can argue, as we did before, that this series is, in fact, Cauchy in H, and therefore converges to some element in H. And then you can prove that T takes that element that you have to the sequence that you started with, proving that T is surjective. So I'm not going to go through all the details, but it should be kind of clear that this, at least based on this identity here, what the match should be. So we've seen some applications of this kind of general theory of orthonormal bases of countable maximal subsets in a Hilbert space applications, meaning if it has a basis, orthonormal basis, then the space has to be separable. Every separable infinite dimensional Hilbert space is basically the same. They're all isometrically isomorphic to little l2. But how can we use this in a more concrete setting, whatever concrete means? I mean, concrete kind of is by taste. So I thought we'd pause here on the general theory for Hilbert spaces that we've been doing and do something a little more specific and look at Fourier series, which will connect this general stuff that we've been doing with Hilbert spaces to kind of more of the concrete bit of producing these Lebesgue integration and these big LP spaces, which we proved are complete spaces involving some sense integrable functions. So let's take a pause from general theory and talk a little bit about Fourier series. OK, Fourier series, which was the reason why a lot of, especially the integration theory was created in the first place, was to understand a certain question, which we'll get to in a minute. Let me just start off with a very simple theorem that the subset of functions e to the i n x over root 2 pi in now an integer is an orthonormal subset of L2 minus pi to pi. And here, let me just for a quick refresher, if t is a real number e to the i t, this is simply defined to be the complex number cosine t plus i sine t. And it satisfies all the things that you know and love about the exponential. If I multiply e to the i t times e to the i tau, that's equal to e to the i t plus tau just by referring to the definition and using angle, sum formulas, and so on. All right, so this is not too difficult to prove. What's the proof of this? If I take e to the i n x and inner product it with e to the i m x, now this inner product is in big L2. This is by definition equal to the integral from minus pi to pi e to the i n x times e to the i m x complex conjugate. And again, from the definition, when I take a complex conjugate, that flips this i to a minus i. And then I can take that minus that sits out here and put it in and make this a minus t here and a minus t there, since cosine t is even and sine t is odd. So then this becomes e to the i n x e to the minus i m x dx. And again, you can just go from the definition of what this is. You don't need any fancy complex analysis. This is i to the n minus m times x dx. Now this quantity here, when n equals m, I just get 0 here. And therefore, this is just 1. And when I integrate that, I get 2 pi. So this equals 2 pi. And now when n does not equal m, this has an antiderivative that you expect it to be. And therefore, this is equal to e to the i n minus m x over n minus m times i evaluated at pi n minus pi. And this is if n equals m, n does not equal m. And now what is it about e to the i t? This thing is 2 pi periodic. And it's the same if I have an n here. Then that's going to be 2 pi over n periodic. So if I stick in pi here, the value I get is going to be the same as when I stick in minus pi here, because the difference between these two values is 2 pi. So this is 2 pi periodic. And I'm sticking in two numbers separated by 2 pi. So this will be 0 when n does not equal n. And therefore, that proves the claim that this is an orthonormal subset. We divide by square root of 2 pi so that when I take the inner product of this with itself, or the element with itself, I get 1. Here, I just did e to the i n x. So I got 2 pi. So I divide by the square root of that to get the orthonormal thing. So make a definition. So let f be an L2 of minus pi to pi, the n-th Fourier coefficient. This is a new bit of terminology. So L2 of f is the complex number f hat of n equals 1 over 2 pi inner product, I mean, integral of minus pi to pi of f of t e to the minus i nt dt. And the n-th partial Fourier sum of f is denoted by capital S sub n of f of x. This is equal to the sum for n, an absolute value less than or equal to capital N. So little n is an integer of f hat of n times e to the i n x, which I can is the same as f inner product with i in, let's say, t over square root of 2 pi e to the i. All I did with my definition of the Fourier coefficient is I combined these two square root of 2 pi's in my definition of f hat of n. But this partial sum is just equal to a partial sum in terms of this orthonormal subset. OK? OK, and we also associate to function f a formal object, the Fourier series of f is the formal series because we are not making any claims about its convergence at all, sum from in z f hat of n e to the i n x. OK? So the question that we're going to answer and, like I said, kind of motivated all of this to begin with is the following. So back when Fourier was studying heat conduction, he made a claim that every function can be expanded in terms of, essentially, he was doing cosines and sines. But in terms of this, he said every function can be expanded is equal to its Fourier series. OK? Now, at the time, people said, no, that's not the case. Not every function is periodic. And each of these is 2 pi periodic. So what are you talking about? And then, OK, maybe he said, maybe if we restrict to continuous functions, maybe it's equal to its Fourier series. That's not true. There's continuous functions that have the Fourier series actually diverges at a point and doesn't converge back to the function. But Fourier series, so now if you're asking about pointwise convergence, that's a very tricky and delicate issue. But Fourier series has a very nice and kind of beautiful answer when you look in terms of the space that you're supposed to. As I started off this discussion, I said these elements are orthonormal with respect to this inner product. And this inner product lives, as far as in a Hilbert space, in the space big L2. So the question that one should ask then is you have this orthonormal subset of L2. So the question is, do we have for all f in L2 f of x equals f hat of n e to the i n x? So this is an infinite sum. So I should be talking about in what sense is this series converging. And I mean in the sense of in the space that we're asking this question in L2, i.e. do I have that the partial sums converge to f in the L2 norm? So I'm not going to write the argument. OK, maybe I will. Does this equal, does this, OK, now I'm butchering this. Let's instead of writing that limit, let's say does this norm converge to 0 as capital N goes to infinity? OK? So that's the question. Do we have convergence of this series, meaning the partial sums, do they converge to the function f in the L2 norm? So this is something weaker than or maybe not even comparable to pointwise convergence. So sometimes this is referred to as convergence in the mean. And so what is the way to phrase this question based on what we've done? So this question is equivalent to the question is this collection of orthonormal elements in big L2 maximal subset of big L2, i.e. And so now let's really put this question into equivalence with just a pure statement, i.e. does the vanishing of all the Fourier coefficients imply that the function is 0? So we proved that this statement here is equivalent to e to the i nx being an orthonormal basis. OK, so we proved one direction. We proved that if I have a collection of orthonormal vectors, then that's an orthonormal basis implies that every function can be expanded in this infinite series. But the converse clearly holds, too. If I can expand every function in an infinite series with those coefficients, then that implies that the subset has to be maximal, right? Because if something's orthogonal to everything in the collection, then all those coefficients appearing in the series are 0, and therefore the function is 0. So this question here is equivalent to asking whether or not this collection is maximal, which means if I have an element in L2 that is orthogonal to everything in here, then it has to be 0, which is this statement here, all right? So let me put a box around it. Based on what we've done, the question of convergence of Fourier series in big L2, and what I'm using here really as well is the fact that big L2 is complete, right? This all only works in a Hilbert space, right? At certain points, we relied on the fact that Cauchy sequences converge to something in the space, right? So the fact that I can kind of cleanly reduce this question down to what's in yellow relies on the fact that big L2 is complete, right? Which we did a lot of work to show and to construct, OK? All right. Now, so this is the question that we're going to try to answer, and let me go ahead and answer. I asked a question, so I should give the answer. The answer is yes, but it's going to take some work. This is a non-trivial matter. So let's see, how much time do I have? OK. So how we're going to proceed is via what may be referred to as Fayer's method. So again, our goal is to show this to answer the question about convergence of Fourier series in L2. Why in L2, because that's a complete Hilbert space that we're working in, that we're going to apply our general framework to. So let me start off with kind of a following simple calculation that for all F in L2 minus pi to pi, and for all natural numbers n, including 0, if I want to look at the nth partial sum of F, I can write this as the integral from minus pi to pi of a function evaluated at x minus t times f of t integrated dt. And again, this should be interpreted as the Lebesgue integral, even though I'm writing it using the notation that you used. Lord. Sorry. That e was awful. I just couldn't let it stay there. Even though I was using kind of this notation at one point to denote the Riemann integral, I'm now using this notation for the Lebesgue integral if the functions, if I'm talking about Lebesgue integration, which is not such an abusive notation because we found out that the Lebesgue integral of continuous functions is the Riemann integral. So let me finish the statement. So we can write it as some function of x minus t times f of t integrate from minus pi to pi, where dn of x, this is equal to the function, which is 2n plus 1 over 2 pi. 1 over 2 pi when x equals 0. And sine of n plus 1 half of x over 2 pi sine x over 2 when x does not equal 0. In this function here, so first off, note that this is a continuous function. As x converges to 0, using L'Hopital's rule, if you like, this thing converges to 2n plus 1 over 2 pi. In fact, it's a smooth function. This function here is referred to as the Dirichlet kernel. So as a first step, I said we're going to look at, we're going to rewrite the partial sums in this way. I'll tell you why in a minute. But let's just take this as a warm up calculation of some calculations to come. So what's the proof we have that the nth partial Fourier sum of f, this is equal to n less than or equal to n of, let me just write out here what the Fourier coefficient is, 1 over 2 pi minus pi to pi of e to the minus i of f of t e to the minus i nt dt e to the i n x. And this is just a finite sum, so I can bring this inside the integral and combine everything. And I get this is equal to minus pi to pi of f of t times dn of x minus t, where dn of, so in fact, let me not jump ahead. I'll go ahead and write this out. This is equal to now sum times e to the i n x minus t dt. So this is dn. All right, so dn, so call this thing dn of x minus t, x minus t appearing there. And now let's compute dn of x. So let me just rewrite what it is, sum n less than or equal to n e to the i n x. Where did the t go again? Again, this is dn of x minus t, so the argument's there. So dn of x is, there's the argument. Maybe I should have put a y or something like that, but I didn't think that far ahead. So this is the d capital N. And now let's just kind of massage this a little bit. We can write as e to the minus i n x times now the sum from n equals 0 to 2n e to the i n x. This is a sum from, if you'd like, n equals minus capital N to n. So if I factor out an e to the minus i n x, I can write this sum as this sum. Now, this is a geometric sum. This e to the i n x, again, this is something that you can just check from the definition. This is also equal to e to the i x raised to the n power. And I know how to sum things that involve something being raised to the nth power, finite sums, that is. This is equal to 1 over 2 pi times e to the minus i n x times 1 minus e to the i 2n plus 1 x over 1 minus e to the i x, the thing that's appearing here. 2n plus 1, the thing that appears on top, plus 1. Now, multiplying through by this e to the i n x, pulling out a half e to the i x over 2 and distributing that to the bottom, we get that the previous is equal to 1 over 2 pi. So first off, this is valid only when x is not equal to 0. When x equals 0, I just get 1 here, and I get 1 here. And then I get the sum from 0 to 2n, which is equal to 2n plus 1. That's what I get when x equals 0. So this is valid for x not equal to 0. And so I get e to the i n plus 1 x. I should say, after I've taken away a half x that appeared with this 1x and distributed it down on the bottom, e to the i x over 2 minus e to the minus i x over 2. Now, if I have e to the i times something minus e to the minus i times that something, and I subtract those two, I pick up 2i times sine of whatever this real number is. So I pick up 1 over 2 pi times 2i sine of n plus 1 half x over 2i sine of x over 2. And these 2i's cancel. And that equals 1 over 2 pi sine of n plus 1 half x over sine x over 2, which is what I wanted. All right. So what's the idea of trying to prove this? In the end, I mean, in the beginning, I should say, we were asking about the convergence of the partial sums, the partial Fourier sums to f. And we don't know that going in. That's what we're trying to prove. So maybe working with the partial sums is not the best thing. What am I getting at here? How about I introduce the next bit, and then I'll explain why we're interested in it. So if f is in L2 minus pi to pi, we define the nth Cesaro Fourier mean of f. So this is the new bit of terminology. This is going to be the average of the partial sums of f. This we denote by sigma n of f of x. This is equal to the average of the first n partial sums of f. OK? All right. So in the end, what we'd like to do is, we're trying to establish that this claim in the yellow box. If the Fourier coefficients are all 0, then the function has to be 0. So you may think, well, let's prove that the partial sums converge to the function f. And that would give us immediately that the function is 0, because the partial sums would all be 0, because they involve the coefficients of f. But that's kind of ridiculous, because that's actually what we're trying to prove. That's equivalent to the question that we're trying to, that's equivalent to what's in the yellow box. We're not making our life any easier by doing that. OK, so now what one can do instead is, instead of trying to prove what's in the yellow box, that if all the coefficients are 0, the function is 0, what if we can prove that this object now converges to f? OK? This object here, which is this mean of the partial sums, maybe has better properties than the partial sums originally that we were trying to study, right? Remember, if you look back to 18100, if you have a, just say, a sequence of real numbers which converges, you can define a Cesaro mean of that by averaging the first n terms, just like we did here. There's an n plus 1 here, because we're starting at 0 and going up to n, rather than going from 1 to n. But if you have a sequence of real numbers, you can look at its Cesaro sums, or Cesaro means. And what's great about the Cesaro means is that it kind of behaves a little bit better than the sequence you start with, but you don't lose any information. So if the original sequence converges, then the Cesaro mean also converges, right? So if you're expecting the partial sums to converge to f, then the Cesaro means should converge to f, OK? But the Cesaro means have even better quality. Let's go back to sequences of real numbers. You could have sequences of real numbers that don't converge whose Cesaro means do converge, right? So take the sequence 1, minus 1, 1, minus 1, 1, minus 1, and so on, right? That sequence doesn't converge, but the Cesaro means do converge. The Cesaro mean is 1, 0, 1 third, 0, 1 fifth, 0, 1 seventh, 0. So the Cesaro means converge to 0. So all of that is to say that this object here, which is the average of the partial sums, we expect to behave better than just how the partial sums converge. We expect it to have better convergence properties, OK? And what does better convergence properties mean? Quite honestly, it means we should be able to show it converges to f in hopefully some sort of straightforward way, or maybe not straightforward way, but in a, yeah, I don't know how to describe that. And that's what we'll do, OK? That's the plan is what we're going to show is that for every f in L2, the Cesaro means converge to f in L2, meaning the limit as capital N. So let me. So what's the goal that we'll show is we'll show that the Cesaro means, the Cesaro Fourier means of f converge to f in L2, OK? Now, if we can do this, then we will have answered and we will have shown what's in the yellow box, right? Because if you assume all of the Fourier coefficients are 0, then all of the partial sums are 0, and therefore, all the Cesaro means are 0. And by this thing that we are hoping to prove, this will prove that 0 converges to f, and therefore, f is 0, which is what we wanted to show, OK? So one more time, we want to prove that if all the Fourier coefficients are 0, then the function has to be 0. Now, if all the Fourier coefficients are 0, then all the partial sums are 0, and therefore, all the Cesaro means are 0. And if we're able to prove this holds for all f in L2, then this would tell us that 0, which is what all of these Cesaro Fourier means are, converges to f, and therefore, f is 0, OK? Our desired conclusion. And from that, we conclude that the collection e to the i nx over square root of 2 pi is a maximal, is an orthonormal basis for L2. And therefore, the Fourier series of a given L2 function converges to the function in L2, meaning f minus the partial sum converges to 0 as n goes to infinity, OK? All right, and so that'll be what we do next time, is prove this claim right here.