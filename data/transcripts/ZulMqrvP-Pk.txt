 Το επόμενο πρόγραμμα είναι προσδοκημένο στη δικαιωμή Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει να προσφέρει υψηλές ειδικές παιδικές πιθανότητες αξιόπιστα. Για να κάνετε μια διευθύνση ή να παρακολουθείτε περισσότερα υλικά από χιλιάδες μαθητές MIT, επισκεφτείτε MIT OpenCourseWare στηn ocw.mit.edu. Λοιπόν, σήμερα θα ξεκινήσουμε με την παραγωγή του τι συζητήσαμε την τελευταία φορά, θα επισκεφθούμε τη δεφινίση των μαρκών των κλίμακων, και μετά, η μεγαλύτερη μέρα της διευθυνσίας θα συγκεντρωθούμε στον ανθρώπινο συμπεριφέρον τους, δηλαδή θα δούμε τι κάνει ένα μαρκόν των κλίμακών, αν έχει λειτουργεί για πολύ καιρό, τι μπορούμε να πούμε για τις προφανείς των διαφορετικών κλιμάκων. Λοιπόν, θα ήθελα να επαναλαμβάνω το κείμενο που έκανα την τελευταία φορά, ότι οι μαρκές των κλίμακων είναι μια πολύ χρήσιμη κλίμακα των μοντέων, και πάντα ό,τι είναι στον πραγματικό κόσμο μπορεί να είναι σχεδιασμένο με ένα μαρκόν των κλίμακών, αν και αν καθορίζετε την κατάστασή σας στην καθαρά τρόπη. Λοιπόν, θα δούμε μερικά παραδείγματα, θα δούμε περισσότερα παραδείγματα στις προβλήματα που θα κάνετε στο δουλειό και στην δραστηριοδοχή. Στην άλλη, δεν θα πάμε πολύ βαθύ σε παραδείγματα, αλλά θα εξελίξουμε την γενική μεθοδολογία. Στην άλλη, δεν θα πάμε πολύ βαθύ σε παραδείγματα, αλλά θα εξελίξουμε την γενική μεθοδολογία. ΟΚ. Βεβαίως, οι μοντέλες του Markov μπορούν να είναι αρκετά γενικές, μπορούν να λειτουργούν σε συνεχή ή συγκεκριμένη χρόνο, μπορούν να έχουν συνεχή ή συγκεκριμένη κλίμακα. Σε αυτή τη σχέση θα παραμείνουμε μόνο στο πράγμα όπου η κλίμακα είναι συγκεκριμένη και η χρόνο είναι συγκεκριμένη, γιατί αυτό είναι το πιο απλό πράγμα. Και επίσης, είναι το πράγμα όπου βγάζετε την αισθητορία σας πριν πάτε σε περισσότερα γενικές περίπτωσες, ίσως σε άλλες σχέσεις. Οπότε, το κράτος είναι διεξαρτημένο. Υπάρχει ένα διεξαρτημένο και ένα φινάλιο. Υπάρχει ένα φινάλιο τρόπο κράτους, και σε οποιοδήποτε στιγμό το πρόβλημα βρίσκεται σε ένα από αυτούς τους κράτους. Το χρόνο είναι διεξαρτημένο, οπότε κάθε μοντέλο της χρόνου κάποιος χιούρτζει και τότε το κράτος βγάλει, και όταν βγάλει μπορεί να βγει στο ίδιο μέρος ή να βγει σε άλλο μέρος. Η εξέλιξη του πρόβλημας είναι οδηγημένη από τις προφανωτικές μετατροπές. Pij είναι η προφανωτική ότι το επόμενο κράτος είναι j, διότι το τώρατο κράτος είναι i. Και η πιο σημαντική πραγματικότητα που έχει η κλίμακα Markov, η δεφινιότητα μιας κλίμακας ή πρόβλημας Markov, είναι ότι αυτή η προφανωτική π.i.j. είναι η ίδια κάθε φορά που βγάλεις στο κράτος i, όχι με αφορά πώς το βγάλεις εκεί, και όχι με αφορά τι ώρα είναι. Οπότε, το μοντέλο που έχουμε είναι οδηγμένο, το οποίο γραφτικά σημαίνει ότι αυτές οι προφανωτικές μετατροπές είναι τα ίδια κάθε φορά. Οπότε, το μοντέλο είναι αδύνατο, σε αυτό το σημαντικό. Είμαστε ενδιαφέρον με το τι θα κάνει η κλίμακα ή το πρόβλημα σε πλήρη περίοδο. Είμαστε ενδιαφέρον, ας πούμε, με την προφανωτικότητα ότι ξεκινώντας σε μια συγκεκριμένη κίνηση, και μερικές φορές μετά, βρισκόμαστε σε κάποια συγκεκριμένη κίνηση j. Ευτυχώς, μπορούμε να καταγραφούμε αυτές τις προφανωτικές μετατροπές. Βεβαίως, στην πρώτη φορά, η προφανωτικότητα που είμαστε μια φορά μετά σε κίνηση j, δεδομένου ότι είμαστε τώρα σε κίνηση i, από την κατεστημότητα, αυτό είναι μόνο τα προφανωτικά μετατροπές. Άρα, γνωρίζοντας αυτά, μπορούμε να ξεκινήσουμε μια προφανωτική μετατροπή που μας πει ότι οι προφανωτικές μετατροπές είναι για περισσότερα βήματα, περισσότερα από τις τελευταίες βήματα. Αυτή η προφανωτική μετατροπή είναι μια ορισμένη ορμόλογη. Είναι πάντα αλήθεια. Μπορείτε να την κοπείτε ή να την θυμηθείτε. Αλλά υπάρχει μια μεγάλη ιδέα πίσω από αυτή την ορμόλογη που πρέπει να κρατήσετε στο σκοπό. Είναι μια ιδέα διατυπωσίας και κερδίσης. Ας το φτιάξουμε. Η πιθανότητα ότι βρίσκετε στο στόμα j, την σκοτώσετε σε πιθανότητες των διαφορετικών τρόπων που μπορείτε να δεχτείτε στο στόμα j. Ποιες είναι αυτές τις διαφορετικές τρόπες? Τις διαφορετικές τρόπες είναι τα διαφορετικά στόματα k σε οποία μπορείτε να βρίσκετε την προηγούμενη στιγμή. Βρίσκετε στο στόμα k την προηγούμενη στιγμή και με την πιθανότητα pkj κάνετε μια διακοπή στο στόμα j. Αυτό είναι ένα πιθανό σκenario που σας φέρνει στο στόμα j μετά από εξαρτησίες. Και με την κοψή όλων των k, έχουμε διαφθεί όλες τις πιθανότητες. Πριν αρχίσουμε την πιο σοβαρά πράγματα, ας κάνουμε λίγο προσοχή για να καταλάβουμε πώς χρησιμοποιούμε τις προσοχές διακοπής για να καταλάβουμε πιο γενικές προσοχές, μετά θα μιλήσουμε για κάποιες δραστηριότητες των Markov κλίμακων και μετά θα φτάσουμε στο κύριο επιχειρήμα σήμερα, το οποίο είναι το κίνημα στήριξης. Άρα κάποιος σας δώσει αυτήν την κλίμακα και η κατάστασή μας είναι ότι αυτές οι στροφές που δεν είναι δείχνει εδώ αντιμετωπίζουν 0 προσοχή, και κάθε ένα από τις στροφές που είναι δείχνει έχει μια αρχή που δεν είναι 0 και κάποιος μας την δίνει. Αντιμετωπίστε ότι η κλίμακα ξεκινάται στο κίνημα 1. Θα θέλαμε να καταλάβουμε την προσοχή ότι ακολουθεί αυτήν την συγκεκριμένη τραγωδία. Δηλαδή, πηγαίνει σε 2, μετά σε 6, μετά σε 7. Πώς καταλάβουμε την προσοχή μιας συγκεκριμένης τραγωδίας? Αυτή είναι η προσοχή της τραγωδίας από 1, που πηγαίνεις σε 2, μετά σε 6, μετά σε 7. Η προσοχή αυτής της τραγωδίας είναι ότι χρησιμοποιούμε τη ρολή της διευθυνσίας. Η προσοχή που συμβαίνουν διάφορα πράγματα είναι η προσοχή ότι το πρώτο πράγμα συμβαίνει, η οποία είναι μια μετατραπτώση από 1 στο 2, και μετά, διότι είμαστε στο κίνημα 2, διευθυνθούμε με την προσοχή συνδεδεμένη ότι το επόμενο πράγμα συμβαίνει, δηλαδή ότι X2 είναι εξατμών 6, διότι πριν από τώρα είμαστε στο κίνημα 1. Αυτή η προσοχή συνδεδεμένη είναι απλά P2,6. Και παρατηρήστε ότι αυτή η προσοχή συνδεδεμένη εφαρμόζεται, δεν με αφορά πώς έρθαμε στο κίνημα 2, αυτό είναι η αξία της προσοχής, οπότε δεν μας αρνούν την πραγματικότητα ότι ήρθαμε σε ένα συγκεκριμένο τρόπο, διότι ήρθαμε εδώ, η αξία P2,6 είναι η αξία ότι η επόμενη μετατραπέζη μας πάρει στο 6. Και τότε, διότι όλα αυτά συνέβη, διότι πριν από τώρα είμαστε στο κίνημα 6, πρέπει να διευθυνθούμε με την αξία ότι η επόμενη μετατραπέζη μας πάρει στο κίνημα 7, και αυτό είναι απλά P6,7. Λοιπόν, για να βρεις την αξία που ακολουθεί μια συγκεκριμένη μετατραπέζη, μόνο πρέπει να διευθυνθείς τις προσδοκίες διαδρομής με το συγκεκριμένο τρόπο. Αν θέλεις να καταλήξεις κάτι άλλο, όπως, για παράδειγμα, η προσοχή ότι 4 βαθμίδες μετά βρίσκομαι στο κίνημα 7, διότι άρχισα, ας πούμε, σε αυτό το κίνημα. Πώς καταλήξεις αυτή την προσοχή? Μία τρόπη είναι να χρησιμοποιήσεις μια εφαρμογή για τα Rij, που ξέρουμε ότι είναι πάντα αξιωμένα. Αλλά για μικρές και απλές παραδείγματα και με μικρό χρόνο, μπορείς να το κάνεις με μια πρόσοχη δύναμη. Πώς θα ήταν η πρόσοχη δύναμη? Αυτό είναι το πράγμα που 4 βαθμίδες μετά βρίσκομαι στο κίνημα 7. Αυτό το πράγμα μπορεί να συμβεί με διάφορες τρόπες, οπότε μπορούμε να παρατηρήσουμε την πλήρη των διφέρεν τρόπων και να γράψουμε τις προφανείς τους. Αρχίζοντας από 2, μια πιθανότητα είναι να ακολουθήσω αυτή την τραγουδία. 1-τραγουδία, 2-τραγουδία, 3-τραγουδία, 4-τραγουδία, και αυτό με φέρνει στο κίνημα 7. Ποιο είναι η προφανότητα αυτής της τραγουδίας? Είναι P2,6, P6,7, P7,6, και τότε P6,7. Αυτή είναι η προφανότητα μιας συγκεκριμένης τραγουδίας που με φέρνει στο κίνημα 7 μετά από 4 εξετάσεις. Αλλά υπάρχουν και άλλες τραγουδίες. Ποιο μπορεί να είναι αυτό? Μπορώ να ξεκινήσω από το κίνημα 2, να πάω στο κίνημα 6, να παραμείνω στο κίνημα 6, να παραμείνω στο κίνημα 6 μια φορά, και τότε από το κίνημα 6 να πάω στο κίνημα 7. Και... Ωραία, πρέπει να υπάρχει ένας άλλος. Ποιο είναι το άλλο? Νομίζω πως μπορώ να πάω... 1, 2, 6, 7. OK, αυτή είναι η άλλη τραγουδία. Πлюс P21, P16... Όχι. P12, P26, και P67. Λοιπόν, η προφανότητα της μετατραπτώσεις, η προφανότητα τελικής αναγκασίας στο κίνημα 7, είναι χαρακτηριστεί ως η ποσότητα των δυνάμεων τρόπων που μπορώ να πάω στο κίνημα 7 σε ακριβώς 4 βήματα. Λοιπόν, μπορούμε να κάνουμε αυτό πάντα χωρίς να γνωρίζουμε τόσο πολύ για Markov chains ή για τη γενική ορισμό για τα Rij's που είχαμε. Ποιο είναι το πρόβλημα με αυτή την προϊόντα? Το πρόβλημα με αυτή την προϊόντα είναι ότι το ποσό δυναμωμένων δραστηριότητες γίνεται αρκετά μεγάλο αν αυτό το περιοδικό είναι λίγο μεγαλύτερο. Αν αυτοί 4 ήταν 100 και ρωτήσατε πόσες διαφορετικές δραστηριότητες με διάφορα δραστηριότητες είναι εκεί, που με φέρνουν από εδώ να εκεί, αυτό το ποσό δραστηριότητες θα ήταν μεγάλο. Θα μεγαλώσει εξωτερικά με το χρόνο. Αυτή την καλύτερη κατασκευή θα ήταν απασχολημένη. Η βασική ορισμότητα, η αναγκασία που έχουμε για τα Rij's, είναι ένας μορφός τρόπος να οργανώσουμε αυτή την κατασκευή, ώστε η ποσότητα που κάνετε δεν είναι εξωτερική στο χρόνο. Αλλά, είναι λινεύρη με το χρόνο. Για κάθε βήμα χρόνου που χρειάζεται στο χρόνο, συνεχίζετε την ίδια εφαρμογή πάνω και πάνω. OK. Τώρα, η άλλη πράγματα που συζητήσαμε τελικά την προηγούμενη φορά ήταν η κλασσифικασία των διαφορετικών κύκλων της Markov κλίμακας σε διαφορετικά είδη. Η Markov κλίμακα, γενικά, έχει κύκλες που είναι συνεχισμένες, το οποίο σημαίνει ότι από ένα συνεχισμένο κύκλο μπορώ να πάω κάπου άλλο, αλλά από αυτό κάπου άλλο υπάρχει πάντα κάποιο τρόπο να έρθω πίσω. Άρα, αν έχετε κλίμακα τέτοιας φορής, δεν με αφορά πού πηγαίνετε, δεν με αφορά πού ξεκινάτε, μπορείτε πάντα να έρθετε πίσω από όπου ξεκινήσατε. Κλίματα τέτοιας φορής είναι ονομαστές. Από την άλλη πλευρά, αν έχετε κλίματα τέτοιας φορής και μετατραπτώσεις τέτοιας φορής, τότε αυτές οι κλίματα είναι συνεχισμένες στον σημαντικό ότι από αυτές τις κλίματα είναι πιθανό να πάτε κάπου άλλο, από το οποίο δεν υπάρχει τρόπο να έρθετε πίσω από όπου ξεκινήσατε. Η γενική στροφή μιας Markov κλίμακας είναι, γενικά, μια συλλογή τρανσιωνικών κλιματών. Είστε σίγουροι ότι θα αφήσετε τρανσιωνικές κλιματα. Και μετά από το αφήγημα των τρανσιωνικών κλιμάτων, εισέλθετε σε μια κλίμακα με την οποία σας κρατά. Σας κρατάτε αν βγαίνετε εδώ, σας κρατάτε αν βγαίνετε εκεί. Αυτή είναι μια συνεχής κλίμακα κλίμακας. Από κάθε κλίμακα μπορείτε να πάτε σε κάθε άλλη κλίμακα σε αυτήν την κλίμακα. Εδώ μπορείτε να πάτε σε κάθε άλλη κλίμακα σε αυτήν την κλίμακα. Αλλά αυτές τις δύο κλίμακες δεν ταμοιραζόμαστε. Αν ξεκινάτε εδώ, δεν υπάρχει τρόπο να πάτε εκεί. Αν έχετε δύο συνεχές κλίμακες, τότε είναι ξεκάθαρο ότι οι αρχικές συνθήκες της μαρκούς σας κλίμακα σημαίνουν στον πλούτο τρόπο. Αν ξεκινάτε εδώ, θα είστε κρατάτες εδώ, στον πλούτο τρόπο, και σχεδόν εδώ. Οπότε οι αρχικές συνθήκες κάνουν διαφορά. Ας πούμε ότι ξεκινάτε εδώ, μεταφεύχετε, και κάποια στιγμή κάνετε αυτή τη μεταφεύχηση, βρίσκοντας εδώ. Και μέσα εδώ συνεχίζετε να διακυρνίζεστε γιατί της λιτότητας συνεχίζετε να επισκεφθείτε όλες τις κράτης πάνω και πάνω. Και ελπίζοντας ή μπορείτε, σε πολύ διάφορο τρόπο, δεν αφορά ακριβώς τι ώρα είναι ή πού ξεκίνησατε, αλλά η πιθανότητα να είστε σε ένα συγκεκριμένο κώδικο είναι αυτό ίσο, από το τι ήταν η αρχική συνθήκη. Οπότε με ένα μόνο συνεχόμενο κλάσμα ελπίζουμε ότι οι αρχικές συνθήκες δεν αφορούν. Με δύο συνεχόμενες κλάσματα ή περισσότερες συνεχόμενες κλάσματα, οι αρχικές συνθήκες θα αφορούν. Οπότε πόσες συνεχόμενες κλάσματα έχουμε είναι κάτι που έχει να κάνει με το πραγματικό συμβίωμα της κλάσμας και την έκταση με την οποία αρχικές συνθήκες αφορούν. Ένα άλλο τρόπο που οι αρχικές συνθήκες μπορούν να αφορούν είναι αν η κλάσμα μας έχει μια περιοδική στρατηγική. Υπάρχουν πολλά τρόπα που καθορίζουν την περιοδικότητα. Η τρόπα που βρίσκομαι ο πιο αυτοκίνητος και με την λίγη πολλά σύνδεσματαγων είναι η επόμενη. Το χώρο κλάματος είναι καθοριστικό. Αν μπορείς να λάμπει τις κράτης σε ένα τρόπο κλάματος που λέγεται D-κλάματος ή ομάδες και το διαγραμμάτο έχει την πραγματικότητα ότι από ένα κλάμα πάντα κάνεις μια τρανσίστιο σε το επόμενο κλάμα. Εδώ, D είναι εξαρτημένο από 2. Έχουμε 2 υπολογές της κλάματος. Όταν είμαστε εδώ, την επόμενη φορά θα είμαστε εκεί. Όταν είμαστε εδώ, την επόμενη φορά θα είμαστε εκεί. Η κλάματος έχει μια περιοδική στρατηγική. Μπορεί να υπάρχει ακόμα κάποια αρνητικότητα. Όταν βγάλω από εδώ να εδώ, η στάση με την οποία βγάλω μπορεί να είναι αρνητική, αλλά είμαι σίγουρο ότι θα είμαι μέσα εδώ. Και την επόμενη φορά θα είμαι σίγουρο ότι είμαι μέσα εδώ. Αυτό θα είναι μια στρατηγική διαγραμμάτο με την οποία έχουμε μια περίοδο 3. Αν ξεκινάς σε αυτή την κλάμα, ξέρεις ότι την επόμενη φορά θα είσαι μέσα εδώ, και τέτοια. Οπότε, αυτή η κλάμα έχει μια περιοδική στρατηγική και αυτή η περιοδικότητα θα είναι διατηριασμένη. Αν ξεκινάς, ας πούμε, σε αυτή την κλάμα, σε σωστές φορές είμαι σίγουρο ότι είμαι εδώ, σε σωστές φορές είμαι σίγουρο ότι είμαι εδώ. Οπότε, η σωστή φορά έχει σημασία στην αποδεχόμενη διαγραμμάτο των διαφορετικών στρατών και, σε συγκεκριμένη φορά, η πιθανότητα να είμαι σε μια συγκεκριμένη στρατη δεν μπορεί να μεταφερθεί σε μια στρατη. Η πιθανότητα να είμαι σε μια στρατη μέσα εδώ θα είναι 0 σε σωστές φορές. Συνήθως, θα είναι κάποια σωστή φορά σε σωστές φορές. Οπότε, πηγαίνει 0, σωστή, 0, σωστή, 0, σωστή, δεν καταλάβει σε καμία πράγμα. Οπότε, όταν έχουμε περιοδικότητα, δεν εξετάζουμε τις πιθανότητες του κράτους να μεταφερθούν σε κάτι, αλλά, πιο αυτοί, εξετάζουμε να αυξάνονται. Τώρα, πώς μπορούμε να πούμε αν μια στρατη είναι περιοδική ή όχι. Εντάξει, υπάρχουν συστηματικές τρόπες για να το κάνουμε, αλλά, συνήθως, με τα εξετάσεις που βλέπουμε σε αυτή τη κλассική, μόνος μας ελέγχει την στρατη και πεινάμε αν είναι περιοδική ή όχι. Πολλοί πιστεύουν ότι είναι περιοδική. Δεν είναι. Πολλοί πιστεύουν... ένα. Πολλοί πιστεύουν ότι δεν είναι περιοδική. Εντάξει, δεν είναι περιοδική. Ας δούμε. Ας κάνω κάποια σχηματρία εδώ. Εντάξει. Είναι περιοδική? Είναι. Από μια κόκκινη στάση μπορείς να φτάσεις μόνο σε μια μικρή στάση. Από μια μικρή στάση μπορείς να φτάσεις μόνο σε μια κόκκινη στάση. Αυτή η κλίμακα, ακόμα και αν δεν είναι εμφανίζοντας από το φωτογραφικό, έχει αυτή την στρατη. Μπορούμε να οργανώσουμε τις στάσεις σε κόκκινες στάσεις και μικρές στάσεις. Από τις κόκκινες πάντα φτάσαμε σε μια μικρή και από μια μικρή πάντα φτάσαμε σε μια κόκκινη. Αυτό σας λέει ότι κάποιες φορές το κοινωνικό σχόλινγκ δεν είναι εύκολο. Σε άλλη πλευρά, κάτι πολύ χρήσιμο να γνωρίσουμε. Κάποιες φορές είναι πολύ εύκολο να πει ότι μια κόκκινη δεν είναι περιοδική. Ποιο είναι αυτό το πράγμα? Αντιμετωπίζουμε ότι η κόκκινη σας έχει μια αυτοπροστασία κάπου, τότε, αυτοματικά, ξέρετε ότι η κόκκινη σας δεν είναι περιοδική. Ξέρετε, η δεφινιότητα της περιοδικής πρέπει ότι αν είστε σε μια συγκεκριμένη ομάδα κράτη, την επόμενη φορά θα είστε σε μια διαφορετική ομάδα. Αλλά αν έχετε αυτοπροστασίες, αυτή η πράγματική δεν είναι αλήθεια. Αν έχετε μια αυτοπροστασία είναι πιθανό να παραμείνετε μέσα στην ομάδα σας για την επόμενη φορά. Οπότε, όταν έχετε μια αυτοπροστασία, αυτό σημαίνει ότι η κόκκινη δεν είναι περιοδική. Και γυνάς αυτό είναι το απλύτερο και εύκολο τρόπο που μπορούμε να πούμε την περισσότερη φορά ότι η κόκκινη δεν είναι περιοδική. Οπότε τώρα έρχομαστε στο μεγάλο θέμα σήμερα, το κεντρικό θέμα, το οποίο είναι η ερώτηση για το τι κάνει η κόκκινη με τη διάρκεια. Η ερώτηση που μας ζητά και την οποία εξελίξαμε τελικά με την παρακολουθία μιας παραδείγματος, είναι κάτι που συνέβη στο παραδείγμα τελικά, οπότε ζητάμε αν αυτό συμβαίνει για κάθε σημείο της κόκκινης. Είμαστε ζητάμε αν η πιθανότητα που βρίσκεται στο κίνημα j κάποια φορά n καθαρίζεται σε μια ασφάλεια κίνημα αξίας, ας το ονομάσουμε πι-ασφαλή j, δηλαδή ζητάμε αν αυτή η ποσότητα έχει ένα σύμβολο όταν n πηγαίνει στην αιώνα, ώστε να μιλήσουμε για την ασφαλή πιθανότητα ζητών αξίας, και, παραπάνω, ζητάμε αν η ασφαλή πιθανότητα αυτής της ασφάλειας δεν αποτελεί την αρχική ασφάλεια. Σύν' άλλα λόγια, μετά από ότι η κόκκινη λειτουργεί για πολύ, πολύ χρόνο, δεν σημαίνει ακριβώς πόλος είναι, και δεν σημαίνει από πού ξεκίνησε η κόκκινη. Μπορείτε να μου πείτε ότι η πιθανότητα ότι το κράτος είναι ένα συγκεκριμένο j είναι απόψιμη η πιθανότητα πι-sub-j. Δεν αφορά ακριβώς τι ώρα είναι, όταν μιλήσετε ότι πολύ χρόνο έχει εξαρτάσει ώστε αυτό το n είναι ένα μεγάλο τόπο. Αυτή είναι η ερώτηση. Είδαμε παραδείγματα, και καταλαβαίνουμε ότι αυτό δεν θα είναι το πάντοτε πράγμα. Για παράδειγμα, όπως μόλις έχουμε δύο κλάσεις συνεχής, όπου ξεκινάμε δεν αφορά. Η πιθανότητα πι-j που είναι σ' αυτό το κράτος j θα είναι 0 αν ξεκινάμε εδώ, αλλά θα ήταν κάτι θετικό αν ξεκινήσαμε σε αυτό το κράτος. Οπότε η πρωτοβολία αφορά αν έχουμε πολλές κλάσεις συνεχής. Αλλά αν έχουμε μόνο ένα κλάσμα συνεχής κράτος από κάθε από κάθε από τα οποία μπορείτε να προσέξετε σε κάθε άλλο, τότε δεν έχουμε αυτό το πρόβλημα. Τότε εγγερμανίζουμε ότι οι πρώτες συνθήκες θα είναι ξεχάσμες. Αυτή είναι μια συνθήκη που χρειαζόμαστε. Και η δεύτερη συνθήκη που χρειαζόμαστε είναι ότι η κλάση δεν είναι συνεχής. Αν η κλάση είναι συνεχής, τότε αυτά Rij's δεν συνεχίζουν. Είναι συνεχώς συνεχίζοντας. Αν δεν έχουμε συνεχή, τότε δεν έχουμε συνεχής. Αυτό είναι η μεγάλη θεωρία του Markov χαύλου, η θεωρία της συνεχής συνεχής συνεχής. Ξέρει, ότι, ναι, οι Rij's συνεχίζουν σε μια σύνεχη θεωρία, την οποία λέμε συνεχή θεωρία πιθανότητα, όταν αυτές οι δύο συνθήκες είναι υπεροφανεμένες. Δεν θα προβλήματι αυτή τη θεωρία. Αν είστε σίγουροι για το αποτελέσμα αυτού του αποτέλεσματος, αλλά πιθανότητα είναι λίγο πολύ για το να το κάνουμε σε αυτή τη σχέση. Ποιο είναι η ιδιωτική ιδέα πίσω αυτής της θεωρίας? Ας δούμε. Ας σκεφτούμε ιδιωτικά για το γιατί η αρχική θέα δεν αφορά. Σκεφτείτε δύο κοπές της σύνδεσης σε μία συνεχής κλассική στιγμή, και δεν έχετε περιοδικότητα, σε κάποια στιγμή, αυτές τις δύο κατεύθυνσες θα συμμετέχουν απλά γιατί υπάρχει αρκετή αρχότητα εκεί. Ακόμα και αν ξεκίνησαμε από διαφορετικά μέρες, η κίνηση θα είναι η σύνδεση της θέα και η αρχή. Η αρχική θέα δεν αφορά την επίθεση της σύνδεσης σε μία συνεχής κλассική στιγμή, εις ο ο επόμενος τρόπος. Στο μόνο τρόπο see how we might calculate those steady state probabilities. The way we calculate the steady state probabilities is by taking this recursion, which is always true for the n-step transition probabilities, and take the limit of both sides. The limit of this side is the steady state probability of state j, which is pi sub j. The limit of this side, we put the limit inside the summation. Now as n goes to infinity, n minus 1 also goes to infinity. So this Rik is going to be the steady state probability of state k, starting from state i. Now where we start, it doesn't matter. So this is just the steady state probability of state k. So this term converges to that one. And this gives us an equation that's satisfied by the steady state probabilities. Actually, it's not one equation. We get one equation for each one of the j's. So if we have 10 possible states, we're going to get a system of 10 linear equations in the unknowns, pi 1 up to pi 10. OK, 10 unknowns, 10 equations, you might think that we are in business, but actually this system of equations is singular. 0 is a possible solution of this system. If you plug pi equal to 0 everywhere, the equations are satisfied. It does not have a unique solution. So maybe we need one more condition to get a uniquely solvable system of linear equations. It turns out that this system of equations has a unique solution. If you impose an additional condition, which is pretty natural, the pi j's are the probabilities of the different states, so they should add to 1. So you add this one equation to the mix. And once you do that, then this system of equations is going to have a unique solution. And so we can find the steady state probabilities of a Markov chain by just solving these linear equations, which is numerically straightforward. Now these equations are quite important. I mean, they're the central point in the Markov chain. They have a name. They're called the balance equations. And it's worth interpreting them in a somewhat different way. So intuitively, one can sometimes think of probabilities as frequencies. For example, if I toss an unbiased coin, probability 1 1 half of heads, you could also say that if I keep flipping that coin in the long run, 1 1 half of the time, I'm going to see heads. Similarly, let's try an interpretation of this pi j, the steady state probability, the long-term probability of finding myself at state j. Let's try to interpret it as the frequency with which I find myself at state j if I run a very, very long trajectory of that Markov chain. So the trajectory moves around, visits states. It visits the different states with different frequencies. And let's think of the probability that you are at a certain state as being sort of the same as the frequency of visiting that state. This turns out to be a correct statement. If you were more rigorous, you would have to prove it. But it's an interpretation which is valid and which gives us a lot of intuition about what this equation is saying. So let's think as follows. Let's focus on a particular state j and think of transitions into the state j versus transitions out of the state j, or transitions into j versus transitions starting from j. So transition starting from j, that includes a self-transition. So how often do we get a transition if we interpret the pi j's as frequencies? How often do we get a transition into j? Here's how we think about it. A fraction pi 1 of the time, we're going to be at state 1. Whenever we are at state 1, there's going to be a probability, p1j, that we make a transition of this kind. So out of the times that we are at state 1, there's a frequency, pi 1j, with which the next transition is into j. So out of the overall number of transitions that happen in a trajectory, what fraction of those transitions is exactly of that kind? That fraction of transitions is the fraction of time that you find yourself at 1 and times the fraction with which out of 1 you happen to visit next, state j. So we interpret this number as the frequency of transitions of this kind. At any given time, our chain can do transitions of different kinds, transitions of the general form. From some k, I go to some l. So we try to do some accounting. How often does a transition of each particular kind happen? And this is the frequency with which transitions of that particular kind happens. Now, what's the total frequency of transitions into state j? Transitions into state j can happen by having a transition from 1 to j, from 2 to j, or from state m to j. So to find the total frequency with which we would observe transitions into j, it's going to be this particular sum. Now, you are at state j if and only if the last transition was into state j. So the frequency with which you are at j is the frequency with which transitions into j happen. So this equation expresses exactly that statement. The probability of being at state j is the sum of the probabilities that the last transition was into state j. Or in terms of frequencies, the frequency with which you find yourself at state j is the sum of the frequencies of all the possible transition types that take you inside state j. So that's a useful intuition to have, and we're going to see in an example a little later that it gives us shortcuts into analyzing Markov chains. But before we move, let's revisit the example from last time. And let us write down the balance equations for this example. So the steady state probability that I find myself at state 1 is the probability that the previous time I was at state 1 and I made a self-transition. It's the probability that I was here last time and I made a transition of this kind, plus the probability that last time I was here and I made a transition of that kind. So plus pi 2 times 0.2. And similarly for the other states, the steady state probability that I find myself at state 2 is the probability that last time I was at state 1 and I made the transition into state 2, plus the probability that last time I was at state 2 and I made the transition into state 1. Now these are two equations in two unknowns, pi 1 and pi 2. But you notice that both of these equations tell you the same thing. They tell you that 0.5 pi 1 equals 0.2 pi 2. Either of these equations tells you exactly this, if you move terms around. So these two equations are not really two equations. It's just one equation. They are linearly dependent equations. And in order to solve the problem, we need the additional condition that pi 1 plus pi 2 is equal to 1. Now we have our system of two equations, which you can solve. And once you solve it, you find that pi 1 is 2 7ths and pi 2 is 5 7ths. So these are the steady state probabilities of the two different states. Now if we start this chain at some state, let's say at state 1, and we let it run for a long, long time, the chain settles into steady state. What does that mean? It does not mean that the state itself enters steady state. The state will keep jumping around forever and ever. It will keep visiting both states once in a while. So the jumping never ceases. The thing that gets into steady state is the probability of finding yourself at state 1. So the probability that you find yourself at state 1 at time 1 trillion is approximately 2 7ths. The probability that you find yourself at state 1 at time 2 trillion is again approximately 2 7ths. So the probability of being at that state settles into a steady value. That's what steady state convergence means. It's convergence of probabilities, not convergence of the process itself. And again, the two main things that are happening in this example, and more generally when we have a single class and no periodicity, is that the initial state does not matter. There's enough randomness here so that no matter where you start, the randomness kind of washes out any memory of where you started. And also in this example, clearly we do not have periodicity because we have self-arcs. And this in particular implies that the exact time does not matter. So now we're going to spend the rest of our time by looking into a special class of chains that's a little easier to deal with, but still it's an important class. So what's the moral from here? This was a simple example with two states, and we could find the steady state probabilities by solving a simple system of 2 by 2 equations. If you have a chain with 100 states, it's no problem for a computer to solve a system of 100 by 100 equations. But you can certainly not do it by hand, and usually you cannot get any closed form formula, so you do not necessarily get a lot of insight. So one looks for special structures or models that maybe give you a little more insight, or maybe lead you to closed form formulas. And an interesting subclass of Markov chains in which all these nice things do happen is the class of birth-death processes. So what's a birth-death process? It's a Markov chain whose diagram looks basically like this. So the states of the Markov chain start from 0 and go up to some finite integer m. What's special about this chain is that if you are at a certain state, next time you can either go up by 1, you can go down by 1, or you can stay in place. So it's like keeping track of some population. At any given time, one person gets born, or one person dies, or nothing happens. I guess we're not accounting for twins here. So we're given this structure, and we are given the transition probabilities, the probabilities associated with transitions of the different types. So we use p's for the upward transitions, q's for the downward transitions. An example of a chain of this kind was the supermarket counter model that we discussed last time. That is, a customer arrives, so this increments the state by 1, or a customer finishes service, in which case the state gets decremented by 1, or nothing happens in which you stay in place, and so on. In the supermarket model, these p's inside here were all taken to be equal, because we assumed that the arrival rate was sort of constant, at the same at each time slot. But you can generalize a little bit by assuming that these transition probabilities, p1 here, p2 there, and so on, may be different from state to state. So in general, from state i, there's going to be a transition probability, pi, that the next transition is upwards. And there's going to be a probability, qi, that the next transition is downwards. And so from that state, the probability that the next transition is downwards is going to be qi plus 1. So this is the structure of our chain. As I said, it's a crude model of what happens at the supermarket counter. But it's also a good model for lots of types of service systems. Again, you have a server somewhere that has a buffer. Jobs come into the buffer, so the buffer builds up. The server processes jobs, so the buffer keeps going down. And the state of the chain would be the number of jobs that you have inside your buffer. Or you could be thinking about active phone calls out of a certain city. Each time that the phone call is placed, the number of active phone calls goes up by 1. Each time that the phone call stops happening, is terminated, then the count goes down by 1. So it's in processes of this kind that the model with this structure is going to show up. And they do show up in many, many models. Or you can think about the number of people in a certain population that have a disease. So one more person gets the flu, the count goes up. One more person gets healed, the count goes down. And these probabilities in such an epidemic model would certainly depend on the current state. If lots of people already have the flu, the probability that another person catches it would be pretty high. Whereas if no one has the flu, then the probability that you get the transition where someone catches the flu, that probability would be pretty small. So the transition rates, the incidence of new people who have the disease, definitely depends on how many people already have the disease. And that motivates cases where those P's, the upward transition probabilities, depend on the state of the chain. So how do we study this chain? You can sit down and write a system of n linear equations in the pi's. And this way, find the steady state probabilities of this chain. But this is a little harder. It's more work than one actually needs to do. There's a very clever shortcut that applies to birth-death processes. And it's based on the frequency interpretation that we discussed a little while ago. Let's focus on, let's put a line somewhere in the middle of this chain and focus on the relation between this part and that part in more detail. So think of the chain continuing this direction, that direction. But let's just focus on two adjacent states. And look at this particular cut. What is the chain going to do? Let's say it starts here. It's going to move around. At some point, it makes a transition to the other side. And that's a transition from i to i plus 1. It stays on the other side for some time. It gets here. And eventually, it's going to make a transition to this side. Then it keeps moving, and so on. Now, there's a certain balance that must be obeyed here. The number of upward transitions through this line cannot be very different from the number of downward transitions. Because we cross this way. Then next time, we'll cross that way. Then next time, we'll cross this way. We'll cross that way. So the frequency with which transitions of this kind occur has to be the same as the long-term frequency that transitions of that kind occur. You cannot go up 100 times and go down only 50 times. If you have gone up 100 times, it means that you have gone down 99, or 100, or 101, but nothing much more different than that. So the frequency with which transitions of this kind get observed, that is, out of a large number of transitions, what fraction of transitions are of this kind? That fraction has to be the same as the fraction of transitions that happen to be of that kind. What are these fractions? We discussed that before. The fraction of times at which transitions of this kind are observed is the fraction of time that we happen to be at that state. And out of the times that we are at that state, the fraction of transitions that happen to be upward transitions. So this is the frequency with which transitions of this kind are observed. And with the same argument, this is the frequency with which transitions of that kind are observed. Since these two frequencies are the same, these two numbers must be the same. And we get an equation that relates the Pi to Pi plus 1. This has a nice form because it gives us a recursion. If we knew Pi i, we could then immediately calculate Pi i plus 1. So it's a system of equations that's very easy to solve. Almost. But how do we get started? If I knew Pi 0, I could find Pi 1 and then use this recursion to find Pi 2, Pi 3, and so on. But we don't know Pi 0. It's one more unknown. It's an unknown. And we need to actually use the extra normalization condition that the sum of the Pis is 1. And after we use that normalization condition, then we can find all of the Pis. So you basically fix Pi 0 as a symbol, solve these equations symbolically, and everything gets expressed in terms of Pi 0. And then use that normalization condition to find Pi 0, and you're done. Let's illustrate the details of this procedure on a particular special case. So in our special case, we're going to simplify things now by assuming that all those upward Pis are the same, and all those downward Qs are the same. So at each point in time, if you're sitting somewhere in the middle, you have probability P of moving up and probability Q of moving down. This rho, the ratio of P over Q, is frequency of going up versus frequency of going down. If it's a service system, you can think of it as a measure of how loaded the system is. If P is equal to Q, it means that if you're at a state, you're equally likely to move left or right. So the system is kind of balanced. The state doesn't have a tendency to move in this direction or in that direction. If rho is bigger than 1, so that P is bigger than Q, it means that whenever I'm at some state in the middle, I'm more likely to move right rather than move left, which means that my state, of course it's random, but it has a tendency to move in that direction. And if you think of this as number of customers in Q, it means your system has the tendency to become loaded and to build up a queue. So rho being bigger than 1 corresponds to a heavy load where queues build up. Rho less than 1 corresponds to a system where queues have the tendency to drain down. Now let's write down the equations. We have this recursion, pi i plus 1 is pi i times pi over Q. In our case here, the Ps and the Qs do not depend on the particular index, so we get this relation. And this P over Q is just the load factor rho. Once you look at this equation, clearly you realize that pi 1 is rho times pi 0. Pi 2 is going to be, so I'll be in detail, so pi 1 is pi 0 times rho. Pi 2 is pi 1 times rho, which is pi 0 times rho squared. And then you continue doing this calculation, and you find that you can express every pi i in terms of pi 0, and you get this factor of rho i. And then you use the last equation that we have, that the sum of the probabilities has to be equal to 1. And that equation is going to tell us that the sum over all i's from 0 to m of pi 0 rho to the i is equal to 1. And therefore, pi 0 is 1 over the sum of the rho to the i for i going from 0 to m. OK. So now we found pi 0, and by plugging in this expression, we have the steady state probabilities of all the different states. OK, let's look at some special cases of this. Suppose that rho is equal to 1. If rho is equal to 1, then pi i is equal to pi 0. It means that all the probabilities, the steady state probabilities, are equal. It means that every state is equally likely in the long run. So this is an example that's called a symmetric random walk. It's a very popular model for modeling people who are drunk. So you start at the state, and at any point in time, either you stay in place, or you have an equal probability of going left or going right. There's no bias in other direction. You might think that in such a process, you will tend to kind of get stuck near one end or the other end. Well, it's not really clear what to expect. It turns out that in such a model, in the long run, the drunk person is equally likely to be at any one of those states. The steady state probability is the same for all i's if rho is equal to 1. And so if you show up at a random time, and you ask where is my state, you will be told it's equally likely to be at any one of those places. So let me make that note. If rho equal to 1 implies that all the pi i's are 1 over m plus 1, m plus 1 because that's how many states we have in our model. Now let's look at a different case. Suppose that m is a huge number. So essentially, a supermarket has a very large space, a lot of space, to store their customers. But suppose that the system is on the stable side. p is less than q, which means that there's a tendency for customers to be served faster than they arrive. The drift in this chain tends to be in that direction. So when rho is less than 1, which is this case, and when m is going to infinity, this infinite sum is the sum of a geometric series. And you recognize it, hopefully. This series is going to 1 over 1 minus rho. And because it's in the denominator, pi 0 ends up being 1 minus rho. So by taking the limit as m goes to infinity in this case, and when rho is less than 1 so that this series is convergent, we get this formula. So we get the closed form formula for the pi i's. In particular, pi i is 1 minus rho, rho to the i. So these pi i's are essentially a probability distribution. They tell us if we show up at time 1 billion and we ask where is my state, you will be told that the state is 0. Your system is empty with probability 1 minus rho. Or there's one customer in the system, and that happens with probability 1 minus rho, and it keeps going down this way. And it's pretty much a geometric distribution, except that it is shifted so that it starts at 0, whereas the usual geometric distribution starts at 1. So this is a mini introduction into queuing theory. This is the first and simplest model that one encounters when you start studying queuing theory. This is clearly a model of a queuing phenomenon such as the supermarket counter, with the p's corresponding to arrivals, the q's corresponding to departures. And this particular queuing system, when m is very, very large and rho is less than 1, has a very simple and nice solution in closed form. And that's why it's very much liked. And let me just take two seconds to draw one last picture. So this is the probability of the different i's. It gives you a PMF. This PMF has an expected value, and the expectation, the expected number of customers in the system, is given by this formula. And this formula, which is interesting to anyone who tries to analyze a system of this kind, tells you the following, that as long as rho is less than 1, then the expected number of customers in the system is finite. But if rho becomes very close to 1, so if your load factor is something like 0.99, you expect to have a large number of customers in the system at any given time. OK. All right. Have a good weekend. We'll continue next time.