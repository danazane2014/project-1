 So welcome, everybody. Welcome back. Let's get started with today's lecture. We, where were we? On Tuesday, we covered, the main topic was the recursion theorem, which allows programs to self-reference. And we saw some applications of that too. So we gave a new proof that ATM is undecidable. We looked at this language of minimal Turing machine descriptions. And we had a short digression into mathematical logic, where we looked at how one shows that there are true but unprovable statements in any reasonable formal system. OK, so today, we're going to shift gears entirely. And we're moving into the second half of the course, where we are beginning a study of computational complexity theory. And we'll say a little bit about that during the course of the lecture, of course. But the main things that we're going to cover in terms of content that you will need is defining the complexity classes and the class P. So and we'll prove a few theorems along the way, but that's the main objective of today's lecture. Computability theory, which was the subject of the first half of the course and which is what the midterm exam is going to cover, was a subject that was an active area of mathematical study in the first part of the 20th century. It really dates back into the late 19th century, in fact, when people were trying to figure out how to formalize mathematical reasoning. But it really got going in the 1930s with the work of GÃ¶del and Church and Turing, who really formalized for the first time what we mean by algorithm. And that allowed the study of algorithms to really get started. And it had its impact, as I mentioned, on the actual design, building, and thinking about real computers. The main question, if you kind of boil the subject down to a single question, is some language decidable or not? In complexity theory, which got started kind of when computability theory more or less wrapped up as a subject, largely because they answered many of the questions that they answered pretty much all of the questions that they were asking. So there really aren't interesting unsolved questions left in that field. And you really need mathematical questions to keep a subject alive, unsolved questions. So complexity theory got its start in the 1960s. And it continues on as an active area of research to the present day. And I guess, if you could boil it down, it would be, is a language decidable with some restriction on the resources, such as the amount of time or memory or some other kinds of resources that you might provide, randomness and so on. All of those fall within the area of computational complexity theory. So let's get ourselves started with an example. Here is a language that we've looked at in the past, A to the k, B to the k. And let's look at it now from the perspective of complexity. All of the languages that we're going to be studying in complexity are all going to be decidable languages. So the question of undecidability in complexity theory is not really of interest. It's all decidable languages. But the question is, how decidable? What sort of resources do you need to do the deciding? So for this language A, how many steps are needed? Well, we're going to spend a little time just kind of setting up the definitions of the subject and kind of motivating them. So for this language A, when I ask how many steps are needed, well, it's going to depend upon which input you have in mind. Some inputs might require more steps than others. So the way we're going to set the subject up, which is the standard way that people in this field look at it, and I think that applies to lots of examples outside as well, is that we're going to kind of group all of the inputs of the same length together and look at the maximum cost, the maximum number of steps you need to solve any one of those inputs of a given length. And we'll do that for each length. And the way we're going to frame it is in terms of giving a maximum or what's called an upper bound on the amount of time that you need to solve all of those inputs of length n. That's what's sometimes called worst case complexity. I'm sure many of you have seen this already. But just to make sure we're all together on this, you might contrast that, for example, with what's called average case complexity, where instead of looking at the most difficult case among all inputs of length n, you take the average of all inputs of length n. And then you have to do, then it's a little bit more complicated, because then you need to have a probability distribution on those inputs and so on. We're not going to look at it in this course from that perspective. We're only going to be looking at what's called worst case complexity. So let's begin then by looking at this in more detail and taking as our starting point the theorem that says that on a one-tape Turing machine, which is deciding this language A, A to the k, B to the k, you can do this on a one-tape Turing machine, M we're calling it, in at most some constant times n squared steps for any input of length n, where the constant is going to be fixed independent of n. So this is going to be having a constant factor in the complexity is going to come up often. And so instead of saying this over and over again, we're going to use a notation that M uses order n squared steps. I'm sure many of you have seen that terminology as well. But just for the purposes of making sure we're all together on that, there is this big O and little o notation. I'm expecting you to be familiar with that. Big O is when you apply it to functions as it's done. You say f is big O of g as for two functions f and g. It's basically if f is less than or equal to g if you're ignoring constant factors. And you say f is little o of g if f is strictly less than g if you're ignoring constant factors. That's kind of one sort of informal way of looking at it. The precise definition is given up there on the slide. And if you haven't seen it before, make sure you look at it in the book, where it's all carefully described and defined so that you're comfortable with these notions, because it's really we're going to be using this without any further discussion from here on. OK, so let's get to the proof then of this theorem that you can do the language A in order n squared steps. Not super hard. I think if I ask you to come up with an algorithm to solve A, this would be the algorithm that you would find, basically. First, you would start off by scanning the input, w, to make sure it's of the right form. So a run of a's followed by a run of b's of some lengths. And if it's not of that form, then you're going to reject right away. The next thing you'll do is then go through a repeat loop in the Turing machine. And if you imagine here is your machine, here is the input w, you're going to go through that repeating repeatedly. Of course, you can do this in a number of different ways. But here's the way I have in mind for you on this slide. Anyway, we're going to scan the entire tape, crossing off a single a and a single b on a scan. And then you're going to keep doing that until you've crossed off everything, unless you run out of a's or you run out of b's. In that case, you're going to reject. If you run out of a's or b's before you run out of the other type, then you know that you started out with an unequal number. And so the machine is going to reject. If you've managed to cross them all off without running out of one before the other, then you'll accept. I know this is kind of obvious, but I think it's important to get us all together on this at the beginning. So here's a little animation of the Turing machine doing that. I'm not showing the motion of the head, but imagine the head scanning back and forth, crossing off these a's and b's, one a and one b on each pass, until they're all crossed off. And then it accepts, unless, of course, it runs out of a's or b's before the other type. Then it rejects. Now, let's do a very quick informal analysis of how much time this has taken. So the very first stage, I'm calling each of these things stages of the Turing machine to distinguish them from the steps of the Turing machine, which the individual transition function moves. So this is the entire stage of the machine. The very first stage takes order n steps, because you have to make a scan across the input. And then I'm not giving all the full detail. Of course, you're going to scan, and then you're going to return the head back to its starting position. That's just going to be an extra factor of n, an extra n. So that's what we're talking about, being order n steps for the very first stage. And then as you go through the repeat loop, each time you go through the repeat loop, you're going to cross off one a and one b. So that's going to mean you're going to have to do this roughly order n times in order to cross off all the a's and b's. So there's going to be order n iterations of this repeat loop. Each one of them is going to, again, require a scan. So that's order n steps for each one of the iterations. So adding that all up, the very top row gives us the order n. And then we have the order n iterations times order n steps is order n squared steps. And so the sum of these two is order n squared steps due to the nature of arithmetic when you have the big O notation. The dominant term overrides all of the others. So that's, in a nutshell, how we will, this is our very first example of analyzing the Turing machine algorithm for a language. So let me ask you now whether there is some other Turing machine, some other one-tape Turing machine, which can do better than this Turing machine does in terms of how much time it takes. So one idea that you might have, instead of crossing off a single a or a single b, maybe you can cross off 2 a's and 2 b's or 10 a's and 10 b's. Well, that'll cut down the running time by a factor of 10. But from the standpoint of this theorem, it's still going to be an order n squared algorithm. And so that really doesn't change the amount of time used from the perspective of, from our perspective, where we're going to be ignoring the constant factors on the running time. So I ask you here, can you do better than just improving things by a constant factor? There we go. OK, so here's a check-in on this problem, on the problem A. Solving, deciding A on a one-tape Turing machine. Can we do better than order n squared, as I just described in that theorem, in that algorithm for that theorem? Or can you get it down to n log n? Or maybe you can get it down to order n. What do you think? Obviously, we're just getting started. But just make your best guess. And let me just post that for you as a poll. What's most important to me is that you understand the terminology that we're using and the way we're talking about it. Because that's going to be setting us up for the definitions that are going to come a little bit later in the lecture. OK, so I'm going to close the poll. We're kind of all over the place on it. But that's good, since we haven't really covered this material yet. In fact, B is the correct answer. We can improve this algorithm down to order n log n, but not all the way down to order n. So let me show you how you do it in order n log n on the next slide. And so here is a one-tape Turing machine that can decide A by using only order n log n steps instead of order n squared steps. So this is a significant improvement. So I'll describe the Turing machine here again. It is the picture of the machine on an input. And the very first thing I need to say is that we're going to scan to make sure the input is of the right form. And now, again, it's going to be making repeated passes over the input. But we're going to do it a little differently now. Instead of crossing off a single A and a single B, or some fixed number of A's and a fixed number of B's, we're going to cross off every other A and every other B. And in that way, we're going to essentially cut the number of A's and B's in half. And that's why the number of iterations is only going to be a log instead of linear. So we're going to cross off every other A and every other B. And at the same time, we're going to keep track of the parity, the even-odd parity, of the number of A's that we've seen and the parity of the number of B's that we've seen that have not yet been crossed off. And we're going to compare those parities to make sure that they agree. If they ever disagree, we know we started off with different numbers of A's and B's. And I'll illustrate this in a second just to make sure we understand this algorithm. So I'm going to write down as a little table of the parities that we've seen. And I'm going to illustrate the algorithm with a little animation. So again, we're now going to scan across, crossing off every other A and then every other B. But before we get to the B's, we observe, as we cross these off, that we had six A's. Now, I'm not saying we count them. We just keep track of the even-odd parity. That can be done in the finite control of the machine. Counting them would be more complicated. But just keeping track of the parity is something that the finite automaton could do. So the parity in this case, because they were six, is going to be even. Now we cross off the B's. Same, even parity. Now we're going to return the head back to the beginning. I'm obviously not showing the head moving here. We return the head back to the beginning. And now we scan across, again, crossing off every other remaining A and counting the parity of the remaining A's. So here now, it's going to be this one and this one are going to get crossed off. And there were three A's, so that was odd parity. And the same for the B's. Three B's, odd parity. And now we return our head back to the beginning, cross again off every other A and every other B. So that was odd parity. There was just one. Crossing off the B, odd parity because it's just one. They all agree, so the machine is going to accept because everything is now crossed off. And the parities agreed along the way. Let me just say for a second, obviously, if you ever get disagreement on the parities, then you know that the number of A's and number of B's had to disagree. But how do we know that if the parities always agree, that we actually did start out with the same number of A's as B's? And you could see that in a number of different ways. But perhaps a cute way to see it is there is actually, if you look at these parities here, the sequence of parities actually in reverse. So let's say odd, odd, even. And you look at the binary representation of the number of A's, which is 6. So the binary representation would be 1, 1, 0. The fact that you get odd, odd, even, and 1, 1, 0 is not a coincidence. In fact, the sequence of parities in reverse that you get is exactly the same as the binary representation. You'd have to confirm that with a little proof. It's not hard. But once you've confirmed that, you can see that if the sequence of parities agree, then the numbers have to be the same because the binary representations agreed. OK, so now getting to the analysis here, again, order n steps to do the check, log n iterations. Each scan takes order n steps. So the total running time here is going to be order n log n. Of course, it's going to be the log n times n. That's where the n log n comes from. Now, questions you might ask, could I do even better than that? Can I beat n log n by more than any constant factor? So can I do little o of n log n? And the answer is no. This is the best possible one-tape Turing machine for this language. So a one-tape Turing machine cannot decide A by using little o of n log n steps. We're not going to prove that. I'm not going to ask you to be responsible for the proof. But in fact, what you can show is that any language that you can do on a one-tape Turing machine in little o of n log n steps turns out to be regular. So you can prove a rather strong theorem here. Not super difficult to prove, but I don't want to spend a lot of time on proving bounds for Turing machines because really, the whole purpose of setting this up using Turing machines is to talk about algorithms in general. I'm not going to be focusing on the nitty gritty of Turing machines. OK, so what is my? OK, yeah, so I wanted to just stop and make sure that we are together here. So a brief pause, and feel free to send me any questions. OK, this is a good question. If we can keep track of parities, why can't we just keep track of the number of A's or B's? Well, you could keep track of the parity in the finite memory. And so you can do that with effectively no work. But the finite memory is not enough for doing a count up to some arbitrarily large number. Now, you could store the count on the tape, but that's going to cost you time to maintain that counter. And so that's not going to be so simple as keeping track of the parity in the finite memory. OK, somebody's asking if A star B star is regular. Yes, A star B star is regular. So what? But A to the k B to the k, which is our language, is not regular. That's the language we're looking at. OK, so getting questions about what happens with multiple tapes, we'll talk about that in a second. Yes, we could do an order n steps on a regular computer, sure. But for this slide, anyway, we're looking at one-tape Turing machines. OK, getting questions about big O and little o. For something to be little o means it's less than any constant factor times the function. So you have to look at the definition in the book. I think enough people in the class probably know this and have seen this already. I don't want to spend everybody's time on it. But please review it in the book. Somebody's asking if you need to store the parity on the tape. No, you can just store it in the finite memory. I mean, storing the finite memory seems to me the simplest thing. OK, why don't we move on. Please feel free to ask questions to the TAs as well. We have two TAs at least here attending with me. So good. Right. All right, so we cannot do better on a one-tape Turing machine than order n log n. And that's something we can prove, though we're not going to do it here. However, if you change the model, for example, use a two-tape Turing machine, then yes, as a lot of you are suggesting in the chat, you can do better than that. So if we now have a two-tape Turing machine or a multi-tape Turing machine, you can do it in order n steps. And that's actually the point I'm really trying to make here. So if you have here your two-tape Turing machine, then two tapes, same language. Now what we're going to do is copy the A's to the second tape. That we can do on a single pass. And then once the A's have been copied to the second tape, we can continue on reading the B's and match them off with the A's that appear on the second tape. So in order n steps, you can do the comparison instead of order n log n steps. And of course, if they match, you're going to accept, otherwise reject. So let's just see. Here's a little animation demonstrating that. Of course, it's very simple. So here is the hero that, if you could see that, it came maybe a little too fast. Here, let's just show it again. Here is the heads moving across, and the A's coming down to the bottom. And now the upper head is going to continue on reading the B's. The lower head is going to go back to the beginning on the A's and matching off the B's with the A's. And that's how we can verify or check that they are the same number. So now in this case, they were the same number, so the machine would accept. If they were a different number, the machine would not accept. And the analysis is very simple. So each stage here is going to take a linear number of steps, order n steps, because it just consists of a single scan. There are no loops in this machine, no repeat loops. OK, so question on this? Yeah. All right. Why don't we move on then? Now, observe, and the point I'm really trying to make is that on a one-tape Turing machine, you can do it in n log n, but not any better. But on a two-tape Turing machine, you can do it in order n. So there's a difference in how much time you need to spend, how many steps you need to spend, depending upon the model. And that's significant for us. So the number of steps depends on the model. One-tape Turing machine was order n log n. Multi-tape was order n. We call them model dependence. If you contrast that with the situation in the computability section of the course, we had model independence. The choice of the model didn't matter. And that was nice for us, because the theory of decidability didn't depend upon whether you had a one-tape Turing machine or a multi-tape Turing machine. It was all the same set of decidable and recognizable languages. So we didn't have to worry about which model we were actually going to work with. We could work with any model. Even just an informal model of algorithm would be good enough, because we're going to end up with the same notion in the end. Now, that goes away in complexity theory. Now we have a difference depending upon the model. And from a mathematical standpoint, that's a little less nice, because which model do you work with? If you want to understand the complexity of some problem that you have at hand, now you have to make a choice. Are you going to work with a Turing machine or how many tapes? Or are you going to look at some other model? And you're going to get different results. So it's somewhat less natural from a mathematical standpoint just to talk about the complexity of some problem. But we're going to kind of bring back something close enough to model independence by observing that even though we don't have model independence, as we did in computability theory, we can limit how much dependence there is. So the amount of dependence is going to be low, as we will see, provided you stick with a reasonable class of deterministic models. So the dependence, though it does exist, is not going to be that much. It's going to be polynomial dependence. And we'll say exactly what that means in a second. And from our standpoint, that's going to be a small difference, a negligible difference that we're going to ignore. So we're going to focus on questions that do not depend on the model choice among these reasonable deterministic models. Now, you may say, well, that's not interesting from a practical standpoint because polynomial differences, say, the difference between n squared and n cubed, certainly make a difference in practice. But it really depends on what kinds of questions you're focusing on. So if you want to look at something that's a very precise distinction, say, between n squared and n cubed, then you might want to focus in on which model you're going to be working with. And that's going to be more the domain of an algorithms class. But from our standpoint, we're going to be looking at other still important questions. But they are questions that don't depend upon exactly which polynomial you're going to have. We're going to be looking more at distinctions between polynomial and exponential. And still, there are important practical questions that arise in that somewhat different setting. So with that in mind, we're going to continue to use the one-tape Turing machine as our basic model of complexity. Since the model among the reasonable deterministic models in the end is not going to matter from the perspective of the kinds of questions we're going to be asking. So with that, we are going to continue then. It's important to remember that going forward, we're going to stick with the one-tape Turing machine model. Maybe that's something you would have expected us to do anyway, but I'm trying to justify that through this little discussion that we had thus far. So now we're going to start defining things. With the one-tape model in mind. So first of all, if you have a Turing machine, we're going to say it runs in a certain amount of time. So if T is some sort of time-bound function, like n squared or n log n, we'll say the machine runs in that amount of time, like n squared or n log n. If that machine M always halts within that number of steps on all inputs of length n. So it always halts within T of n steps on inputs of length n. Then we'll say that the machine runs in T of n time. So in other words, if the machine runs in n squared time, then the machine, when you give it an input of length 10, it's got to be guaranteed to halt within 100 steps. 10 squared, 100 steps on every input of length 10. That's what it means for the machine to be running in that much time. And it has to do that for every n, for every input length. And with that, we're going to come to the following definition, which is highlighted in color because we're going to be using this definition throughout the semester. So it's important to understand it. This is the definition of what's called the time complexity classes. And what I'm going to do is take some bound, T of n. And again, think of T of n like a bound like n squared. So if you have time T of n or time n squared, that's going to be the collection of all languages that you can decide within time n squared or within time T of n. So in other words, it's a collection of all languages B such that there's some one-tape Turing machine. Here, we're focusing, again, on the one-tape Turing machine. There is some deterministic one-tape Turing machine that decides B. And that machine runs in that amount of time. So this is a collection of languages. The time complexity class is a set of languages. I'm going to draw it now as a diagram. So if you take the language, again, that we've been using as our standard example, A to the k, B to the k, that's in time n log n, as we observed two slides back or three slides back. So on a one-tape Turing machine, you can do this language A in time n log n. So it's in the time complexity class n log n. This region here captures all of the languages that you can do in order n log n time. For example, that also includes all of the regular languages. Why is that? Well, any regular language can be done on a one-tape Turing machine in time order n. Because the Turing machine only just needs to scan across, doesn't even need to write, just needs to scan across from left to right on the tape. And in n steps, it has the answer. So all of the regular languages are actually in time n, certainly a subset of time n log n. And these all form a kind of a hierarchy. So if you increase the bound, you can imagine that the class of languages grows as you allow the machine to have more and more steps to do its computing. So these are all the languages that you can do in n squared, order n squared time on a one-tape Turing machine, n cubed time on a one-tape Turing machine, and so on, exponential time, 2 to the n time on a one-tape Turing machine. These are all collections of languages getting larger and larger as we increase the bound. OK, so someone is asking kind of a, OK, let's see. Let me get to some of these questions here. I'll try to get to them in order. Um, OK, so somebody says a good question. If you have a regular computer, so an ordinary sort of random access computer, so we'll talk about that in a second, can do it in order n? Can you do it on a multi-tape Turing machine also in order n time? Actually, I don't know the answer to that offhand. I suspect the answer is no. That ordinary computers have a random access capability that Turing machines do not. And so that there are going to be some examples of problems that you can do with a random, with a regular computer that you cannot do with a multi-tape Turing machine in order n time. I'd have to double check that, though. So we can. And so some question, what we believe is true and what we can prove to be true? As we'll see, there are a lot of things that we believe to be true in this subject that we don't know how to prove. Somebody is asking kind of an interesting sort of more advanced question. Is there some function f, some function t, where it's so big that that time t of n gives you all of the decidable problems? It would be a very big T. But the answer actually to that question is yes. But that's a little bit exotic. So let's not spend a lot of time on that right here. But happy to talk about that offline. It's a good question here. Somebody is asking me, does it mean that there are no languages between order n and order n log n? Because I pointed out that anything below n log n is going to be regular. And so as soon as you get below n log n, you can do an order n. And yes, there is what's called a gap between order n and order n log n on a one-tape Turing machine. You don't get anything new from order n until you jump up. So from order n to order n log log n, nothing new shows up. We'll talk about those kinds of things a little bit down the road when we look at actually the relationship among these various classes and what we call a hierarchy theorem, which shows how much bigger do you have to make the bound in order to be sure you'll get something new. All right. Somebody is asking, is there a model which has the same time complexity as a normal computer? Well, I mean, there's the random access model, which is supposed to capture a normal computer. So these are all great questions, kind of more riffing off of this into more advanced directions. Let's move on. Here's another check-in. Suppose we take, this is a little bit of a check to see how comfortable you are with the notions we've just presented and whether you can think about some of the arguments that we've made and apply them into a new language. So take the language WW reverse, strings followed by their, followed by themselves backwards. This language B, the even-length palindromes, if you will. What's the smallest bound that you need to be able to solve that language B? And I'll pose it as a question for you. So which time complexity class is that language B in? Is it time order n, order n log n, n squared, so on? What do you think? So we're about to come to the coffee break. So why don't we, I'll answer any questions that come up. I think we've got everybody answered. So I'm going to end the polling. Make sure you're in if you want to be in. So the correct answer is, in fact, order n squared. It would be hard for you, a reasonable guess here would be order n log n. I mean, you can come up with the same procedure that as the one we showed at the beginning, the order n squared procedure for A to the k, B to the k works for W, W reverse as well. You can just cross off, sweep back and forth, crossing off the symbol from W and going across to the other side, crossing off the symbol from W reverse. And that procedure will give you an n squared, an order n squared algorithm. You might imagine you can improve it to order n log n, but you cannot. You can prove that order n squared is the best possible. I'm a little unhappy that a lot of you came up with order n, frankly, because I already told you that order n is, these are just regular languages. Anything that you can do in less than little o of n log n is going to be regular. And we know that this language is not regular. So this was not a good answer. So please pay attention. And OK, so let us stop sharing. I will turn now to our break for five minutes. And I'm happy to try to take questions along the way as we're waiting for the time to end. So let's just see. Let me put this up here. OK, let me try to take some of your questions. So someone has asked me about quantum computers as reasonable models of comp. You may say a quantum computer is a reasonable model of computation, and that's fine. I would not say it's a reasonable model of deterministic computation. That's fine, I would not say it's a reasonable model of deterministic computation, at least from our standpoint. Let's not quibble about the words. I'm not including quantum computers in the collection of machines that I have in mind right now when I'm talking about the reasonable models of deterministic computation that we're going to be discussing. OK, let's see. OK, a bunch of people apparently are asking the TAs why all regular languages can be done in order n. So if you think about a DFA, which processes an input of length n with n steps, and a DFA is going to be a type of Turing machine that never writes on its tape, so if the DFA can do it in n steps, the Turing machine can do it in n steps. And so therefore, every regular language can be done in order n steps on a Turing machine. Not sure where the confusion is, so please message me if you're still not getting it. OK, somebody's saying, why are we using one-tape Turing machines instead of random access? Wouldn't it be better to use the random access machines? If you're trying to do algorithms, yes, that's a more reasonable model. We're trying to prove things about the computation. And from that standpoint, we want to use as simple of a model as possible. If you're trying to prove things using random access computers, it's possible to be very messy. So that's why we don't use random access machines to prove the kinds of things we're going to be proving about computation that are really the meat and potatoes of this course. So I mean, there's compelling reasons why you would want to use a simple model like a Turing machine, but not a powerful model like a random access computer. So somebody's asking me, does the class time order n log log n have any elements? Yes, it has all the regular languages, but nothing else. Order n log log n is only the regular languages. You have to go all the way up to n log n before you get something non-regular. Somebody's asking me, are we going to talk about how the random access model works? No. No. You know, there's beyond the scope of this course, outside of what we're going to be doing. We're going to talk about Turing machines. Not because we care so much about Turing machines, but I'm trying to prove things about computation. And the Turing machines are a convenient vehicle for doing that. OK, our candle has burned out. Why don't we return then to the next slide so everybody can come back. So this answers one of the questions I got on the chat is, what actually is the dependency between multi-tape Turing machines and one-tape Turing machines? Can we bound that in general? Yes, we can. We're going to show that converting a multi-tape Turing machine to a one-tape Turing machine can, at most, blow up the amount of time that's necessary by a squaring. No, I acknowledge it's a lot. But it still allows you, but it's still small compared with an exponential increase. And we're going to be focusing in this course on things like the difference between polynomial and exponential, not between the difference of, not the difference between n squared and n cubed. That's going to be less of an issue for us. So the way I'm showing this theorem is that if you have a multi-tape Turing machine that can do a language in a certain amount of time, then it's in the time complexity class of that time bound squared. And the way I'm just saying that is because this is the bound that's utilizing the one-tape model. So another way of saying that is converting multi-tape to one-tape squares the amount of time you need at most. So the way we're going to prove that is simply by going back and remembering the conversion that we already presented from multi-tape to one-tape and observe that, if we analyze that conversion, it just ends up squaring the amount of time that the multi-tape used. So why is that? So if you remember, let's just make sure we're all together on this. The way the single-tape machine S simulates the multi-tape Turing machine M is that it takes the contents of each of M's tapes up to the place where there's infinitely many blanks. Obviously, you don't store the infinite part. But the active portion of each of M's tapes, you're going to store them consecutively in separate blocks on S's tape, on S's only tape. And now every time M makes one move, S has to scan its entire tape to see what's under each of the heads and to do all the updating. So to simulate one-tape step of M's computation, S is going to use order T of n steps, where T of n is the total running time that M is going to use. So why does T of n steps coming up here? Well, that's because you have to measure how S is going to make a scan of, of course, its tape. How big can its tape be? Well, M, if it's trying to use as much tape as possible, can use at most T of n tape on each of it, T of n cells on each of its tapes. So altogether, there's just going to be some constant number of times T of n cells on S's tape. You see that? So each one of these is going to be at most T of n long. So this altogether is going to be order T of n long. Because what can M do? It can send its head out, say, the head on this tape here, moving as fast as possible to the right, using as much tape as it can. But it can only use T of n cells in T of n time. So this is going to be order T of n. So one step of M's computation is going to be T of n steps on S's computation. But M itself has T of n steps. So it's going to be T of n times T of n for the total number of steps that S is going to end up using. And that's where the squaring comes from. Similar results. I'm not going to do lots of simulations of one model by another. I think that you'll get the idea. And if you're interested, you can study those on your own. But you can convert multidimensional Turing machines to one-tape Turing machines, one-tape ordinary linear one-dimensional machines. And the bottom line is that among all of the reasonable models, they're all what are called polynomially related. If each can simulate the other, with at most a polynomial overhead. So if one of the machines can use this T of n time, the other machine that's simulating it would use T to the k of n time for some k. That's what it means for the two machines to be polynomially related. And all reasonable deterministic models are polynomially related. So as we've already seen, one-tape and multi-tape Turing machines are polynomially related because converting multi-tape to one-tape blows you up by at most a squaring, to k equals 2 in this case. Multidimensional Turing machines, again, polynomially related. The random access machine, which I'm not going to define, but it's the machine that you might imagine you would, I'm sure they must define in some form in the algorithms classes, polynomially related. Cellular automata, which are just arrays of finite automata that can communicate with each other similarly. All the reasonable deterministic models, again, classical models, I'm not talking about quantum computing, are polynomially related. So that justifies our choice in picking one of them as long as we're going to ask questions which don't depend upon the polynomial. So let's then talk about the class P. So the class P, this is an important definition for us. This is the collection of all languages that you can do in time n to the k for some k on a one-tape Turing machine. Or as I've written it over here, I don't know if this notation is unfamiliar to you, but this is like just a big sum. But here it's a big union symbol. It's union over all values of k of the time class n to the k. So this is time n, union time n squared, union time n cubed, union time n to the fourth, and so on. So we call these the polynomial time decidable languages. So we're going to be spending a certain amount of effort exploring this class P and other similar classes. Somebody's asking, why is it a union? I'm not sure how else you would write it. So if you have a proposal for a different way to write it, that's fine. But this is for all k. I don't know. If you only had a finite number of k's, you could just take the biggest one. But since it's for all k, you need to write it as a union. Now, I want to argue that the class P is an important class. And why has it had so much impact on the subject and in terms of applications as well? So one thing is that the class P is invariant for all reasonable deterministic models. What do I mean by that? So we have defined the class P in terms of these time classes here, which in turn are defined in terms of the one-tape model. So we have defined P by using one-tape Turing machines. Now, if we had defined P in terms of multi-tape Turing machines, we get exactly the same class because one-tape and multi-tape Turing machines are polynomially related to one another. And since we're taking the union over all polynomials, that polynomial difference is going to wash out. Similarly, we could define P using any of the other reasonable deterministic models, and we get exactly the same class. So in a sense, we get back the situation that we had in computability theory when the class of decidable languages didn't depend on the choice of model. Here, the class P does not matter depending upon the choice of reasonable deterministic model. And we also kind of, even in the case of computability theory, we have to stick with kind of reasonable models that cannot do an infinite amount of work in one step. So I'm not going to define what it means to be reasonable. That's, in a sense, an informal notion. But among all of those reasonable models, you're going to get the same class P. The other thing that makes P important is that P roughly corresponds to the problems that you can solve in some reasonable practical sense. Not exactly. Problems that require n to the 100th time, you could argue, cannot be solved in any reasonable sense. But if you think about it, for example, from the perspective of cryptography, cryptographic codes that people come up with are typically designed to require, or the hope is that they require an exponential amount of effort to crack. If someone found even an n to the 100th algorithm that would crack a code, people would feel that the code is not secure, even though n to the 100th is still large. So it's a rough kind of test, but it's still used as a kind of litmus test for practical solvability if you can solve it in polynomial time. You basically figured out how to avoid large searches if you can solve problems in polynomial time. We'll say more about that later. But what I want to bring out here is that we have combined here in the class P something that's mathematically nice, mathematically elegant, with something that's practically relevant. And when you have a combination of the two, then you know you have a winner. Then you know how you have a concept that's going to make a difference. And that's been true for the class P. This has been very influential within and without the theory of computation. So let's look at an example. Let's define a new language we haven't seen before, though it's similar to procedures that we've looked at before, the path language, which is where I'm going to give you a graph G, two nodes in the graph, s and t, where I'm thinking of G as a directed graph. So directed means that the connections between the nodes and G are going to be directed in that they have arrows on. And they're not just lines, but they have an orientation with an arrow. So G is a directed graph that has a path from s to t that respects the directions. So such a, I think I might even have a picture here. Yeah. So imagine here, here is your graph. If you can see it, there are little arrows connecting the nodes. And I want to know, is there a path from the node s to the node t? So that is a picture of a problem, an instance of a graph of a path problem. And I want to find an algorithm for that. And I can show that there is an algorithm that operates in polynomial time for this path problem. And the algorithm, any of the standard searching algorithms would work here. But let's just, for completeness sake, include the breadth-first search algorithm that we have explored previously when we talked about finite automata. So we'll mark s, and they'll keep repeating until nothing new is marked. And we'll mark all of the nodes that were reachable by a single arrow from a previously marked node. And then c of t is marked after you have marked everything you can get to. So you're going to mark, let's see, pictorially here, I think I have this indicated. Yeah, you're going to mark all of the things that are reachable from the node s. And then c, after you can't mark anything new, whether the node t is marked. And if it is, you'll accept. If it is not, you reject. Now, we can analyze this too. And I'm not going to be spending a lot of time analyzing algorithms here. But let's just do it kind of this one time again. And we're doing a bunch of iterations here. So we're going to be repeating until nothing new is marked. So each time we mark something new, we can only do that at most n times, at which point we've marked everything. So the number of iterations here is going to be at most n. And now, for each time we've marked something, we have to look at all of the previously marked nodes and see which things they point at to mark them too. So this is going to be an inner loop, which again has at most n iterations, because it's going through all of the previously marked nodes. And then once we have that, we can scan G to mark all of the nodes which we have not yet marked, whether they are connected with a previously marked node by an edge. And I'm being generous here, because I don't really care. This can be done in at most n squared steps on a one-take Turing machine. I'm not going to describe the implementation, but I'll leave it to you as an exercise. But this is straightforward. So the total number of steps here would be n iterations times n iterations times n squared. So you're going to be at most n to the fourth steps needed. So this is a polynomial algorithm. And whether I ended up with n to the fourth or n to the fifth or n cubed, I don't really care, because I'm just trying to illustrate that the total is polynomial. And that's all I'm going to be typically asking you to do. So to show polynomial time, what I'd be asking you to do is to show that each stage of this algorithm should be clearly polynomial, and that the total number of stages, I'm sorry, this should say stages here, should be polynomial. So each stage is polynomial. And after you're doing all the iterations, the total number of stages that are executed is polynomial. And so therefore, altogether, the total running time, the total number of steps is going to be polynomial. OK, so that's the way we would write up polynomial algorithms in this class. So let's see if there's any questions here. I don't want to get too far ahead of people. Let's see. Yes, in this theorem, I'm talking about one-tape Turing machines, because we're defining everything in terms of one-tape Turing machines. But now at this point, we're talking about polynomial time. My analysis is based on one-tape Turing machines. But in general, you could use any reasonable deterministic model on which to carry out your analysis, because they're all polynomially equivalent. So from the perspective of coming up with showing that a problem is in polynomial time, is in P, you can use any of the models that you wish for convenience. OK, well, that's a good question. What is n? Thank you for asking that question. n is always going to be reserved to indicate the length of the input. So here, n is going to be when we encode g, s, and t. And here also, I haven't said this, but I'm assuming that the encoding that you're using is also somehow reasonable. I think we'll talk a little bit more about that in the next lecture, which is going to be after the midterm. But you can cause problems if you intentionally try to come up with nasty encodings, which will represent things with unnecessarily many characters. But if you try to be reasonable, then just use any one of those encodings, and you'll be fine. So yeah, so n is the length of the representation of the input. Someone's trying to dig into the actual how this is running here. g to mark all y, where xy is an edge. I'm saying that you can do an n squared steps. If you have x, you can mark it in a certain place on the tape. And then as you're going through every other node, every other edge, you can go back and compare x with the x of the edge, and then find the y. It's just going to be too messy to talk about here. I'll leave it as an exercise to you. I'm not going to try to fumble my way through explaining why you can do this in n squared steps, but it's not hard. You guys are all hardcore algorithms folks. You want to know the algorithms for this. I'm not going to do that. Sorry. High level picture here. If you want to look at detailed analyses, this is not the right course for you. Can k equal n? What is k? No. If you're talking about this k here, k cannot equal n. We're not looking at n to the n. These are all fixed k. It's like n squared, n cubed, but not n to the n is going to be an exponential bound, and so that's not going to be included within this union. OK, so we're near the end of the hour. I'm going to introduce one last language here called hand path. And the hand path problem is I'm going to ask now again for a path from s to t, but now a different kind of path, one that goes through every node of g along the way. So I'm looking for a path that goes that hits every node of g, not just the shortest, most direct path, but in a sense, the most indirect path, the longest path that goes from s to t that visits everything else along the way. A path of that kind that hits every node of the graph is called the Hamiltonian path, because the mathematician Hamilton studied those and made some definitions about that. I'm not going to, I don't actually know the history there, but I just know they're called Hamiltonian paths. So here's a picture I want to get from s to t, but I want to sort of pick up everything else along the way. So as you remember, the path problem itself can be solved in P. And what I'd like to know, can the simple modification where I'm asking you to visit everything else along the way, is that problem also in P? And I'm going to pose this as a check-in for you. But actually, before I get to that, let me give you an algorithm for HamPath that doesn't work to show it's in P, because it's exponential. So here's an algorithm for HamPath where let's m be the number of nodes in G. And what I'm going to do is I'm going to try every possible path in G and see if it actually works as a Hamiltonian path, and accept if it is. And then if all paths fail, then I'll reject. So I'm going to try every possible routing through G. If you want to think about it, think of m as every possible permutation of the nodes of G. And then you're going to see whether that's actually constitutes a path in G that takes you from s to t and goes through all of the nodes. So this algorithm would work. This would give you a correct algorithm for the HamPath problem. The problem is, the difficulty is, that there are so many possible paths that it's going to take you an exponential number of steps to execute this algorithm. It's not a polynomial time algorithm, because there are many possible paths that you could go through. If you're looking at it with a very crude bound, but you really can't improve that significantly, there would be m factorial, which is going to be much greater than 2 to the m paths of length m. So the algorithm is going to run for exponential time and not polynomial time. So my question for you is, I'm going to pose it as a check-in problem, is whether you could actually do this problem in polynomial time. So I want you to think about that as I'm setting up the question. So take the HamPath problem, just like the path problem, which I described with that marking algorithm, but now you want to hit every node along the way. Can you show that problem is solvable in P? And there's a whole range of possibilities here, where either the answer is yes, you can see what the polynomial time algorithm is, to definitely know where you can prove there is no such polynomial time algorithm. And I'll put this as a check-in for you. And I'm curious to see what you come up with. Most people are getting it wrong. Well, I mean wrong, I'm not clear what wrong is here. OK, are we done? Please check something. I can see a few of you have not answered, but the poll is running out. OK, time is up. Hm, so in fact, as I think many of you know, but not all of you, this is an unsolved problem. This is a very famous unsolved problem, which is equivalent to the P versus NP problem that we're going to be talking about very soon, which, among other things, would be worth $1 million if you solve it. So for those of you who have answered A or E, please talk to me after lecture. And maybe we can work on it together. No, so yeah, I think most people would believe that the answer is no. But no one knows how to prove it at this time. So I'm interested in the folks who have come up with what they think are solutions. And I should say that there are some folks who believe that there might be other outcomes besides just a simple no, which might be proven eventually. So we're going to talk more about this. But this is the answer to the question, just to make sure you understand, is that it's an unsolved problem right now. So we don't know. Definitely yes and definitely no, at least according to the state of knowledge of which I'm aware, are not correct answers. But any of the others, well, who knows. So I think that's the end of what I had to say for today. We covered complexity theory as an introduction, looked at different possible models, focused on the one-tape model, introduced, based on the one-tape model, these complexity classes, the class P, and we showed an example of this path problem being in P, talked also about this hand-path problem, which we'll talk about more after the midterm. So I'll stick around for a few minutes if you have any further questions. Otherwise, OK, so let me just take questions here. Somebody is asking me about my personal opinion on P versus NP. My personal opinion on P versus NP is that P is not equal to NP and that we will prove it someday. When I was a graduate student back in the mid-'70s, I thought it would be solved by now. And in fact, I made a bet with Len Adleman, who I subsequently ended up becoming the A of the RSA code, that we would solve it by the year 2000. And I bet what was then a lot of money for me, which was an ounce of gold, which I did end up paying off to Len in the year 2000. So I'm not making any more bets, but I still believe that it will be solved. Hopefully, I'll get a chance to see the solution. I spent a lot of time thinking about it myself. But obviously, I haven't solved it. Otherwise, we would know. But hopefully, somebody will. I'm getting asked a question here that's kind of an interesting question, but I don't really know. I'm sure I understand it. What's the largest possible runtime of a decidable problem? What is the largest decidable runtime? So anything that I can describe can be, there are going to be algorithms that run for longer. You can define an algorithm. You can define a runtime, which would, in a sense, beats all other runtimes, so that any runtime is going to be dominated by that extremely slow runtime. But it's not something that one can describe. I can describe it to you by mathematical procedure, but it's not going to be something like 2 to the 2 to the n. Somebody's here proposing a solution to the hand-path problem, I presume in polynomial time. Why is the following flawed? If s goes through all nodes and ends up at t, well, s, we're not, I presume you mean starting at s if we end up going through all nodes and end at t. The proposal is a little complicated here. Basically, if I can try to rephrase it, you want to try to, from every possible node, you want to try to calculate a path to t and also a path from s to that node. And you can do that for all possible nodes, but there's no way to really combine them into a single path that visits all. Solving for each node separately is not going to do the trick, because you have to somehow combine all that information into a single path, just one path, that goes from s to t and visits all the other nodes along the way. And that is not, I don't see how what your proposal, how that's going to actually work. Professor Spitzer? Yes. A question on the, like we were kind of talking about earlier, but what we talked about today was defined for the one tape turn machines, correct? Yeah. So, and you said we could apply it for the multi tape ones, but are, like, is, well, I don't know if it's, we talked about earlier, if something is accepted by the one tape turn machine, like, can it be applied to the multi tape turn machine and vice versa? Like, are they interchangeable like that? Well, they're interchangeable only in the sense that the amount of time that you would need. It's a different machine. If you have a multi tape turning machine for some language, you can convert it to a one tape turning machine using a procedure that we described earlier in the term. And you'll get a different machine. It's going to run for a different amount of time. You're using that procedure. The point is that the amount of time that the one tape turning machine is going to run for is not that much worse than the multi tape turning machine's time. So if the multi tape turning machine's time was n cubed, the one tape turning machines is going to be the square of that. So it's going to be n to the sixth. But it's not going to be, it's not going from multi tape to one tape. It's not going to convert you from polynomial to exponential. That's the only point I'm trying to make. It's going to convert from one polynomial to a somewhat bigger polynomial. But it's still going to leave you polynomial. I don't know. I can't see your face. No, no, yeah. I guess my thing is that, especially when we were talking about earlier, when you were bringing it up, it just seemed like you could just turn anything to a multi tape turning machine and completely cut the time out. If I had something to n log n, if I do it in a multi tape turning machine, I have it in big O of n. You know what I mean? It just seemed like the multi tape was so much more powerful. But then I guess not with the explanations and the models we were talking about today. Yeah, I would not say the multi tape turning machines are still pretty limited in their capabilities. And don't forget, when you have a multi tape turning machine, you have only a fixed number of tapes. I mean, you can also define variations of multi tape turning machines that have increasing number of tapes as the input. Either under program control, it can launch new tapes. Or it could just have more tapes depending upon the size of the input. That would also be a possibility. That's not the model that we have defined. But you could define a model like that. But as long as the total amount of work being done by the machine at any step is going to be a polynomial amount of work, then you can convert it to a one tape turning machine with only a polynomial increase in the bound. So you want to be careful of machines. One thing I meant to say but didn't say, so here would be an unreasonable model, which you might think of as a plausible model. But it's not going to be a reasonable model from our standpoint. And that would be a model, for example, that can do full precision, say, integer arithmetic with a unit cost per operation. So each operation costs 1. But I'm going to allow you to do, for example, addition and multiplication. The thing that's bad about that in terms of being unreasonable is that after k step, each time you do a step, you could double the size of the integer by squaring it. After k steps, you could have an integer which is 2 to the k long. And now doing operations there is going to involve an exponential amount of work, even in any reasonable sense, in a theoretical sense and also in a practical sense. So a model that operates like that is not going to be able to convert to a one tape Turing machine with only a polynomial increase. Because it's doing an exponential amount of work, exponentially, within a polynomial number of steps. So that's within a linear number of steps, within n steps. So that's an example of an unreasonable deterministic model. Yeah. Thank you. Sure. So I'm just curious. Some idea just occurred to me. I guess if you had an Oracle Turing machine, basically just so that you could look at a Turing machine description, decide whether it's a decider or not, then it'd be a little bit interesting to think about what happens if you look at all, if you have a description of a pair of a Turing machine and an input string, and you can look at for all size n descriptions of a pair, what's the most steps that it takes for such a machine to converge? So then you'd have combined Turing machine and input string descriptions, where you could look at what's the longest it takes to converge. I don't know. Just a random thought that occurred. Yeah. So we actually, we will talk about Oracle Turing machines later on in the term. These are machines that have access to free information. And that actually turns out to be, there's some interesting things you can say about what happens when you're providing a machine with, in a sense, information for free. That you might otherwise want to charge it for actually computing that information. But let's just say we're going to allow it to get that information without being charged. And then how does that affect the complexity of other problems, for example? And so we will talk about that later. But too much of, I think, of a digression at this moment to try to define all that. But happy to chat with you about it on Piazza if you want to raise a question there. Sure. No problem. Somebody's asking me about strategies for solving the P versus NP problem. We will also talk about that a little later in the term as well. But clearly, it seems beyond the reach of our present techniques to be able to prove that some problems really take a long time. Like that Hamiltonian path problem. Seems like there's nothing really you can do that's significantly better than triangle possibilities, as I described in that exponential algorithm on the last slide. But how do you prove that? Nobody knows. So lots of people have tried, including yours truly. I mean, I've spent a lot of time thinking about it, haven't succeeded with it. But there is somebody, I think somebody, someday, someday, somebody will come up with the new idea that's needed to solve it. But it's going to clearly take some sort of a breakthrough, some sort of a new idea. It's not just going to be a combination of existing ideas, existing methods. I think we're about 10 minutes past. A few of you are still here. I'm going to say goodbye to you folks. And shortly, I'm going to join my TAs for our weekly TA meeting. So see you guys. Thanks for being here.