 OK, so let's continue our discussion of sequences of functions. So we had two different notions of convergence of sequences of functions. So the first notion was pointwise convergence. So we have a sequence of functions fn from some set s to r. Another fixed function f from s to r. And then we say fn converges to f pointwise if for every x in s, the sequence of real numbers converges to f of x. So if for all x in s, the limit as n goes to infinity of fn of x equals f of x. OK, so I take an x out of s, stick it into fn, so now I get a sequence of real numbers, and I should get f of x as n goes to infinity. And then we introduced the stronger notion of convergence of functions, which was the following. So we have a sequence going from s to r, function from s to r, then we said fn converges to f uniformly on s if somehow across the entire set, fn gets close to s. So here, this statement says if I take for each fixed x, eventually fn of x, so fn evaluated at that point, is close to f of x, f evaluated at that point. But uniform convergence says fn is close to f across the entire set. So if for all epsilon positive, there exists natural number m, so that for all n bigger than or equal to m, for all x in s, fn of x minus f of x is less than epsilon. OK, now if you write out what this means in terms of epsilon m's, remember this is a limit, so this is a limit of sequences, so this means something in terms of epsilons and m's. This would say for all x in s, for all epsilon positive, there exists an m, so on. So the x appears at the front of this definition, while here for uniform convergence, it appears at the end. That is not just a meaningless difference in the way you write the definition, meaning this is a stronger statement than if the x is appearing here. So what am I going on about? So first off, we proved last time that if I have a sequence of functions, again from some subset s to r, converging to f uniformly, then this implies fn converges to f pointwise. But now what I'm going to prove is that, in fact, uniform convergence is something stronger than pointwise convergence. In other words, this is a one-way street. Pointwise convergence does not imply uniform convergence. And we were just going to look at a very specific example, which I was going to state as a theorem, which is the following. fn of x be x to the n, and now we're looking on the unit interval 0, 1. And let f be a function that is 0 if x is in 0, 1, 1, if x equals 1. OK? So first off, let me, from last time, or you can even just check by looking at the form of fn, that fn converges to f pointwise. If I take x in this interval here, so not equal to 1, then x is strictly less than 1. And if I raise it to a high enough power over and over again, that's converging to 0. So it converges to f of x, 0. Now at 1, I just get 1, and that clearly converges to 1. So fn converges to f pointwise. And so the claim is that for all b between 0 and 1, fn converges to f. And I guess I could include 0, that would just be looking at one point, not very interesting. But fn converges to f uniformly. And the second is fn does not converge to f uniformly on the whole interval, however. OK? So maybe it's best to, again, draw this picture that you're supposed to think about when it comes to uniform convergence. So we have the limiting function fn, I mean f. And then we draw a little epsilon-sized collar around the function f. And then uniform convergence, so this is f, uniform convergence says that as long as I go far enough out, the graph of fn should be within this little epsilon collar. OK, so that fn is getting close to f uniformly across the entire set. OK? All right. So number two will give us a chance to negate this definition of uniform convergence, which, like I said, you should always. So we're actually doing two things here. We're giving an example of uniform convergence and also a sequence of functions which does not converge uniformly to this function. So we're doing both an example and non-example, which is the best thing to do for a new definition. So OK, so for the proof of one, let's prove uniform convergence. So let B be n 0, 1. Then the limit as n goes to infinity of B to the n is 0, which implies, OK, so now I'm getting ahead of myself. Write that yet. So now we want to prove uniform convergence of fn to f on, I didn't finish this statement, fn to f uniformly on, sorry about that, B. So I have uniform convergence on any smaller interval other than 0, 1. OK? So sorry about that if that looked a little weird. OK, so then Bn converges to 0 as n goes to infinity. And now we want to prove that fn converges to f uniformly on this interval 0, B. So let epsilon be positive. We now have to find an m so that fn is close to 0 because f is 0 on such an interval. Now since B to the n converges to 0, there exists a natural number m such that for all n bigger than or equal to m, B to the n is less than epsilon. Then for all n bigger than or equal to m, we get, and also for all x, 0, B, we get that fn of x minus f of x. So B is less than 1. So when I stick it into f, I just get 0. This is equal to x to the n minus 0. And absolute value is just x to the n because we're looking at non-negative x. And now x is in this interval 0, B, so it's less than or equal to B. So x to the n is going to be less than or equal to B to the n. And this is less than epsilon. So just as when we looked at uniform continuity of a function, it was a statement like for all epsilon there exists a delta, which just depends on basically the epsilon in the function. Now for uniform convergence, it looks kind of like pointwise convergence, except now for every epsilon you can find an m, which does not depend on the point x. So for every epsilon, you can find an m depending only on epsilon and maybe the function little f. But that doesn't depend on x. This n here that I chose, m, depended only on B, not the point x, which I have to stick into this here. OK, so now let's prove number two. So first off, let's negate the definition so that we know what we're talking about. So Fn does not converge to F uniformly on the set S if there exists a bad. So every for all becomes a there exists. So if there exists some bad epsilon 0 positive, so that for all m natural number, there exists an n bigger than or equal to m, and there exists an x in S, so that Fn of x minus F of x is bigger than or equal to epsilon 0. So this is the negation, but why should we not be surprised that Fn does not converge to F uniformly on 0, 1, if you believe this picture? So let's look at what's going on here. So let me draw now the graph of F. And let's say I take epsilon to be, I don't know, a fourth, say. So OK, now this is what my little epsilon neighborhood of F looks like, or epsilon 2 is. It's right along, or for epsilon equals a fourth, say. It's a tube around 0 up to x equals 1, and then it's a little area around 1. And now if I were to have uniform convergence, then as long as n is very large, Fn has to be within this area that I have here. So in fact, let me shade it in. So for Fn large, it has to be within this region that I'm coloring in. But now what do we know about x to the n? Well, it starts at 0 and ends at 1, and looks something like that, which means here, always, it leaves this epsilon tube around F, this epsilon collar, I guess. Fn leaves the shaded area, which is where it's supposed to stay. So I hope this intuitive explanation is clear, and why it shouldn't be too big of a surprise that Fn does not converge to F uniformly on 0 or 1. We'll see another reason in a little bit why it's impossible for Fn to converge to F uniformly when we talk about the interchange of limits. But just using the definition, we can prove that Fn does not converge to F uniformly. So the negation is that there exists a bad epsilon 0, so that we have all of this. So the point is to choose epsilon so that this never intersects with this epsilon neighborhood of the function down here, never intersects with this epsilon neighborhood of just the point x equals 1, y equals 1. So let's choose epsilon 0 to be 1. So now we have to prove for all n there exists an n, so let m be a natural number. So choose n to be m, and choose x to be, let's say, 1 over 4 to the 1 over m. Now, this is a number less than 1, so its mth root is less than 1, and also positive. Then this F of x equals 0, and F sub m of this x, which is just 1 over 4 to the 1 over m, now raised to the mth power, is 1 over 4, which implies that F of m of x minus F of x is equal 1 over 4, which equals epsilon 0. I guess if you like, you can write bigger than or equal to epsilon 0. OK? So basically, if you choose any n, so there was nothing special about epsilon 0 being 1 4th. You choose anything less than 1, that would do. You can check that. If I chose 1 half here, I could then choose this point x, where Fm is far away from F of x to be 1 over 1 half to the 1 over m, just as long as I don't choose epsilon 0 to be equal to 1. OK? So we have that example. And we had another sequence of functions we had looked at last time, which were these functions that look like little, that look like tenths. I don't know why I'm making this axis bigger when it should be the other one. So there's 1, 1 over n, 1 over 2n, and then way up here at 2n. So at this point, and then it's piecewise linear. So then it's just a straight line down to here. I'm not going to write down exactly the equation for each piece, but and then 0 to 1. So this is Fn. And we proved that, so last time we proved that Fn converges to the function 0 pointwise. But it does not converge uniformly to 0. Again, so what's the point? The point here is that if I were to draw a little epsilon collar around the function 0, it would look something like this. And Fn would have to be within this little strip for all n sufficiently large. But Fn is getting taller and taller, so it always leaves kind of any strip that I put around the function 0. So Fn does not converge to 0 uniformly. We can make a proof out of that, though. So Fn does not converge to 0 uniformly. So I should always tell you where I'm talking about, and this should be on 0, 1. So why not? Well, we can take any epsilon 0, really. So let's choose epsilon 0 to be 1. Let m be a natural number. So we should find n and x so that this inequality is satisfied. So let's choose n to be m, x to be 1 over 2m, this point where I peak. Then F of m of x minus F of x. Now, F here is just 0. The limiting function is 0. So let me not even put F. Let me put just 0. This equals Fm of 1 over 2m, which equals 2m. And this is certainly bigger than or equal to 1, which is epsilon 0. OK? OK. Now, and in a little bit, I'll give you a whole host of examples. It seems like I've only given you maybe one example up to this point of functions which converge uniformly to something. But in a minute, I'll give you a very useful test to decide when a series involving functions converges uniformly. But before we get to that, let's revisit these three questions that we asked in the last lecture in the context of power series, but now in this more general setting of convergence of functions. So now what I'm talking about, and this is really, although what I'm about to say may sound a bit alarming, that we're now in essentially the last week of the class, and we're really getting to the first real part of analysis. So I was talking with a professor from Duke one time, and he made this funny observation that somehow in math, and I think this is not just math, but this is a lot of science-based classes, are taught, if you were to translate it into studying a book, it's like you spend a year studying introductions to a book, and then you spend a year studying middle parts of books, and then you spend another year studying the last parts of books. So now here, we're starting to get into the middle part of the book of analysis, not the textbook. We're at the end of that, but at least in the grand scheme of things, which is the interchange of limits. You have two limiting processes that you want to interchange. OK? In analysis, first, God created the limit, and then man asked, can we interchange limits? And so what do I mean by that? This is not always a thing you can do. So, and this is at the very heart of analysis, what is when can we interchange limits? So let me give you the simplest example. Let's say we have the following limit. So I take the limit as k goes to infinity of the limit as n goes to infinity of n over k, n over k plus 1. So that's just a sequence depending on n and k. All right? Now, as n goes to infinity, what do I get? This is just equal to, well, I can multiply the bottom by k to get rid of this one, so then I just get n over n plus k. Remember, k is fixed. And then I take the limit as n goes to infinity, so I get 1. So I'm taking the limit as k goes to infinity of this expression. Now, for each k, when I take the limit as n goes to infinity, I get 1. So I get 1 there. Now, what happens if I interchange the limit? And now look at the limit as n goes to infinity of the limit as k goes to infinity of n over k, n over k plus 1. Well, now, as k goes to infinity for each n, so remember, I'm taking the limit as n goes to infinity of this expression, which is formally this expression with the limits interchanged. This is equal to 0 over 0 plus 1 equals 0. And these two do not equal each other. So it's not always the case that you can interchange limits. OK? That's the simple fact of life. And to be able to make certain statements, do certain computations, you need to be able to interchange limits. And what kind of limits? Maybe taking an infinite sum and integrating, or like we stated in the beginning, power series are, in a sense, a certain limit. They're a limit of partial sums. They're a limit of polynomials. And then let's say differentiation, that's a limit. So if a natural question, like we said last time, is, is the derivative of this infinite sum the infinite sum of the derivative? Those are two limiting processes, which we're asking, can we interchange? So the three questions, again, that I asked in terms of power series, I'm going to now frame again in this general setting. So if Fn from S to R, F from S to R, and Fn converges to F, maybe point-wise or uniformly. So let's leave this open-ended for now, because these are the only two notions we have of convergence. And let me make, so suppose Fn is from S to R, F is S to R, and Fn converges to F point-wise or uniformly. And so this sentence is not written very well. And Fn is continuous for all n, then is F continuous. So suppose we have a sequence of continuous functions converging to another function F, either point-wise or uniformly. Is the limiting function continuous? And I'll explain in a minute why this is a limiting, kind of asking can we interchange two limits. Second question is, suppose Fn from AB to R is differentiable for all n, F from AB to R, and we have that Fn converges to F, either point-wise or uniform. We're leaving this open-ended for now. And the derivatives also converge, say to some function g, then is F differentiable? And is the limit of the derivatives equal to the derivative of the limit? And then the last question, so this is the third kind of main limiting process we've seen in this class, which is integration. Suppose Fn is a sequence of continuous functions, F is a continuous function, and Fn converges to F, again, maybe either point-wise or uniformly. We're leaving this open-ended for now. Does the limit of the integrals equal the integral of the limit? OK? Now, again, I want you to, it's really, I guess, more clear here, the fact that we're asking about interchanging two limits. So here we have this integration is just a symbol for taking this limiting process, where you take a sequence of partitions of AB with norm converging to 0, then the integral from A to B of Fn, this is defined to be this limit of Riemann sums. So this is a limiting process here, although I'm writing it with this simple notation. So I'm asking it, can I take this limit as n goes to infinity, and can I interchange it with this limiting process? Now, for continuity, it's kind of maybe a little more hidden on what's the interchange of limits that you're really looking at. So it looks more like this. So remember, so for one, we're asking, suppose x is in set S, xn is a sequence converging to x, then basically, can we do this? Now, I would like to show that f of x is equal to the limit as n goes to infinity of f of x of n. So let me actually make this an m. I'm going to use two different. Let's use a k. So if I compute limit as k goes to infinity of f of x of k, I would like to show that equals f of x if I'm trying to show that the limit is continuous, assuming the functions that are converging to f are continuous. If I look at the limit as k goes to infinity, then I'm tempted to do the following, that this is equal to the limit as k goes to infinity of the limit as n goes to infinity of fn of x, assuming either pointwise convergence or uniform convergence, xk. And now, if I'm just being a little bit careless, I interchange limits and write this as the limit as n goes to infinity of the limit as k goes to infinity. So here is kind of where I'm asking, can I interchange limits? Again, this is not a proof. This is discussion on what is the interchange of limits that I'm looking at for question number one. Question number three is more clear. And then for this, once I've done this, differentiability will be a little bit clear on what is the interchange of limits I'm looking at. So let's say I was just doing whatever I like and going through this, then I would interchange these limits. And since each of these fn's are continuous, then the limit as k goes to infinity of fn of x sub k, and x sub k converges to x, this just gives me fn of x. And since fn, again, converges to f in some sense, this should give me f of x. So what I'm asking is, was all this OK? Because at some point, at this point in particular, I had to interchange a limit. And we've just seen that we can't always do that. We can't always interchange limits and get the same thing. Here, we got 1. When we interchange the limit, we got 0. So it's not always the case that I can interchange limits. This equality between this limit and the interchange limit is the big question mark. So that's the whole basis for question number one. OK, so I hope that discussion was clear enough. Now, the answer to these three questions is, in fact, yes. But only for uniform convergence. If the convergence, and this is the mode of convergence we must have so that the answer to all of these three questions, which is we'll state and prove as theorems, are correct. Now, the natural question is, what if we have a weaker hypothesis? Namely, what if we only assume pointwise convergence? Is the answer to any of these questions yes? And well, no. So the answer to all three of these questions is no if we only assume pointwise convergence. So let's go through an example showing that each of these three questions is no if we only assume pointwise convergence. So let's look at an example showing one is no if we only assume pointwise convergence. And we basically already have it on the board. Take fn of x to be x to the n on 0, 1. x is n. n, then each of these functions, so and for all n, fn is a continuous function on 0, 1. fn converges to f pointwise. But f itself is not a continuous function. So this provides an example of a sequence of functions which converges pointwise to a function which is not continuous. Again, what I was saying there in the answer is that if I have a sequence of functions which converges uniformly to a function f, then that function is continuous. Here, if we only assume pointwise convergence, we may not get a continuous function in the end. And this is what this example shows. fn of x equals x to the n. These are all continuous functions. They converge to a function which is not continuous pointwise. OK, I'll say something else in a minute. So let's look at example two now. Basically, we take the previous example and kind of integrate it to get an example of a sequence of functions that converges and its derivative converges pointwise. So for two, take fn of x to be x to the n over n on 0, 1. Then a couple of things. fn converges to 0. fn prime converges to the function f, which is the same function from here. So let me actually make this g. And these are pointwise. So I have a sequence of differentiable functions that converge pointwise to something, and the derivatives also converge pointwise to something. And so let's call f equals 0, but g is not equal to f prime. The derivative of f, the constant function 0, is just 0. g is equal to this function, which is 0 if x is n 0, 1, and 1 if x is equal to 1. So here we see that the derivative of the limit is not the limit of the derivatives, if we only assume pointwise convergence of the functions. Now, the last example showing that 3 does not hold if we only assume pointwise convergence is also on the board. It's the whole point of this one up there. So let's go on the next board. So here, fn from 0 to 1 to r is the function, this 10th function, 1 over n, 1 over 2n, 2n. It's just piecewise linear, so it's 0 from 1 over n to 1. And it goes up to 1 over 2n, 2n, and then back down to the origin. And so we know that fn converges to 0 pointwise. Now, the integral of 0 is just 0. Let's look at the integral of fn from 0 to 1. The integral of 0, 1 of fn. Now, if we were all together, this would be the point where I stop and ask if anybody can remember the area of a triangle, even though we're in this advanced analysis class. But I don't get to ask you that. I get to just ask myself that, and I know the answer. Because I prepared, and only because of that. This is 1 half base times the height. So remember, the integral is an area. And I could write down the formula of what this function is and actually integrate it out using the fundamental theorem of calculus, but just go with me on this, that the integral of fn is just the area of this triangle that has base starting at 0 and going to 1 over n, and it peaks at 2n. So the base is 1 over n. The height is 2n. So this equals 1 for all n. See, this is why I was making it peak. So the integral from 0 to 1, which is just 1 for all n, does not converge to the integral of the limit. So in this case, the limit of the integrals is not the integral of the limit. And what's the reason? Because we only have pointwise convergence. Like I said a minute ago, the answer is yes to all three of these questions if the convergence is uniform. And what these three examples are supposed to show you is the answer is no if I only assume pointwise convergence, the weaker notion of convergence. OK, so let's now prove some theorems. So this first theorem addresses question one. Let's suppose fn from s to r. f from s to r, fn is continuous, meaning it's continuous at every point in s for all n. And fn converges to f uniformly on s. Then the conclusion is that f is continuous. All right, so the proof. I mean, we've done several proofs like this before. But for some reason, at least I see in textbooks, for this proof, they always refer to it as an epsilon over 3 argument. And then it's the last time they call it an epsilon over 3 argument. So we have to show f is continuous at every point in s. So let c be a point in s. Let epsilon be positive. We have to find a delta so that for all x minus c less than delta, an absolute value f of x minus f of c is less than epsilon. And what we're going to do is we're basically going to replace f by some fm for m large enough. And the fact that we have uniform convergence is what allows us to do that. So let epsilon be positive. Since the fn's converge to f uniformly, there exists a natural number m so that for all n bigger than or equal to m, for all y and s, fm of y minus f of y is less than epsilon over 3. Now this f sub capital M, I'm just going to fix that. So it should be n. So this is for all n bigger than or equal to capital M. I really just need one, so let's look at f sub capital M. That's a continuous function. Since f sub capital M is continuous, there exists a delta positive so that for all x minus, if x is within distance delta to c, then I get that f sub M of x minus f sub M of c is less than epsilon over 3. So then this delta here, so I have been, OK, so I'm doing something what, you know, I stopped doing something which I was doing in all previous lectures when I would say there exists a delta 0, choose delta to be this delta 0. There exists a M0, choose M to be this M0. Now, you know, I'm actually saying I've dropped that and stopped doing that because it should be clear from the context now what I'm choosing delta to be. So then for all x minus c less than delta, so I'm saying that I'm now choosing this delta that came from here, which came from f sub capital M. Capital M came from this, what I needed here. So now if I look at f of x minus f of c, which I want to show is less than epsilon. Now, if I add and subtract f sub M of x and f sub M of c and use the triangle inequality, this is less than or equal to f of x minus f sub M of x plus f sub M of x minus f sub M of c plus f sub M of c minus f of c. So I just added and subtracted f sub M of x and f of M of c and then used the triangle inequality. Now, by this estimate here, since I'm looking at a particular n basically equal to M, I have this is less than epsilon over 3, no matter what y is in this set. So then certainly for x, I'll have this is less than epsilon over 3. How I chose delta, remember, was to guarantee that this would be less than epsilon over 3, as long as x minus c is less than delta. And then of course, this one is less than epsilon over 3 again, because of this uniform closeness of fM to f. And therefore, for all absolute value of x minus c less than delta, I have f of x minus f of c is less than epsilon. And that finishes the proof. So if we have uniform convergence, then the uniform, so a good theorem should be able to be stated in one sentence. And with this, or at least some sort of simple to an easy way to remember it, what this says is the uniform limit of continuous functions is continuous. So the uniform limit of continuous functions is continuous. Next we'll show, in a sense, the uniform limit of differentiable functions is continuous. And we're going to do kind of the simplest statement of that, although one can make stronger statements. But in practice, this one suffices, really, at least where it pops up later in life. But before I get to that one, let's do 3, which is, let's see, what would be the short way of saying that? The integral of the uniform limit is the limit of the integrals. Something like that. That would be the short and sweet way of stating the following theorem, which is, so this is the answer to 3, so we skipped over 2 for a minute. Suppose fn is a sequence of continuous functions on a, b, because we're going to be talking about limits, I mean, integrals, and we've only spoken about integrals for continuous functions. Suppose fn is a continuous function on a, b, f from a, b to r, and fn converges to f uniformly. Note that that's, so by what we've just proven, the previous theorem, this automatically guarantees that f is a continuous function. So we can ask about the relationship between the integral of f and the limit of the integrals of fn. Then the limit as n goes to infinity, integral from a to b of fn equals the integral from a, b to f. So the integral of the uniform limit is the limit of the integrals. So this is just a sequence of numbers, and we want to show it converges to this number here. So let's do this the old-fashioned way. Let epsilon be positive. Since fn converges to f uniformly, there exists a natural number m such that for all n bigger than or equal to m, for all x in a, b, fn of x minus f of x is less than epsilon. Now basically what we're going to do is integrate this inequality. Remember integration, unlike differentiation, integration respects inequalities. And for all n bigger than or equal to m, meaning I'm choosing my m as this guy for proving this limit, if I look at the integral from a, b of fn minus the integral of a, b to f, this is by linearity of the integral, the integral of fn minus f, absolute value, by the triangle inequality for integrals, which we proved. This is less than or equal to the integral from a, b of fn minus f. And what do we know? For all n bigger than or equal to m, this function here, fn of x minus f of x, an absolute value, is bounded by epsilon. And therefore, the integral of this side is going to be less than the integral of the right side. So I did this wrong. Let's put a b minus a over this. So this is less than integral a, b epsilon over b minus a. And so then I just pick up this number times the length of the interval, which equals epsilon. So for all n bigger than or equal to m, the absolute value of this integral of f sub n minus the integral of f is less than epsilon. So the integral of the uniform limit is the limit of the integrals. So now we'll use this to do the last interchange of limits theorem that I had in mind, so number two. And again, this is kind of the simplest statement, and maybe easiest to prove, that one can make. One can make stronger statements and prove them, but in most cases this suffices. So suppose fn a, b to r. So this is continuously differentiable for all n. f and g, these are two functions from a, b to r. And fn converges to f uniformly on a, b. And the derivatives converge uniformly to this function g. And in fact, I don't even need this. I could just say pointwise. So I only need uniform convergence of the derivatives if I'm assuming everything is continuously differentiable, if I'm assuming the sequences are continuously differentiable. Then f is differentiable, in fact, continuously differentiable, meaning the derivative is continuous, and the derivative of f is equal to g, meaning that the uniform limit of the derivatives converges to the derivative of f. So again, what this says is the uniform limit of, or at least in essence, in spirit, is not exactly what it says, but it says the uniform limit of continuously differentiable functions is differentiable. And that the derivative of the uniform limit is the limit of, so the derivative of the uniform limit is the uniform limit of the derivatives. So to prove this, we use the fundamental theorem of calculus. So let x be a point in AB. And by the fundamental theorem of calculus, if I want fn of x, if I take fn of x minus fn of a, this is equal to the integral from a to x of fn prime. The integral of the derivative gives me back the function evaluated at the endpoints. And therefore, since I know pointwise convergence, these two numbers converge pointwise to f of x and f of a, respectively. So f of x minus f of a equals the limit as n goes to infinity of fn of x minus fn of a. And this is equal to, just by the previous expression, limit as n goes to infinity of the integral from a to x of f prime. Now, fn prime, sorry. Now, these fn primes are converging to g, this function g uniformly. And therefore, the integrals converge. That's what we just proved. So this equals the integral of the limit. And therefore, so we started off with f of x minus f of a. And we showed it's equal to the integral from a to x of g. So f of x equals f of a plus the integral from a to x of g. But now again, by the fundamental theorem of calculus, this implies that f is differentiable. And the derivative of f of x, the derivative of f is equal to the derivative. So remember, f of a, that's just the constant equals the derivative of this function, which is g. I think we have just enough time to prove one more pretty good theorem. Pretty good. It's very good. And then we'll use it in our next lecture to discuss, or at least conclude some answers that we originally asked about power series. So this theorem is due to the godfather Weierstrass. I don't know, did I refer to him as a godfather or Riemann as a godfather? Anyways, I think it was Weierstrass that I referred to as a godfather. To prove the following theorem, when can you guarantee uniform convergence for at least series of functions, which are limits of partial sums, so limits of functions. And he proved this basically so he could come up with a whole host of examples of continuous functions which are nowhere differentiable. We kind of gave a proof of this theorem when we looked at that example when we were talking about differentiability, but we didn't state it as a theorem there. So let's take a sequence of functions fj from s to r. And suppose there exists a sequence mj such that two things hold. So these are a sequence of positive numbers. So we have a sequence of functions from s to r and a sequence of positive numbers so that these numbers dominate the fj's, and two, they're summable. So sum from j equals 1 to infinity is convergent. Then the conclusion, and since I've been using numbers for conclusions and letters for hypotheses, let's go back to that. Then we have two conclusions. The first one is pretty obvious for all x and s. This series, where I just take x and stick it into f sub j, this converges absolutely. And the second is, if I define now the function to be the sum of these series, then the partial sums converge to f uniformly, as n goes to infinity on s. So if I have a sequence of functions, each one bounded by some number m sub j, positive number, or non-negative number at least, and the series involving the m sub j's is convergent, then the series of the f sub j's converges uniformly. That's the conclusion. So in our example of that continuous nowhere differentiable functions, each of these f sub j's were cosine of 160jx over 4 to the j. So before we prove this theorem, we can combine all of what we've done so far to state the following, the function f of x equals sum from j equals 1 to infinity. And I can make it something else, but let's say sine of 40k over 2 to the k x is continuous on, let's say, 0, 1 for now. Or I could say on r. Why is that? Each of these f sub, and I'm really butchering this, trying to go fast. Each of these functions, this is 2 to the j, not 2. Each of these functions is bounded by 1 over 2 to the j, and 1 over 2 to the j is summable. So then by this theorem, this convergence, so this function here, is the uniform limit of the partial sums. The partial sums are just a finite sum involving sine, so they're continuous functions. So f is the uniform limit of continuous functions and is therefore continuous. So we could have used this theorem to prove that that function we looked at back in differentiability was continuous, but we didn't have uniform convergence and all that back then. So we just proved it by hand. But using this, so this theorem gives you a big class of sequences of functions which converge uniformly to some function. So 1, all right, so let's prove this quickly. So 1 follows from, what does it follow? It follows from the assumption A, B, and the comparison test. If I take an x and s, f sub j of x is bounded by m sub j, and m sub j is summable, this series converges. So by the comparison test, the sum with absolute values here for each fixed x converges. And that's absolute convergence. Now let's show that the partial sums converge to the limit uniformly. OK. So let epsilon be positive. Since this sum converges, there exists an m natural number. So that, remember we have this Cauchy criterion for, well I guess we don't have to have, so that what? Sum from n equals m plus 1 to infinity of m sub j, so j, which is equal to, I chose a poor letter, so this m here should not, let's change this to an n. So this is less than epsilon. So the point is that the tail is small. The sum from j equals n plus 1 to infinity of m sub j is less than epsilon. And for all n bigger than or equal to this capital N, for all x and s, if I look at the limit, which is f of x, this sum of the series minus sum from j equals 1 to n, this is equal to, now f of x is equal to the whole sum, so minus this first part, this is equal to sum from j equals n plus 1 to infinity of f sub j of x. And by the triangle inequality, which does hold for convergent series, this is less than or equal to sum from j equals n plus 1 to infinity of f sub j of x. And by assumption A, this is less than or equal to sum from j equals n plus 1 to infinity of m sub j. And since n is bigger than or equal to capital N, I have this is less than or equal to sum from j equals capital N plus 1 to infinity of m sub j. And this thing, we chose capital N so that that's less than epsilon. And that's the end. So we chose, again, this n was chosen depending only on this series. It didn't depend on any x at any, you know, it didn't depend on the point x and s. So I had to go through that kind of quickly because I'm up against a time crunch. But the point is for this theorem is that if I have a sequence of functions that are bounded by these numbers m sub j, so this is, I was going so fast I didn't even label it correctly. This is called the Beierstrass m test, m because you see m here. If I have a sequence of functions bounded by some numbers m sub j and those m sub j's are summable, then what it says is that the series of the functions converges uniformly. All right, so we'll stop there.