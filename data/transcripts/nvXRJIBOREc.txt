 The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. Well, OK. I'm happy to be back. And I'm really happy about the project proposals that are coming in. This is like, OK, this is really a good part of the course. And so keep them coming. And I'm happy to give whatever feedback I can on those proposals. And do make a start. They're really good. And if some are completed before the end of the semester and we can offer you a chance to report on them, that's good too. So well done with those proposals. So today, I'm jumping to part six. So part six and part seven are optimization, which is the fundamental algorithm that goes into deep learning. So we've got to start with optimization. Everybody has to get that picture. And then part seven will be the structure of CNNs, convolutional neural nets, and all kinds of applications. And so can we start with optimization? So first, could I get the basic facts about three terms of a Taylor series? So that's typical. It's seldom that we would go up to third derivatives in optimization. So that's the most useful approximation to a function. Everybody recognizes it? Here, I'm thinking of f as just one function and x as just one variable. But now I really want to go to more variables. So what do I have to change if f is a function of more variables? So now I'm thinking of x as, well, no, let me see. Yeah, I want n variables here. x is x1 up to xn. So just to get the words straight so we can begin on optimization, so what will be the similar step? So the function f at x, remember, x is n variables. Now what do I have? Delta x. So what's the point about delta x now? It's a vector, delta x1 to delta xn. And what about the derivative of f? It's a vector, too, the derivative of f with respect to x1, the derivative of f with respect to x2, and so on. So what do I have to change about that? And now those guys are vectors, so it's their dot product. So it's delta x transpose, that vector times this df dx. So now I'm replacing this by all the derivatives. And it's the gradient. So the gradient of f at x is the derivatives. Let's see. It's essential to get the notation straight here. So it'll be the partial derivatives of the function f. So grad f is the partial derivatives of f with respect to x1 down to partial derivative with respect to xn. OK, good. That's the linear term. And now what's the quadratic term? 1 half. Now delta x isn't a scalar anymore. It's a vector. So I'm going to have delta x transpose and a delta x. And what goes in between is the second derivatives. But I've got a function of n variables. And so what does this mean? So now I have a matrix of second derivatives, right? And I'll call it H. This is the matrix of second derivatives. Hjk is the second derivative of f with respect to xj and xk. And what's the name for this guy? The Hessian matrix. How the Hessians got into this picture, I don't know. The only Hessians I know are the ones who fought in the Revolutionary War for somebody. Which side were they on? I think maybe the wrong side. The French were on our side. And anyway, Hessian matrix. And what are the facts about that matrix? Well, the first fact is that it's symmetric. And the key fact is it's symmetric. OK. And again, it's an approximation. And everybody recognizes that if n is very large and we have a function of many variables, then we had n derivatives to compute here. And about half n squared derivatives using the half comes from the symmetry. But the key point is the n squared derivatives to compute there. So computing the gradient is feasible if n is small or moderately large. Actually, by using automatic differentiation, the key idea of back propagation, back prop, you can speed up the computation of derivatives quite amazingly. But still, for the size of deep learning problems, that's out of reach. OK. So that's the picture. And then I will want to use this to solve equations. There is a parallel picture for a vector, f. So now this is a vector function. This is f1 of x up to fn of x. And x is x1 to xn. So I have n functions of n variables. n functions of n variables. Well, that's exactly what I have in the gradient. Think of these two as parallel, the parallel being f corresponds to the gradient of f. n functions of n variables. OK. OK. Now maybe what I'm after here is to solve f equals 0. So I'm going to think about the f at x plus delta x. So it starts with f of x. And then we have the correction times the matrix of first derivatives. And what's the name for that matrix of first derivatives? Well, if I'm just given n functions, and I, yeah, what am I after here? I'm looking for the Jacobian. So here will go the Jacobian, J. This is the Jacobian named after Jacobi, Jacobian matrix. And what are its entries? The JK entry is the derivative of the J function with respect to the K variable. And I'm stopping at first order there. So these are the sort of like facts of calculus, facts of 18.02, you could say. Multivariable calculus, that's the point. Notice that we're doing just like the first half of 18.02, just differential calculus, derivatives, Taylor series. We're not doing multiple integrals. That's not part of our world here. OK. So that's the background. Now I want to look at optimization. OK. OK. So over here, I want to optimize. Well, over here, let me try to minimize f of x. And I'll be in the vector case here. And over here, I want to solve f equals 0. And of course, that means f of 1 equals 0 all the way along to fn equals 0. Here I have n equations and n unknowns. Let me start with that one. And I'll start with Newton's method. Newton's method to solve these n equations and n unknowns. OK, so Newton's method, which is often not presented in 18.02. That's a crime, because that's the big application of the gradients in Jacobian. OK. So I'm trying to solve n equations and n unknowns. And so I want f at x plus delta x to be 0. Right? So I want f of x plus delta x to be 0. So f at x plus delta x is I'm putting in as 0. I'm just copying that equation. Is f at where I am. Let me use k for the case iteration. So I'm at a point xk. I want to get to a point xk plus 1. And so I have 0 is f of x plus j at that point times delta x, which is xk plus 1 minus xk. Good. That's Newton's method. Of course, 0 isn't quite true. Well, 0 will be true for the I'm constructing xk plus 1 here. I'm constructing xk plus 1. OK. So let me just rewrite that, and we've got Newton's method. So we're looking for this change, xk plus 1 minus xk. I'll put it on this side as plus xk. OK. So that's this. Now I have to invert that and put it on the other side of the equation. So that'll go with a minus. This guy will be inverted. And f at xk. So that's Newton's method. Natural. Let me just repeat that. You see where the xk plus 1 minus xk is sitting, right? And I moved f of xk to the other side with a minus sign. And then I multiplied through by j inverse. So I got that. So that's Newton's method for a system of equations. And over there, I'm going to write down Newton's method for minimizing a function. This is such basic stuff that we have to begin here. Let me even begin with an extremely straightforward example of Newton's method here. Suppose my function, ah, suppose I've only got one function, actually. Suppose I only have one function. So suppose my function is x squared minus 9. And I want to solve f of x equals 0. I want to find the square root of 9. So what is Newton's method for it? We just should see. My point is just to see how Newton's method is written and then rewrite it a little bit so that we see their convergence. So of course, the Jacobian is 2x. So Newton's method says that xk plus 1, I'm just going to copy that Newton's method, minus 1 over 2xk, right? That's the derivative, times f of xk, which is xk squared minus 9. OK. OK. We followed the formula. This determines xk plus 1. And let's simplify it. So here I have xk minus, that looks like a half of xk. So I think I have a half of xk. And then this times this is 9 halves of 1 over xk. Is that right? Half of xk from this stuff, and plus 9 halves of 1 over xk. OK. Can I just check that I know the answer is 3? Can I be sure that I get the right answer 3? So if xk was exactly 3, then of course, I expect xk plus 1 to stay at 3. So does that happen? So half of 3 and 9 halves of 1 third, what's that? Half of 3 and 9 halves of 1 third, OK, that's 3 halves and 3 halves. That's 6 halves, and that's 3. OK. OK. So we've checked that the method is consistent, which just means we kept the algebra straight. But then the really important point about Newton's method is to discover how fast it converges. So now let me do xk plus 1 minus 3. So now I'm looking at the error, which is, I hope, approaching 0. Is it approaching 0? How quickly is it approaching 0? These are the fundamental questions of optimization. So I'm going to subtract 3 from both sides somehow. OK, from here. I guess I'm going to subtract 3. Can I just? So I was just checking that it was correct. OK. Now, so xk plus 1 minus 3. I'm going to subtract 3 from both sides. I'm going to subtract 3 there. And then I hope that that box is what goes down here, right? Subtracted 3 from both sides, so I'm looking at the, I'm hoping it go, now hoping things go to 0. OK, so what do I have there? Let me factor out the 1 over xk. So what do I have then left? 1 over xk. So there's a 9 halves from there. 1 over xk, so I really have a half of xk squared, because I've divided by an xk. And this minus 3, I better put minus 3xk, because I'm dividing by the xk. I claim that that's, now I've got it. And let's see, let me take out the 2. 2, forget these 2's, and make that a 6. So I have 1 over 2xk times 9 plus xk squared minus 6. Anything good about that? Yeah. We hope so. We hope that that is something attractive. So this is, again, this is the error at step k plus 1. And it's 1 over 2xk times this thing in brackets, 9 plus xk squared minus 6xk. And we recognize that as xk minus 3 squared. xk squared minus 6 of them plus 9, that's xk minus 3 squared. OK, that was the goal, of course. That's the goal that shows why Newton's method is fantastic. If you can execute it, if you can start near enough, notice that, so how do I describe this great equation? It says that the error is squared at every step, squared at every step. So if I'm converging to a limit, it will satisfy the, it will be 3, or I guess minus 3. Is that possible? Yeah, minus 3 is another solution here. So we've got two solutions. The Newton's method could converge to 3. Am I right? It could converge to minus 3? So I'd have a similar equation sort of centered at minus 3. Or does it always do one of those? It could blow up. It could, so there are sort of regions of attraction. There are all the starting points that approach 3. And the whole point of that equation is with quadratic convergence, the error being squared at every step. It zooms in on 3. Then there's all the starting points that would go to minus 3. And then there are the starting points that would blow up. And those, maybe for this very simple problem, the picture is not too difficult to sort out those three regions. But if we had, and this is allowing for a vector, two equations or n equations, then we're in n variables. And it's really, you get beautiful pictures. You get some of the type of pictures that gave rise to these books on fractals, picture books on fractals for these basins of attraction. Does the starting point lead you to one of the solutions, or does it lead you to infinity? Here, that would be interesting to just draw it for this. But the essential point is the quadratic convergence, if it's close enough. You see that it has to be close. If x0 is pretty near 3, then this is about 1 6 of that. And there will be a good region of attraction in this case. So that's Newton's method for equations. And now I want to do Newton's method. I just want to convert all those words over to Newton's method for optimization. So remember, these boards were solving F equals 0. This board is minimizing capital F. And what's the connection between them? Well, of course, this corresponds to solving the gradient equals 0. At a minimum, if I'm minimizing, I'm finding a point where all the first derivatives are 0. So that will be the match between these, that this grad F in this picture is the small f in that picture. Now, I guess here I have, and this is sort of the heart of our applications to deep learning, we have very complicated loss functions to minimize, functions of thousands or hundreds of thousands of variables. So that means that we would like to use Newton's method, but often we can't. So I need to put down here two methods, one that doesn't involve those high second derivatives, and one, a Newton's that does. So first I'll write down a method that does not involve. So method one, and this will be steepest descent. And what is that? That says that xk plus 1, the new x, is the old x minus. Steepest descent means that I move in the steepest direction, which is the direction of the gradient of F. I move some distance, and I better have freedom to decide what that distance should be. So this is a step size S, or in the language of deep learning, it's often called the learning rate. So if you see learning rate. OK. So is that so? And it's natural to choose Sk. We're going along. Do you see what this right hand side looks like? I'm at a point in n dimensions. We're all in n dimensions here. We have functions of n variables. There is a vector. There is a direction to move down the steepest slope of the graph. And here is a distance to move. And we will stop. We'll have to get off this step normally. If we stay on it, it'll swing back. It'll take us off to infinity. You would like to choose Sk so that you minimize capital F. You take the point on this line. So this is a line in Rn, a direction in Rn. And for all the points on that line in that direction, F has some value. And what you expect is that initially, because you chose it sensibly, the value of F will drop. But then at a certain point, it'll turn back on you and increase. So that would be the natural stopping point. And I would call that an exact line search. So exact line search would be exact line search is the best guess. Of course, that would take time to compute. And you probably, in deep learning, that's time you can't afford, so you fix the learning rate S. Maybe you choose 0.01 to be pretty safe. So that's method one, steepest descent. Now method two will be Newton's method. So now we have xk plus 1 equal to xk minus something times delta F. And now I'm going to do the right thing. I'm going to live right here. And the right thing is the Hessian, the second derivative. This was cheap. We just took the direction and went along it. Now we're getting really the right direction by using the second derivative. So that's H inverse. And what I've done is to set that to 0. So that would be, do you see that's Newton's method? It's totally parallel to this guy. Actually, I'm really happy to have these two on the board parallel to each other, because you have to kind of keep straight. Are you solving equations or are you minimizing functions? And you're using different letters in the two problems, but now you see how they match. The Jacobian of, so again, the match is think of F as the gradient of F. That's the way you should think of it. So the Jacobian of the gradient is the Hessian. The Jacobian of the gradient is the Hessian. And that makes sense, because the first derivative of the first derivative is the second derivative, only we're doing matrix-wise. So the Jacobian of the gradient, we're doing a vector matrix sentence instead of a scalar sentence. The Jacobian of the gradient is a Hessian. Yeah, right. So that's what I wanted to start with, just to get those basic facts down. And so the basic facts were the three-term Taylor series, and then the basic algorithms followed naturally from it by setting F at the new point to 0, if that's what you were solving, or by assuming you had the minimum. Right, good, good, good, good. OK, now what? Now we have to think about solving these problems, studying do they converge? What rate do they converge? Well, the rate of convergence is like why I took this, separated off this example. So the convergence rate for Newton's method will be quadratic. The error gets squared. And of course, that means super fast convergence if you start close enough. The rate of convergence for steepest descent is, of course, not. You're not squaring errors here, because you're just taking some number instead of the inverse of the correct matrix. So you can't expect super speed. So a linear rate of convergence would be right. You expect that the error to be, you would like to know that the error is multiplied at every step by some constant below 1. That would be a linear rate compared to being multiplied by being squared at every step. OK. And so this will be our basic. This is the basic formula that we build on for large scale, for really large scale problems. And there are methods, of course, people are going to come up with methods that, they're sort of a cheap Newton's method. Levenberg-Marquardt. And it's in the notes at the end of this section, or at the end of the 6.4 that we'll get to. So Levenberg-Marquardt is a sort of cheap man's Newton's method. It does not compute the Hessian, but it says, OK, from the gradient I can see a sort of one term in the Hessian. So it grabs that term. But it's not fully second order. OK. So now we have to think about problems. And I guess the whole message here is, and our starting point has to be convexity. Convexity is the key word for these problems. For the function that we want to minimize, if that's a convex function, well, first of all, the convex function is likely to have one minimum. And the picture that's in our mind of steepest descent, this picture of a bowl, a bowl is the graph of a convex function. So I'm turning to convexity now. I'll leave that board there, because that's pretty crucial. And speak about the idea of convexity. Convex function, convex set. So let's call the function f of x. And the typical convex set will be, I'll call it k. OK. So we just want to remember, what does that word convex mean, and how do you know if you have a convex function or a convex set? OK, let me start with convex set. Because here's my general problem, my convex minimization, which you hope to have, and in many applications you do have. So you minimize a convex function for points in a convex set. So that's like the ideal situation. That's the ideal situation, to get something on your side, something powerful, convexity. The function is convex. And so let me draw a convex function, the graph. So I'll draw a convex function, say, bowl. So that's a graph of f of x. And then, so here are the x's. Let me maybe put x1 and x2 in the base. And the graph of f of x1, x2 up here. OK, actually, I'm over there. I should be calling this function f, I think. Is that right? Yeah, little f would be the gradient of this guy. Yeah, I think so. OK, so now I'm minimizing over certain x's, not all x's. I might be minimizing, for example, K might be the set where Ax equals b. K might be, in that case, a subspace, or a shifted subspace, when I said subspace. But then 1806 is reminding me in my mind that I only have a subspace when b is 0. But I have a, you know the word for a subspace that's sort of moved over? Affine. So I'll just put that word down. Bunch of words to learn for this topic. But they're worth learning. So it's like a plane, but not necessarily through the origin. If b is 0, it doesn't go through. If b is not 0, it doesn't go through the origin. OK, anyway, or I have some other convex set. Let me just put the convex set K in the base plane. And did I make it convex? I think pretty luckily I did. So now what's the, well, the convex set, the constraint. So this is the constraint set. Constraint is that x must be x is in the set K. And I drew it as a convex blob. Here was an example where it's a flat, not a blob, but a flat plane. But let me come back to what does convex mean. What's a convex set? We have to do that. Should have done that before. In the notes, I had the fun of figuring out, if I took a triangle, is that a convex set? Let's just be sure. So what's a convex set? That is a convex set, because if I take any two points in the set and draw the line between them, it stays in the set. So that's convexity. Any line from x1 to x2 stays in the set. OK, good. So here's my little exercise to myself. What if I took the union of two triangles? All I wanted to get you to do is just sort of think, visualize convex and not convex possibilities. Suppose I have one triangle. Even if it was obtuse, that's still convex, right? No problem. But now, what if I put those two triangles together, take their union? Well, if I take them sitting with a big gap between, like I've lost. I mean, I've never had a chance that way. Because if I took one of my, if it was the union of these two, well, you know what I'm going to say. If I took that point and that point, of course, it goes outside. Stupid. What about, but what if the triangles, what if that triangle, that lower triangle, kind of overlaps the upper triangle? Is that a convex set? Everybody's right, saying no. How do I say that the union of those two triangles is not a convex set? Guys, you tell me where to pick two points where the line goes out. Well, I take one from that corner and one from that corner, and the line between them went outside. So union is usually not convex. Well, if I think of the union of two sets, my mind actually automatically goes to the other corresponding possibility, which is the intersection of the two sets. So if I take the intersection of the two sets. Now, what's the deal with that? When I had two triangles, two separated triangles, what can we say about the intersection of those two triangles? It's empty. So should we regard the empty set as a convex set? Yes. Isn't it? It's vacuous. So it hasn't got any problems. But now, is the intersection is always convex? I'm assuming the two sets that we start with are. Now, that's an important fact, that the intersection of convex sets. Let's just draw a picture that shows an example. So what's the intersection? Just this part, and it's convex. OK, can you give me a little proof that the intersection is convex? So I take two points in the intersection. Let me start the proof. To test if something's convex, how do you test it? You take two points in the set, in the intersection, and you want to show that the line between them is in the intersection. OK, why is that? So take two points. Take x1 in the intersection of, we've got two sets here, and that's the symbol for intersection. Now, we've got another point in the intersection. And now, we want to look at the line between them, the line from x1 to x2. What's the deal with that one? Is that fully in k1? Why is it fully in k1? I took two points in the intersection. I'm looking at the line between them, and I'm asking, is it in the first set, k1? And the answer is yes, because those points were in k1, and k1 is convex. And is that line between them in k2? Yes, same reason. The two endpoints were in k2, so the line between them is in k2. So the intersection of convex sets is always convex. The intersection of convex sets is convex. Good. So you'll see in the notes these possibilities with two triangles. Sometimes you can take the union, but not very often. Now, what's the next thing I have to do? Convex functions. We've got convex sets. What are convex functions, and we're good. Because this is our prototype of a problem. And I now know what it means for that f to be a convex. No, I'm sorry. I now know what it means for the set k to be convex set, but now I have to look at the other, often more important part of the problem. What's the function I'm minimizing? And I'm looking for functions with this kind of a picture. OK, the coolest way is to connect the definition of a convex function to the definition of a convex set. This is really the nicest way. It's a little quick. It just switches by you. But tell me, do you see a convex set in that picture? You see a convex set in that picture. That's the picture of a graph of a convex function. It's a picture of a bowl. Are the points on that surface, is that a convex set? No, certainly not. But where is a convex set to be found here in that picture? Yes. AUDIENCE 1. Is that a y and a 3? Yes, the points on and above the bowl. Inside the bowl, we could say. These points. So convex function, yes, a function's convex when the points on and above the graph are a convex set. This is, you could say, OK, mathematicians are just being lazy, having got one definition straight for a convex set. Now they're just using that to give an easy definition of a convex function. Actually, it's quite useful for functions that could maybe equal infinity, sort of generalized functions. But it's not the quickest way to tell if the function is convex. It's not our usual test for convex functions. So now I want to give such a test. OK. So now I have a definition of convex function, of a smooth convex function. Yeah. Yeah, this fact, I shouldn't rush off away from it, from the definition of a convex function as having a convex set above its graph. The really official French name for the set above the graph is the epigraph. But I won't even write that word down. OK. Why do I come back to that for a minute? Because I would like to think about two functions, f1 and f2. Out of two functions, I can always create the minimum or the maximum. So suppose I have two convex functions, convex functions f1 and f2. OK. Then I could choose the minimum. I could choose my new function. Shall I call it little m for minimum, m of x is the minimum of f1 and f2. And I could choose a maximum function, which would be the maximum of f1 of x and f2 of x at the same point x. It's just natural to think, OK, I have two functions. I've got a bowl, and I've got another bowl. And suppose they're both convex. So I'm just stretching the thing here. I've got the graphs of two convex functions. And I would like to consider the minimum of those two functions and also the maximum of those two functions. I believe life is good. One of these will be convex and the other won't. And can you identify which one is convex and which one is not convex? What about the minimum? Is that a convex function? So just look at the graph. What does the minimum look like? The minimum is this guy until they meet somehow on some surface, and then this guy. Is that convex? We have like one minute to answer that question. Absolutely no. It's got this bad kink in it. What about the maximum of the two functions? So the maximum is the one that's above all the points that are things that are above or on the there's the maximum function. That was the minimum function. It had a kink. The maximum function is like that, and it is convex. So maximum, yes. Minimum, no. And we could have a maximum of 1,500 functions. If the 1,500 functions are all convex, the maximum will be because it's the part way above everybody's graph. And that would be the graph of the maximum. OK, good. And now, finally, let me just say, how do you know whether a function is convex? How to test. How to test. OK, so let me take just a function of one variable. What's the test you learn in calculus, freshman calculus actually, to show that this is a convex function? What's the test for that? Second derivative should be positive or possibly 0. So second derivative greater or equal to 0 everywhere. That's convex. Convex. OK, final question. Suppose f is a vector. So this is a vector. And so I have n functions of n variables. No, I don't. Sorry, I've got one function, but I'm in n variables. So this was just one. What's the test for convexity? Test. So it would be passed, for example, by x1 squared plus x2 squared. Would it be passed by? So here would be the question. Would it be passed by x transpose some symmetric matrix S? That would be a quadratic, a pure quadratic. Would it be convex? What would be the test? I'm looking for an n dimensional equivalent of positive second derivative. The n dimensional equivalent of positive second derivative is convexity. And we have to recognize what's the test. So I could apply it to this function, or I could apply it to any function of n variables. And I maybe should be OK. What's the test here? Here I have a matrix instead of a number. So what's the requirement going to be? Times out, yeah. AUDIENCE 1. Question was positive definite? Positive definite, or semi-definite. Or semi-definite, just as here. Yeah, so the test is positive semi-definite Hessian. And here the Hessian is actually that S, because the second derivatives will produce. I'll put a half in there. The second derivatives will produce S equal to Hessian H. So this here, the S. So positive semi-definite. Hessian in general, second derivative matrix for a quadratic. So it's convex problems where we're going to get farther. We run into no saddle points. We run into no local minimum. Once we found a minimum, it's the global minimum. These are the good problems. Again, happy to see you today, and I look forward to Wednesday.