 Το επόμενο πρόγραμμα προσφέρει από το δίκτυο Creative Commons. Η υποστηρική σας θα βοηθήσει να συνεχίσει να προσφέρει υψηλές ειδικές ειδικές πιθανότητες αξιωματικά για ελεύθερα. Για να κάνετε μια διεγραφή ή να παρακολουθήσετε περισσότερα υλικά από χιλιάδες μαθητές MIT, επισκεφθείτε το MIT OpenCourseWare στηn ocw.mit.edu. Εντάξει, αν δεν το έχετε κάνει ακόμα, παρακαλώ πάρτε λίγο για να πάτε στο site της εξετάσεις του διεγραφή και να εισένετε τις σύνθετες σας για την κλάσσα. Λοιπόν, αυτό που θα κάνουμε σήμερα για να γεμίσουμε όλα αυτά είναι ότι θα πάμε σε μια δουλειά του κόσμου της υποθέσεις εξετάσεις, να δούμε μερικά παραδείγματα υποθέσεις εξετάσεις, ξεκινώντας από απλά μία, όπως η εκείνη, η κατάσταση που συζητήσαμε την τελευταία φορά, σε οποία έχετε μόνο δύο υποθέσεις, προσπαθείτε να επιλέξετε μεταξύ των δύο, αλλά επίσης να δείτε περισσότερα συγκλονιστικές κατάστασεις, σε οποία έχετε μία βασική υποθέση, ας πούμε ότι έχετε μια ευαίσθητη κομμάτια και θέλετε να την δοκιμάσετε αντί για την υποθέση ότι η κομμάτια σας δεν είναι ευαίσθητη, αλλά αυτή η αλληλεπίδραση υποθέσεις είναι πραγματικά πολλά διαφορετικά υποθέσεις. Λοιπόν, είναι η κομμάτια μου καθαρά, είναι η βάση μου καθαρά, έχω την κατάσταση σωστή για ένα διευθύνιο, κ.ο.κ. και θα τελειώσω με μερικές γενικές σχόλες για αυτό το όλο το επιχειρήμα. Λοιπόν, η κατάσταση σε απλές προβλήματα της υποθέσης εξετάσεις είναι η επόμενη. Έχουμε δύο δυνατές μοντέλες. Και αυτό είναι το κλασικό κόσμο, οπότε δεν έχουμε κανένα προηγούμενο πιθανότητας στις δύο υποθέσεις. Συνήθως, θέλουμε να σκεφτούμε ότι αυτή η υποθέση δεν είναι ολοκληρωμένη, αλλά πάντα μια είναι η αποφάσιμη υποθέση, και συνήθως την επίσημενόμενη είναι η αποφάσιμη υποθέση. Και θέλουμε να δούμε αν η αποφάσιμη υποθέση είναι αλήθεια, αν τα πράγματα είναι λοιπόν κανονικά, όπως θα τις εξετάσατε να είναι, ή αν αποφασίζεται να είναι αλήθεια, σε οποίο στήριξη μια αλληλεπίδραση υποθέσεις θα είναι σωστή. Λοιπόν, πώς θα το κάνει κάποιος με το οποίο θα συμφωνήσει. Δεν με αφορά την προσέγγιση που χρησιμοποιείτε, στο τέλος θα κάνετε το επόμενο. Έχετε το χώρο των δυνατών παρατηριασμών που μπορείτε να αποκτήσετε. Λοιπόν, όταν κάνετε το εξετάσιο, θα λάβετε ένα X-δεξί, ένα δεξί δεξιούς, αυτό είναι κάπου. Και για κάποιους δεξίους θα αποφασίσετε ότι θα αποδεχτείτε H0, για κάποιους δεξίους ότι θα αποδεχτείτε H0 και θα αποδεχτείτε H1. Λοιπόν, αυτό που θα κάνετε είναι ότι θα έχετε κάποια διαφορά της εξέτασης των όλων των X-δεξιών σε δύο μέρες. Και μια μέρα είναι η περιοχή αποδεχτών, και μια μέρα είναι η περιοχή αποδεχτών. Λοιπόν, αν πέφτετε εδώ, αποδεχτείτε H0, αν πέφτετε εδώ, αποδεχτείτε H0. Λοιπόν, για να δημιουργήσετε ένα δεξί δεξιού, βασικά πρέπει να έρθετε με τη διαφορά της εξέτασης σας σε δύο μέρες. Λοιπόν, να καταλάβετε πώς να κάνετε αυτό συμβαίνει σε δύο μέρες. Μία μέρα είναι να αποφασίσετε ποιο τύπο θέλω για την κύρωση που διαχωριζώ. Και, έχοντας επιλέξει το τύπο της κύρωσης, πού ακριβώς το βάλω. Λοιπόν, αν ήθελετε να κόψετε αυτήν την εξέταση χρησιμοποιώντας, ας πούμε, έναν σωστό κόψιμο, μπορείτε να το βάλετε εδώ ή να το βάλετε εκεί ή να το βάλετε εκεί. Πού ακριβώς θα το βάλετε. Λοιπόν, ας δούμε τις δύο βήματα. Το πρώτο πρόβλημα είναι να αποφασίσετε την κυριαρχική σχέση της εξέτασης σας, η οποία είναι ο τρόπος της στρατηγίας σας. Και την τύπη που αυτό γίνεται για το πρόβλημα των δύο υποθέσεων είναι από το γράφω το σύμφωνο διόρθωρο μεταξύ των δύο υποθέσεων. Ας το ονομάσουμε εξ' εξ. Είναι κάτι που μπορείτε να καταποδίσετε, εξ' εξ, δεδομένου το παιχνίδι που έχετε. Ένα υψηλό αριθμό εξ' εξ, γραφτικά, σημαίνει ότι αυτή η πιθανότητα εδώ προκειμένου να είναι μεγαλύτερη από αυτή η πιθανότητα. Δηλαδή, το παιχνίδι που έχετε δει είναι αρκετά πιθανό να έχει συμβεί κάτω από H1, αλλά λιγότερο πιθανό να έχει συμβεί κάτω από H0. Λοιπόν, αν βλέπετε δεδομένες που είναι πιο πιθανότερος, μπορούν να εξηγηθούν καλύτερα κάτω από H1, τότε αυτό το αριθμό είναι μεγάλο, και θα επιλέξετε σε φάρμακο του H1 ή να αποδεχτείτε H0. Αυτό είναι αυτό που κάνετε αν έχετε δισκριτές δεδομένες. Χρησιμοποιείτε τα πιθανότητα. Αν έχετε δυνάμεις, στο περίπτωσο της συνεχής δεδομένης, ξανά, θεωρείτε το αριθμό των δύο δυνάμεων. Λοιπόν, λεπτό Lx είναι ένας φορές που τα δεδομένα σας είναι πιο συμπεριφερόμενα με το H1 αντί με το H0. Μετά από το αποδεχτήμα αυτής της στρατηγίας, η αποφάσιση σας είναι πραγματικά κατασκευή σε όρια με το μόνο αριθμό. Δηλαδή, είχατε τα δεδομένα σας, που ήταν κάποια είδη δεδομένα, και κατασκευάζετε τα δεδομένα σας σε ένα μόνο αριθμό, ένας στατιστικός, όπως το λένε. Σε αυτό το στιλ, το αριθμό των δεδομένων. Και βάλετε ένα σημείο διαχωρισμένο κάπου εδώ, το λένε Ξ. Και σε αυτή την περιοχή, αποδεχτείτε το H1, σε αυτή την περιοχή αποδεχτείτε το H0. Λοιπόν, αντιμετωπίζοντας τον εαυτό μας να χρησιμοποιήσουμε το αριθμό των δεδομένων, για να διατηρήσουμε το δεδομένο, έχουμε πέρα από αυτό το δύσκολο φωτογραφικό πρόβλημα, να βρει ένα σημείο διαχωρισμένο σε εξ-εσπίση, σε ένα απλό πρόβλημα, να βρει ένα σημείο διαχωρισμένο στην πραγματική στρατηγική. Ωραία, πώς θα πάμε. Λοιπόν, αυτό που μας έφερε να κάνουμε είναι να επιλέξουμε αυτό το σημείο Ξ, ή όπως το λέμε, το κρίτικο αριθμό για την αποφάσιση της αποφάσεις μας. Και μπορείτε να τοποθετήσετε σε οποιοδήποτε, αλλά ένας τρόπος να αποφάσισετε πού τοποθετήσετε είναι το επόμενο, κοιτάξτε την διαδίκτυα αυτής της δίκτυας λ-εξ. Έχει μια συγκεκριμένη διαδίκτυα κάτω από η H0, και έχει κάποια άλλη διαδίκτυα κάτω από η H1. Αν βάλω το σύνοδο μου εδώ, εδώ είναι τι θα συμβαίνει. Όταν η H0 είναι αλήθεια, υπάρχει τόσο πολλή πιθανότητα ότι θα τελειώσω να κάνω μια αλήθεια αποφάσιση. Αν η H0 είναι αλήθεια, υπάρχει ακόμα μια πιθανότητα ότι η αρχή δυνατότητα μου θα είναι μεγαλύτερη από η ξ. Και αυτή είναι η πιθανότητα να κάνω μια αλήθεια αποφάσισης αυτής της συγκεκριμένης τύπως. Δηλαδή, να κάνω μια αλήθεια αποφάσισης της H0. Συνήθως, μια πιθανότητα αυτή καθίστεται σε μια συγκεκριμένη αριθμή, αλφα. Για παράδειγμα, αλφα είναι 5%. Και μόλις αποφάσισετε ότι θέλετε αυτό να είναι 5%, αυτό αποφάσιζε πού θα είναι αυτή η αριθμή ξ. Λοιπόν, η ιδέα εδώ είναι ότι θα αποφάσισω H0 αν τα δεδομένα που έχω δει είναι αρκετά ανταποκριτικά με H0, αν είναι αρκετά αδύνατο να έχουν συμβεί στην H0. Και πάω αυτό το επίπεδο, 5%, οπότε βλέπω τα δεδομένα μου και τότε λέω, καλά, αν η H0 ήταν αλήθεια, η πιθανότητα ότι θα είχα δει δεδομένα αυτό το εικόνα θα ήταν λιγότερα από 5%. Δεδομένα που είδα αυτά τα δεδομένα, αυτό προτείνει ότι H0 δεν είναι αλήθεια και τέλος αποφάσιζω H0. Τώρα, φυσικά, υπάρχει και ένα άλλο είδος εργόπισμα. Αν βάλω το σύνοδο μου εδώ, αν H1 είναι αλήθεια, αλλά η πιθανότητα αλήθεια κερδίζει εδώ, θα κάνω ένα λάθος για το αντίθετο εικόνα. H1 είναι αλήθεια, αλλά η πιθανότητα μου έκανε να είναι μικρή, και αποφάσισα σε φάρμακο για H0. Αυτό είναι ένα εργόπισμα του άλλου είδους. Αυτή η πιθανότητα εργόπισμας, το λέμε β. Και μπορείτε να δείτε ότι υπάρχει ένα αγοράγιο μεταξύ αλφα και β. Αν κινηθείτε το σύνοδο σας αυτόν τον τρόπο, η αλφα γίνεται μικρότερη, αλλά η β γίνεται μεγαλύτερη. Και η γενική πιστόλα είναι, στον αγοράγιο σας, ανάλογα με το όρο που βάλετε το σύνοδο σας, είναι αυτό. Μπορείτε να κάνετε αυτή η β να είναι 0, αν βάλετε το σύνοδο σας εδώ, αλλά, σε αυτό το περίπτωσο, είστε σίγουροι ότι θα κάνετε ένα λάθος του αντίθετο εικόνα. Λοιπόν, β γίνεται 0, αλφα γίνεται 1, είναι μια πιθανότητα. β γίνεται 1, αλφα γίνεται 0, είναι η άλλη πιθανότητα, αν στέλνετε το σύνοδο σας ολόκληρο στο άλλο πλευρό. Και, γενικά, θα λάβετε μια κύρια κύρια κύρια, κάποια τύπη. Και αν θέλετε να χρησιμοποιήσετε μια συγκεκριμένη αξία αλφα, για παράδειγμα, αλφα γίνοντας 0,05, τότε θα σας αποτελέσει αυτή η πιθανότητα για β. Τώρα, υπάρχει μια γενική και αρκετά σημαντική θεωρία στα στατιστικά, που δεν προβλήματιζόμαστε, και η οποία μας λέει ότι όταν χρησιμοποιούμε διευθυντικές δοξές, εμείς λάβουμε την καλύτερη κύρια κύρια κύρια. Μπορείτε να σκεφτείτε άλλες τρόπες για να κάνετε τις αποφάσεις σας, άλλες τρόπες για να κόψετε το εξ-σπαίσι σας σε μια περιοχή αποδεχόμενης και αποδεχόμενης, αλλά κάποια άλλη τρόπη που θα το κάνετε θα κερδίσει με κάποιες αρχότητες αλφαγής που θα είναι πάνω από αυτήν την συγκεκριμένη κύρια κύρια. Οπότε, το δοξοδοξιότητας δοξάς, παραδείγματος να σας δώσει το καλύτερο δίκαιο τρόπο να αντιμετωπίσετε αυτήν την δοξαγωγή μεταξύ αλφα και βετα. Δεν μπορούμε να μειωθούμε αλφα και βετα συνεχώς. Υπάρχει μια δοξαγωγή μεταξύ των δύο, αλλά λίγο θα ήθελα να έχουμε ένα δοξαγωγή που αντιμετωπίσει αυτήν την δοξαγωγή μεταξύ αλφα και βετα. Για ένα δεδομένο αλφα θέλουμε να έχουμε το μικρότερο δοξαγωγή μεταξύ βετα. Και η θεωρία είναι ότι οι δοξαγωγές δοξαγωγής έχουν αυτή την προσωπικότητα της οπτιμιότητας. Για ένα δεδομένο αλφα, εμφανίζουν την πιθανότητα εφαρμογής μιας διαφορετικής είδης. Άρα, ας κάνουμε όλα αυτά τα συγκεκριμένα και να δούμε ένα απλό παράδειγμα. Έχουμε δύο δοξαγωγές με διαφορετικά μέτρα. Οπότε, κάτω από H0 έχετε μήνυμα 0, κάτω από H1 έχετε μήνυμα 1. Βάζετε τα δεδομένα σας. Βάζετε σε πραγματικότητα δεδομένα, δημιουργημένα από ένα από τα δύο διαφορετικά μέτρα, και θέλετε να κάνετε μια αποφάσιονση με το οποίο ένα από τα δύο είναι αλήθεια. Άρα, τι κάνετε, γράφετε το αρθροδότητο. Η δύναμη για ένα δοξαγωγή μεταξύ βετα, αν αυτό το δοξαγωγή δημιουργηθεί με το οποίο είναι H0, και η δύναμη αν δημιουργηθεί με το οποίο είναι H1. Επειδή έχουμε δεδομένα, η δύναμη για ένα δοξαγωγή είναι το πρότυπο των δύναμων των αντιμετωπιστών στοιχείων. Επειδή αντιμετωπίζουμε τις δυνάμες, έχουμε αυτές τις εξωτερικές δεδομένες. Ένα πρότυπο εξωτερικών δίνει μας ένα εξωτερικό της σωματίας. Θα σας αποφάσισω τα πληροφορία, αλλά αυτή είναι η τέτοια δύναμη για το δοξαγωγή. Και το δοξαγωγή δοξαγωγή μας λέει ότι πρέπει να δοξαγωγήσουμε αυτή την ποσότητα μετά από το ποιότητα σας και να το παρακολουθήσουμε με ένας σωματίας. Τώρα μπορείτε να κάνετε κάποια αλγέβη εδώ και να το απλώσετε. Και με το να προσφέρετε τις αντίμετα, να πάρετε λογαρισμούς από διώκομα και τ. π. Έρχεται ένας στο σύντομο ότι χρησιμοποιώντας ένα δοξαγωγή που έχει ένα σωματίας σε όλο αυτό το μίσος, είναι οδυναμικός και καταλαβαίνει το αυτό το ποσότητα και το παρακολουθεί με ένα ποιοτητας. Βασικά, αυτό το ποσότητα εδώ είναι μονοτονικό σε αυτό το ποσότητα. Αυτό, οτιδήποτε dumplings είναι μεγαλούτερο από το ποσοτητα, είναι οδυναμικός και αυτό οτιδήποτε είναι μεγαλύτερο από το ποσοτητα. Οπότε, αυτό μας μίλησε την γενική στερή ασφάλεια είδος μιας δοξαγωγής σε αυτή τη συγκεκριμένη περίπτωση. And it's nice because it tells us that we can make our decisions by looking at this simple summary of the data. This quantity, this summary of the data on the basis of which we make our decision, is called a statistic. So you take your data, which is a multidimensional vector, and you condense it to a single number. And then you make a decision on the basis of that number. So this is the structure of the test. If I get a large sum of Xi's, this is evidence in favor of H1, because here the mean is larger. And so I'm going to decide in favor of H1, or reject H0, if this sum is bigger than the threshold. How do I choose my threshold? Well, I would like to choose my threshold so that the probability of an incorrect decision, when H0 is true, the probability of a false rejection equals to a certain number, alpha, such as, for example, 5%. So you're given here that this is 5%. You know the distribution of this random variable. It's normal. And you want to find the threshold value that makes this to be true. So this is a type of problem that you have seen several times, you go to the normal tables, and you figure it out. So the sum of the Xi's has some distribution. It's normal. So that's the distribution of the sum of the Xi's. And you want this probability here to be alpha. For this to happen, what is the threshold value that makes this to be true? So you know how to solve problems of this kind using the normal tables. A slightly different example is one in which you have two normal distributions that have the same mean. Let's take it to be 0. But they have a different variance. So it's sort of natural that here, if your X's that you see are kind of big on either side, you would choose H1. If your X's are near 0, then that's evidence for the smaller variance. You would choose H0. So to proceed formally, you again write down the form of the likelihood ratio. So again, the density of an X vector under H0 is this one. It's the product of the densities of each one of the Xi's. Product of normal densities gives you a product of exponentials, which is exponential of a sum. And that's the expression that you get. Under the other hypothesis, the only thing that changes is the variance. And the variance in the normal distribution shows up here in the denominator of the exponent. So you put it there. So this is the general structure of the likelihood ratio test. And now you do some algebra. These terms are constants. Comparing this ratio to a constant is the same as just comparing the ratio of the exponentials to a constant. Then you take logarithms. You want to compare the logarithm of this thing to a constant. You do a little bit of algebra. And in the end, you find that the structure of the test is to reject H0 if the sum of the squares of the Xi's is bigger than the threshold. So by committing to a likelihood ratio test, you are told that you should be making your decision according to a rule of this type. So this fixes the shape or the structure of the rejection region. And the only thing that's left, once more, is to pick this threshold in order to have the property that the probability of a false rejection is equal to, say, 5%. So that's the probability that H0 is true. But the sum of the squares accidentally happens to be bigger than my threshold, in which case I end up deciding H1. How do I find the value of Xi prime? Well, what I need to do is to look at the picture more or less of this kind. But now I need to look at the distribution of the sum of the Xi's squared. Actually, the sum of the Xi's squared is a non-negative random variable. So it's going to have a distribution that's something like this. I look at that distribution. And once more, I want this tail probability to be alpha. And that determines where my threshold is going to be. So that's, again, a simple exercise, provided that you know the distribution of this quantity. Do you know it? Well, we don't really know it. We have not dealt with this particular distribution in this class. But in principle, you should be able to find what it is. It's a derived distribution problem. You know the distribution of Xi. It's normal. Therefore, by solving a derived distribution problem, you can find the distribution of Xi squared. And the Xi squareds are independent of each other, because the Xi's are independent. So you want to find the distribution of the sum of random variables with known distributions. And since they're independent, in principle, you can do this using the convolution formula. So in principle, and if you're patient enough, you will be able to find the distribution of this random variable. And then you sort of plot it or tabulate it, and find where exactly is the 95th percentile of that distribution. And that determines your threshold. So this distribution actually turns out to have a nice and simple closed-form formula, because this is a pretty common test. People have tabulated that distribution. It's called the Xi squared distribution. There's tables available for it. And you look up in the tables, you find the 95th percentile of the distribution. And this way, you determine your threshold. So what's the moral of this story? The structure of the likelihood ratio test tells you what kind of decision region you're going to have. It tells you that for this particular test, you should be using the sum of the Xi squareds as your statistic, as the basis for making your decision. And then you need to solve a derived distribution problem to find the probability distribution of your statistic, find the distribution of this quantity under H0. And finally, based on that distribution, after you have derived it, then determine your threshold. So now let's move on to a somewhat more complicated situation. You have a coin, and you're told that I tried to make a fair coin. Is it fair? So you have the hypothesis, which is the default, the null hypothesis, that the coin is fair. But maybe it isn't. So you have the alternative hypothesis that your coin is not fair. Now what's different in this context is that your alternative hypothesis is not just one specific hypothesis. Your alternative hypothesis consists of many alternatives. It includes the hypothesis that P is 0.6. It includes the hypothesis that P is 0.51. It includes the hypothesis that P is 0.48, and so on. So you're testing this hypothesis versus all this family of alternative hypotheses. What you will end up doing is essentially the following. You get some data, that is, you flip the coin a number of times, let's say you flip it 1,000 times. You observe some outcome. Let's say you saw 472 heads. And you ask the question, if this hypothesis is true, is this value really possible under that hypothesis, or would it be very much of an outlier? If it looks like an extreme outlier under this hypothesis, then I reject it and I accept the alternative. If this number turns out to be something within the range that you would have expected, then you keep or accept your null hypothesis. OK, so what does it mean to be an outlier or not? First you take your data and you condense them to a single number, so your detailed data actually would have been a sequence of heads, tails, heads, tails, and all that, any reasonable person would tell you that you shouldn't really care about the exact sequence of heads and tails. Let's just base our decision on the number of heads that we have observed. So you somehow, using some kind of reasoning, which could be mathematical or intuitive or involving artistry, you pick a one-dimensional or scalar summary of the data that you have seen. In this case, the summary of the data is just the number of heads, that's a quite reasonable one. And so you commit yourself to make a decision on the basis of this quantity. And you ask, the quantity that I'm seeing, does it look like an outlier or does it look more or less OK? OK, what does it mean to be an outlier? You want to choose the shape of this rejection region, but on the basis of that single number, s. And again, a reasonable thing to do in this context would be to argue as follows. If my coin is fair, I expect to see n over 2 heads. That's the expected value. If the number of heads I see is far from the expected number of heads, then I consider this to be an outlier. So if this number is bigger than some threshold, Xi, I consider it to be an outlier. And then I'm going to reject my hypothesis. So we picked our statistic. We picked the general form of how we're going to make our decision. And then we pick a certain significance or confidence level that we want. Again, this famous 5% number. And we're going to declare something to be an outlier if it lies in the region that has 5% or less probability of occurring. That is, I'm picking my rejection region so that if H0 is true under the default or null hypothesis, there's only 5% chance that by accident I fall there and the thing makes me think that H1 is going to be true. So now what's left to do is to pick the value of this threshold. This is a calculation of the usual kind. I want to pick my threshold, my Xi number, so that the probability that S is further from the mean by an amount of Xi is less than 5%, or that the probability of being inside the acceptance region, so that the distance from the default is less than my threshold, I want that to be 95%. So this is an equality that you can get using the central limit theorem and the normal tables. There's 95% probability that the number of heads is going to be within 31 from the correct mean. So the way the exercise is done, of course, is that we start with this number, 5%, which translates to this number, 95%. And once we have fixed that number, then you ask the question, what number should we have here to make this equality to be true? It's again a problem of this kind. You have a quantity whose distribution you know. Why do you know it? The number of heads by the central limit theorem is approximately normal. So this here talks about a normal distribution. You set your alpha to be 5%, and you ask where should I put my threshold so that this probability of being out there is only 5%. Now in our particular example, the threshold turned out to be 31. This number turned out to was just 28 away from the correct mean, so this distance was less than the threshold. So we end up not rejecting H0. So we have our rejection region. The way we designed it is that when H0 is true, there's only a small chance, 5%, that we get data out of there, data that we would call an outlier. If we see such an outlier, we reject H0. If what we see is not an outlier, as in this case, where that distance turned out to be kind of small, then we do not reject H0. An interesting little piece of language here. People generally prefer to use this terminology, to say that H0 is not rejected by the data, instead of saying that H0 is accepted. In some sense, they're both saying the same thing, but the difference is sort of subtle. When I say not rejected, what I mean is that I got some data that are compatible with my hypothesis. That is, the data that I got do not falsify the hypothesis that I had, my null hypothesis. So my null hypothesis is still alive and may be true. But from data, you can never really prove that the hypothesis is correct. Perhaps my coin is not fair in some other complicated way. Perhaps I was just lucky, and even though my coin is not fair, I ended up with an outcome that suggests that it's fair. Perhaps my coin flips are not independent, as I assumed in my model. So there's many ways that my hypothesis could be wrong, and my null hypothesis could be wrong. And still, I got data that tell me that my hypothesis is OK. So this is sort of the general way that things work in science. One comes up with a model or a theory. This is the default theory, and we sort of work with that theory, trying to find whether there are examples that violate the theory. If you find data and examples that violate the theory, your theory is falsified, and you need to look for a new one. But when you have your theory, really no amount of data can prove that your theory is correct. So we have the default theory that the speed of light is constant, as long as we do not find any data that are run counter to it. We stay with that theory, but there's no way of really proving this, no matter how many experiments we do. But there could be experiments that falsify that theory, in which case we need to look for a new one. So there's a bit of an asymmetry here in how we treat the alternative hypothesis. H0 is sort of the default, which we'll accept until we see some evidence to the contrary. And if we see some evidence to the contrary, we reject it. As long as we do not see evidence to the contrary, then we keep working with it, but always take it with a grain of salt. You can never really prove that a coin has a bias exactly equal to 1 half. Maybe the bias is equal to 0.50001. So the bias is not 1 half, but with an experiment with 1,000 coin tosses, you wouldn't be able to see this effect. So that's how you go about testing about whether your coin is fair. You can also think about testing whether a die is fair. So for a die, the null hypothesis would be that every possible result when you roll the die has equal probability and equal to 1 sixth. And you also make the hypothesis that your die rolls are statistically independent from each other. So I take my die, I roll it a number of times, little n, and I count how many 1's I got, how many 2's I got, how many 3's I got. And these are my data. I count how many times I observed a specific result in my die roll that was equal to some i. And now I ask the question, the n i's that I observed, are they compatible with my hypothesis or not? What does compatible to my hypothesis mean? Under the null hypothesis, n i should be approximately equal or is equal in expectation to n times little p i. And in our example, this little p i is, of course, 1 sixth. So if my die is fair, the number of 1's I expect to see is equal to the number of rolls times 1 sixth. The number of 2's I expect to see is, again, that same number. Of course, there's randomness, so I do not expect to get exactly that number. But I can ask how far away from the expected values was i. If my capital N i's turn to be very different from n over 6, this is evidence that my die is not fair. If those numbers turn out to be close to n times 1 sixth, then I'm going to say there's no evidence that would lead me to reject this hypothesis. So this hypothesis remains alive. So someone has come up with this thought that maybe the right statistic to use, or the right way of quantifying how far away are the n i's from their mean, is to look at this quantity. So I'm looking at the expected value of n i under the null hypothesis, see what I got, take the square of this, and add it over all i's. But also throw in this term in the denominator. And why that term is there, that's a longer story. One can write down certain likelihood ratios, do certain Taylor series approximations, and there's a heuristic argument that justifies why this would be a good form for the test to use. So there's a certain art that's involved in this step that some people somehow decided that it's a reasonable thing to do to calculate, once you get your results, to calculate this one-dimensional summary of your result. This is going to be your statistic. And compare that statistic to a threshold. And that's how you make your decision. So by this point, we have fixed the type of the rejection region that we're going to have. So we've chosen the qualitative structure of our test, and the only thing that's now left is to choose the particular threshold we're going to use. And the recipe, once more, is the same. We want to set our threshold so that the probability of a false rejection is 5%. We want the probability that our data fall in here is only 5% when the null hypothesis is true. So that's the same as setting our threshold, Xi, so that the probability that our test statistic is bigger than that threshold, we want that probability to be only 0.05. So to solve a problem of this kind, what is it that you need to do? You need to find the probability distribution of capital T. So once more, it's the same picture. You need to do some calculations of some sort and come up with the distribution of the random variable T, where T is defined this way. You want to find this distribution under hypothesis H0. Once you find what that distribution is, then you can solve this usual problem. I want this probability here to be 5%. What should my threshold be? So what does this boil down to? Finding the distribution of capital T is, in some sense, a messy, difficult, derived distribution problem. From this model, we know the distribution of the capital N i's. And actually, we can even write down the joint distribution of the capital N i's. In fact, we can make an approximation here. Capital Ni is a binomial random variable. Let's say the number of 1's that I got is 1. And I can write down the distribution of the capital N, the number of 1's that I got, in little n rolls of my die. So that's a binomial random variable. When little n is big, this is going to be approximately normal. So we have normal random variables, or approximately normal, minus a constant. They're still approximately normal. We take the squares of these, scale them. So you can solve a derived distribution problem to find the distribution of this quantity. You can do more work, more derived distribution work, and find the distribution of capital T. So this is a tedious matter. But because this test is used quite often, again, people have done those calculations. They have found the distribution of capital T. And it's available in tables. And you go to those tables. And you find the appropriate threshold for making a decision of this type. OK. Now to give you a sense of how complicated a hypothesis one might have to deal with, let's make things one level more complicated. So here, you can think this X is a discrete random variable. This is the outcome of my roll. And I had the model in which the possible values of my discrete random variable have probabilities all equal to 1 sixth. So my null hypothesis here was a particular PMF for the random variable capital X. So another way of phrasing what happened in this problem was the question, is my PMF correct? So this is the PMF of the result of one die roll. You're asking the question, is my PMF correct? Make it more complicated. How about the question of the type, is my PDF correct when I have continuous data? So I have hypothesized that the probability distribution that I have is, let's say, a particular normal. I get lots of results from that random variable. Can I tell whether my results look like normal or not? What are some ways of going about it? Well, we saw in the previous slide that there is a methodology for deciding if your PMF is correct. So you could take your normal results, the results, the data that you got from your experiment, and discretize them, and so now you're dealing with discrete data. And sort of use the previous methodology to solve a discrete problem of the type, is my PDF correct? So in practice, the way this is done is that you get all your data, let's say data points of this kind. You split your space into bins, and you count how many you have in each bin. So you get this, and that, and that, and that, and nothing. So that's a histogram that you get from the data that you have. Like the very familiar histograms that you see after each one of our quizzes. So you look at this histogram, and you ask, does it look like normal? OK, we need a systematic way of going about it. If it were normal, you can calculate the probability of falling in this interval, the probability of falling in that interval, probability of falling at that interval. So you would have expected values of how many results or data points you would have in this interval, and compare these expected values for each interval with the actual ones that you observed. And then take the sum of squares and so on, exactly as in the previous slide, and this gives you a way of going about it. This is a little messy. It gets hard to do, because you have the difficult decision of how do you choose the bin size. If you take your bins to be very narrow, you would get lots of bins with 0's and a few bins that only have one outcome in them. It probably wouldn't feel right. If you choose your bins to be very wide, then you're losing a lot of information. Is there some way of making a test without creating bins? This is just to illustrate the clever ideas of what statisticians have thought about. And here's a really cute way of going about the test, whether my distribution is correct or not. Instead of, here we're essentially plotting a PMF, or an approximation of a PDF, and we ask does it look like the PDF we assumed. Instead of working with PDFs, let's work with cumulative distribution functions. So how does this go? The true normal distribution that I have hypothesized, the density that I'm hypothesizing, my null hypothesis, has a certain CDF that I can plot. So suppose that my hypothesis, H0, is that the X's are normal, with our standard normals. And I plot the CDF of the standard normal, which is the sort of continuous looking curve here. Now I get my data, and I plot the empirical CDF. What's the empirical CDF? In the empirical CDF, you ask the question, what fraction of the data fell below 0? You get a number. What fraction of my data fell below 1? I get a number. What fraction of my data fell below 2? And so on. So you're talking about fractions of the data that fell below each particular number. And by plotting those fractions as a function of this number, you get something that looks like a CDF. And it's the sort of CDF suggested by the data. Now the fraction of the data that fall below 0 in my experiment is, if my hypothesis were true, that fraction is expected to be 1 half. 1 half is the value of the true CDF. I look at the fraction that I got. It's expected to be that number. But there's randomness, so it might be a little different than that. For any particular value, the fraction that I got below a certain number, the fraction of data that were below 2, is expected, its expectation is the probability of falling below 2, which is the correct CDF. So if my hypothesis is true, the empirical CDF that I get based on data should, when n is large, be very close to the true CDF. So a way of judging whether my model is correct or not is to look at the assumed CDF, the CDF under hypothesis H0, look at the CDF that I constructed based on the data, and see whether they're close enough or not. And by close enough, I mean I'm going to look at all the possible X's and look at the maximum distance between those two curves. And I'm going to have a test that decides in favor of H0 if this distance is small, and in favor of H1 if this distance is large. That still leaves me the problem of coming up with a threshold. Where exactly do I put my threshold? Because this test is important enough and is used frequently, people have made the effort to try to understand the probability distribution of this quite difficult random variable. One needs to do lots of approximations and clever calculations, but these have led to values and tabulated values for the probability distribution of this random variable. And for example, those tabulated values tell us that if we want 5% false rejection probability, then our threshold should be 1.36 divided by the square root of n. So we know where to put our threshold for this particular value if we want this particular error or error probability to occur. So that's about as hard and sophisticated classical statistics gets. You want to have tests for hypotheses that are not so easy to handle. People somehow think of clever ways of doing tests of this kind, how to compare the theoretical predictions with the observed predictions, with the observed data, come up with some measure of the difference between theory and data. And if that difference is big, then you reject your hypothesis. OK, of course that's not the end of the field of statistics, there's a lot more. In some ways, as we kept moving through today's lecture, the way that we constructed those rejection regions was more and more ad hoc. I pulled out of a hat a particular measure of fit between data and the model. And I said let's just use a test based on this. There are attempts at more or less systematic ways of coming up with the general shape of rejection regions that have at least some desirable or favorable theoretical properties. Some more specific problems that people study. Instead of having a test, is this the correct PDF, yes or no? I just give you data, and I ask you, is this the correct PDF, and I ask you, give me a model or a PDF for those data. OK, methods of this kind are of many types. One general method is you form a histogram, and then you take your histogram and plot a smooth line that kind of fits the histogram. This still leaves the question of how do you choose the bins, the bin size in your histograms. How narrow do you take them? And that depends on how many data you have. And there's a lot of theory that tells you about the best way of choosing the bin sizes and the best ways of smoothing the data that you have. A completely different topic is in signal processing you want to do your inference. Not only you want it to be good, but you also want it to be fast in a computational way. You get data in real time, lots of data. You want to keep processing and revising your estimates and your decisions as data come and go. Another topic that was sort of briefly touched upon in the last couple of lectures is that when you set up a model like a linear regression model, you choose some explanatory variables, and you try to predict y from your x variables. You have a choice of what to take as your explanatory variables. Are there systematic ways of picking sort of the right variables, the right x variables, to try to estimate y? For example, should I try to estimate y on the basis of x, or on the basis of x squared? How do I decide between the two? Finally, the rage these days has to do with anything big, high dimensional. Complicated models of complicated things, and tons and tons of data. So these days, data are generated everywhere. Amounts of data are humongous. Also, the problems that people are interested in tend to be very complicated with lots of parameters. So one needs specially tailored methods that can give you good results or decent results, even in the face of these huge amounts of data, and possibly with computational constraints. So with huge amounts of data, you want methods that are simple, but still can deliver for you meaningful answers. Now, as I mentioned some time ago, this whole field of statistics is very different from the field of probability. In some sense, all that we're doing in statistics is probabilistic calculations. That's what the theory kind of does. But there's a big element of art. You saw that we chose the shape of some decision regions or rejection regions in a somewhat ad hoc way. There's even more basic things. How do you organize your data? How do you think about which hypothesis you would like to test, and so on? There's a lot of art that's involved here. And there's a lot that can go wrong. So I'm going to close with a note that you can take either as pessimistic or optimistic. There's a famous paper that came out a few years ago and has been cited about 1,000 times or so. And the title of the paper is, Why Most Published Research Findings are False. And it's actually a very good argument why, in fields like psychology or the medical science and all that, a lot of what you see published that, yes, this drug has an effect on that particular disease, is actually false because people do not do their statistics correctly. There's lots of biases in what people do. I mean, an obvious bias is that you only publish a result when you see something. So the null hypothesis is that the drug doesn't work. You do your tests, the drug didn't work, OK, you just go home and cry. But if by accident that 5% happens, and even though the drug doesn't work, you got some outlier data, and it seemed to be working, then you're excited, you publish it. So that's clearly a bias that gets results to be published, even though they do not have a solid foundation behind them. Then there's another thing. OK, I'm picking my 5%. So when H0 is true, there's a small probability that the data will look like an outlier. And in that case, I publish my result. OK, it's only 5%. It's not going to happen too often. But suppose that I go and do 1,000 different tests. Test H0 against this hypothesis. Test H0 against that hypothesis. Test H0 against that hypothesis. Some of these tests, just by accident, might turn out to be in favor of H1. And again, these are selected to be published. So if you do lots and lots of tests, and in each one you have a 5% probability of error, when you consider the collection of all those tests, actually the probability of making incorrect inferences is a lot more than 5%. One basic principle in being systematic about such studies is that you should first pick your hypothesis that you're going to test, then get your data, and do your hypothesis testing. What would be wrong is to get your data, look at them, and say, OK, I'm going now to test for these hundreds of different hypotheses. And I'm going to choose my hypothesis to be for features that kind of look abnormal in my data. Well, given enough data, you can always find some abnormalities just by chance. And if you choose to make a statistical test, is this abnormality present? Yes, it will be present, because you first found the abnormality, and then you tested for it. So that's another way that things can go wrong. So the moral of this story is that while the world of probability is really beautiful and solid, you have your axioms. Every question has a unique answer that by now you can all of you find in a very reliable way. Statistics is a dirty and difficult business, and that's why the subject is not over. And if you're interested in it, it's worth taking follow-on courses in that direction. OK, so have good luck in the final. Well, and have a nice vacation afterwards.