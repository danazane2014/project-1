 The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. OK, so this is an important day. And Friday was an important day. I hope you enjoyed Professor Sra's terrific lecture as much as I did. You probably saw me taking notes like mad for the section that's now to be written about stochastic gradient descent. And he promised a theorem, if you remember. And there wasn't time. And so he was going to send it to me, or still is going to send it to me. I'll report I haven't got it yet. So I'll bring it to class Wednesday, hopefully. And that will give us a chance to review stochastic gradient descent, the central algorithm of deep learning. And then this today is about the central structure of deep neural nets. And some of you will know already how they're connected, what the function F, the learning function, you could call it the learning function that's constructed. The whole system is aiming at constructing this function F, which learns the training data, and then applying it to the test data. And the miracle is that it does so well in practice. That's what has transformed deep learning into such an important application. So this is on this. Chapter 7 has been up for months on the math.mit.edu slash learning from data site. And I'll add it to Stellar, because that's where you'll be looking for it. And then the second, the back propagation, the way to compute the gradient, I'll probably reach that idea today. And you'll see what it's the chain rule, but how is it organized. OK, so what's the structure? What's the plan for deep neural nets? Good. Starting here. So what we have is training data. So we have vectors, x1 to x. What should I use for the number of samples that we have in the training data? Well, say d for data. And each vector, those are called feature vectors. So equals feature vectors. So each one, each x, has like m features. So maybe my notation isn't so hot here. I have a whole lot of vectors. Let me not use the subscript for those right away. So vectors, feature vectors. And each vector has got maybe, shall we say, m features. Like if we were measuring height and age and weight and so on, those would be the features. So the job of the neural network is to create. And we're going to classify. Maybe we're going to classify men and women or boys and girls. So let's make it a classification problem, just a binary. So the classification problem is, what should we say, minus 1 or 1, which is sort of 0 or 1, or boy or girl, or cat or dog, or truck or car, or anyway. Just two classes, two class. So I'm just going to do two class classification. So we know which class the training data is in. For each vector x, we know the right answer. So we want to create a function that gives the right answer. And then we'll use that function on other data. People know, so let me write that down. Create a function f of x that gets most of, gets the class correct. In other words, f of x should be negative for when the classification is minus 1. And f of x should be positive when the classification is plus 1. And as we know, we don't necessarily have to get every x, every sample right. That may be overfitting. If there's some sample that's just truly weird, by getting that right, we're going to be looking for truly weird data in the test set. And that's not a good idea. We want the rule that we're trying to discover the rule that covers almost all cases, but not every crazy weird case. So that's our job, to create a function f of x that is correct on almost all of the training data. Yeah. So before I draw the picture of the network, let me just remember to mention the site Playground. I don't know if you've looked at that, so I'm going to ask you. Playground at tensorflow.org. How many know that site or have met with it? Just a few. OK. OK. So it's not a very sophisticated site. It's got only four examples. Four examples. And yeah. So one example is a whole lot of points that are blue, B for blue, inside a bunch of points that are another set that are O for orange. Orange, blue. OK. So those are the two classes, orange and blue. So the points x and the feature vector is here, is just the xy, the coordinates. Features are the xy coordinates of the points. And our job is to find a function that's positive on these points and negative on those points. So there is a simple model problem. And I recommend, well, just partly, if you're an expert in deep learning, this is for children. But morally here, I certainly learned from playing in this playground. So you set the step size. Do you set it or does it set? No. Yeah. I guess you can change it. I don't think I've changed it. What else do you set? Oh, you set the nonlinear activation, the nonlinear activation function. Active, I'll say, function. And let me just go over here and say what function people now mostly use. The activation function is called ReLU, pronounced different ways. I don't know how we got into that crazy thing. For this function, that is 0 and x. So the function ReLU as a function of x is the maximum, the larger of 0 and x. So it produces. The point is it's not linear. And the point is that if we didn't allow nonlinearity in here somewhere, we couldn't even solve this playground problem. Because if our classifiers were all linear classifiers, like support vector machines, I couldn't separate the blue from the orange with a plane. It's got to somehow create some nonlinear function, which is maybe the function is trying to be a good function would be a function of r and theta, maybe. Maybe r minus 5. So maybe the distance out to that, let's suppose that distance is 5. Then r minus 5 will be negative on the blues, because r is small. And r minus 5 will be positive on the oranges, because r is bigger. And therefore, we'll have the right signs, less than 0, greater than 0. And it'll classify this data, this training data. Yeah. So it has to do that. This is not a hard one to do. There are four examples, as I say. Two are trivial. It solves, it finds a good function. Well, yeah, I've forgotten. They're so trivial, they shouldn't be mentioned. And then this is the medium test. And then the hard test is when you have oranges, you have a sort of spiral of oranges. And inside, you have a spiral of blues. That was cooked up by a fiend. So the system is trying to find a function that's positive on one spiral and negative on the other spiral. And that takes quite a bit of time, many, many epochs. I learned what an epoch is. Did you know what an epoch is? I didn't know whether it was just a fancy word for counting the steps in gradient descent. But it counts the steps, all right. But one epoch is the number of steps that matches the size of the training data. So if you have a million samples, where ordinary gradient descent, you would be doing a million. You'd have a million by a million problem per step. Of course, stochastic gradient descent just does a mini batch of 1 or 32 or something. But anyway, if we had, yeah. So it's the number of, you have to do enough mini batches so that the total number you've covered is the equivalent of one full run through the training data. And that was interesting point. Did you pick up that point that in stochastic gradient descent, you could either do a mini batch and then put them back in the soup, so with replacement, or you could just put your data in some order, from one to a zillion. So here's a first x and then more and more x's, and then just randomize the order. So you'd have to randomize the order for stochastic gradient descent to be reasonable. And then take a mini batch and a mini batch and a mini batch and a mini batch. And when you get to the bottom, you've finished one epoch. And then you'd probably randomize again, maybe, if you were doing it, if you wanted to live right, and go through the mini batches again, and probably do 1,000 times, yeah, or more. Anyway, so I haven't said yet what you do, what this f of x is like. But you can sort of see it on the screen, because as it creates this function f, it kind of plots it. And what you see on the screen is the 0 set for that function. So perfect would be for it to go through 0. If I had another color. Oh, I do have another color. Look, this is the first time in the whole semester blue has appeared. OK, so if the function was positive there in this part on the blues, and negative outside that region for the oranges, that would be just what we want, right? That would be what this little playground site is creating. And on the screen, you'll see it. You'll see this curve where it crosses 0. So that curve where it crosses 0 is supposed to separate the two sets. One set is positive, one set is negative, where 0 is in between. And the point is, it's not a straight line, because we've got this nonlinear function. This is nonlinear. And it allows us to have functions like r minus 5. And so at 5, that's where the function would be 0. And you'll see that on the screen. You might just go to a playground at TensorFlow. Of course, TensorFlow is the big system. This is the child's department. But I thought it was pretty good. And then on this site, you decide how many layers there will be, how many neurons in each layer. So you create the structure that I'm about to draw. And you won't be able to get to solve this problem, to find a function f that learns that data without a number of layers and a number of neurons. If you don't give it enough, you'll see it struggling. But it's creating the 0 set tries to follow this, but it gives up at some point. This one doesn't take too many layers. And the two trivial examples are just a few neurons do the job. So that's a little comment on one website. If you know other websites that I should know and should call attention to, could you send me an email? I'm just not aware of everything that's out there. Or if you know a good convolutional neural net, CNN, that is available to practice on, where you could give it the training set. That's what I'm talking about here. I'd be glad to know, because I just don't know all that I should. OK, so what does the function look like? Well, as I say, linear isn't going to do it. But linear is a very important part of it, of this function f. So the function f really has the form. Well, so we start here with a vector of 1, 2, 3, 4. m is 5. This is the vector x, five components. OK, so let me erase that now. OK, so then we have layer 1 with some number of points. Let's say n1 is 6 neurons. Let me make this simple. I'll just have that one layer. And then I'll have the output. This will be the output layer. And it's just going to be one number. So each of these, so I'm going to have a matrix A1 that takes me from this. A1 will be, this will be 6 by 5, because I want 6 outputs and 5 inputs, 6 by 5 matrix. So I have 30 weights to choose there. And so the y that comes out is going to be y1, will be A1 times x0. So x0 is the feature vector with five components. So that's a purely linear thing, but we also want an offset vector. So that's a vector. This is then, this is the y that's coming out has six components. The A1 is 6 by 5. The x0 was 5 by 1. And then, of course, this is 6 by 1. So these are the weights. Well, these are, yeah, I'll call them all weights, weights to compute. So in this, so these are connected. The usual picture is to show all these connections. I'll just put in some of them. So in here, we have 30 plus 6 parameters, 36 parameters. And then I'm going to close this. It's going to be a very shallow thing. So that will be just 1 by 6. So we're just getting one output. So that's just a vector at this final point. But of course, the whole idea of deep neural nets is that you have many layers. So you have that 36 more realistically is in the tens of thousands. And you have it multiple times. And the idea seems to be that the first layer that you can sort of separate what layer 1 learns about the data and from what layer 2 learns about the data. Layer 1, this A1, apparently, by just looking after the computation, this learned some basic facts about the data. This learns the next A2, which would go in here, would learn more detail. And then A3 would learn more detail. So we would have a number of layers. And it's that construction that has made neural nets successful. But I haven't finished, because right now it's only linear. Right now I just have a, I'll call it A2 in here. Right now I would just have a matrix multiplication, apply A1 and then apply A2. But in between, there's a 1 by 1 action on each by this function. So that function acts on that number to give that number back again or to give 0. So in there is ReLU. In this, it becomes ReLU on each, six copies of ReLU acting on each of those six numbers. So that really, x1 comes from y1 by applying ReLU to it. Then that gives the x. So here are the y's from the linear part. And here are the x. That's the vector y1 from just a linear plus an affine map, linear plus constant. That's affine. And then the next step is component by component. We apply this function. And we get x1. And then do it again and again and again. So do you see that the function? How do I describe now the function f of x? So the learning function, which depends on the weights, on the a's and b's, is so I start with an x. I apply f1, a1 to it. Yeah, let me do this. So this is the function f of x. f of x is going to be f3, let's say, of f2 of f1 of x. 1, 2, 3, parentheses, right? OK, so it's a chain, you could say. What's the right word for a chain of functions? If I take a function of a function, which is the reason I use the word chain is that the chain rule gives the derivative. So a function of a function of a function, that's called composition, composing function. So this is a composition. I don't know if there's a standard symbol for starting with f1 and do some composition and do some composition. And now what are those separate f's? Those separate f's are the f1 of a vector would be, it includes the ReLU part, the nonlinear part, of a1 x0 plus b1. So two parts, you do the linear or affine map on your feature vector. And then you, component by component, you apply that nonlinear function. And it took some years before that nonlinear function became a big favorite. People imagined that it was better, it was important to have a smooth function. So the original functions were sigmoids, like S curves. But of course, it turned out that experiments showed that this worked even better. So that would be f1. And then f2 would have the same form and f3 would have the same form. So maybe this had 36 weights and the next one would have another number and the next another number. So we're getting, you get quite complicated functions by composition, by like e to the sine of x or e to the sine of the logarithm of x or things like that. Pure math has asked, could you get, what functions can you get? Try to think of them all. Now, what kind of functions do we have here? What can I say about f of x as a function, as a math person? What kind of a function is it? So it's created out of matrices and vectors, out of a linear or affine map, followed by a nonlinear, by that particular nonlinear function. So what kind of a function is it? Well, I've written those words down up here. And f of x is going to be a continuous piecewise linear function. Because every step is continuous, that's a continuous function. Linear functions are continuous functions. So we certainly have, we're taking a composition of continuous functions, so it's continuous. And it's piecewise linear, because part of it is linear, and part of it is piecewise linear. So this is some continuous piecewise linear function of x, x in m dimensions. So one little math question, which I think helps to understand, to swallow the idea of a chain, of the kind of chain we have here of linear followed by ReLU. So here's my question. This is the question I'm going to ask. And by the way, back propagation is certainly going to come Wednesday rather than today. That's a major topic in itself. So let me keep going with this function. Could you get any function whatsoever this way? Well, no, you only get continuous piecewise linear functions. That's an interesting case. Let me just ask you, while one of the exercises says if I took two continuous piecewise linear functions, do you have the next 20 minutes or an attempt to give us a picture of the graph of a piecewise linear function? So say a function of two variables. So I have m equal to 2. And I draw its graph. OK, help me to draw its graph. So this will be a graph of f of x1, x2. And it's going to be continuous and piecewise linear. So what does its graph look like? That's the question. What's the graph of a piecewise linear function look like? Well, it's got flat pieces. In between the change from, I do say piecewise. That means it's got different pieces. But within a piece, it's linear. And the pieces fit with each other because it's continuous. So I visualize the, well, it's like origami. This is the theory of origami, almost. So right, origami, you take a flat thing and you fold it along straight folds. So what's different from origami? Maybe not much. Well, maybe origami allows more than we allow here. Origami would allow you to fold it up and over. So origami would give you a multivalued thing because it's got a top and a bottom and other folds. This is just going out to infinity in flat pieces. And the question will be, how many pieces? So let me ask you that question. How many pieces do I have? You see what I mean by a piece? So I'm thinking of a graph that has these flat pieces. And they're connected along straight edges. And those straight edges come from the ReLU operation. Well, that's got two pieces. Actually, we could do in 1D, we could count the number of pieces pretty easily. So what would be a piecewise linear? Let me put it over here on the side and erase it soon. So here is M equal 1, a continuous piecewise linear F. I'll just draw its graph. So it's got straight pieces like so. Yeah, you've got the idea. It's a broken line type. Sometimes people say broken line, but I'm never sure that's a good description of this. Piecewise linear continuous. So it's continuous because the pieces meet. And it's piecewise linear, obviously. So that's the kind of picture I have for a function of one variable. Now, my question is, as an aid to try to visualize this function in 2D, is to see if we can count the pieces. See if we can count the pieces. Yes. So that's in this notes. I found it in a paper by five authors for a meeting. And so actually, the whole world of neural nets, it's the conferences every couple of years that everybody prepares for, submits more than one paper. So it's kind of a piecewise linear conference. And those are the big conferences. So this is the back propagation section. And I want to look at the. So this paper by Kleinberg and four others. Kleinberg is a computer science guy at Cornell. He was a PhD from here in math. And he's a very cool and significant person. Not so much on neural networks as just this whole part of computer science. So anyway, they and other people, too, have asked this same problem. Suppose you have, suppose I'm in two variables. And suppose, so what are you imagining now for the surface of the graph of f of x and y? It has these lines, fold lines. I'm thinking it has fold lines. So I could start with a complete plane. And I fold it along one line. So now it's like ReLU. It's one half plane there going to a different half plane there, everybody with it? And now I take that function, that surface, which just has two parts. And I put in another fold. OK, how many parts have I got now? I think four. Am I right? Four parts? Yes, because this will be different from this, because it was folded along that line. So these will be four different pieces. They have the same value at the center there. And they match along the lines. But there's, so the number of flat pieces is four for this. So that's with two folds. And now I just want to ask you, with m folds, how many pieces are there? Can I get up to three folds? So I'm going to look for the number of folds. So let me just use a, get a notation, maybe r. r is the number of flat pieces. And m is the dimension of x. In my picture, it's 2. And n is the number of folds. Folds. So let me say it again. I'm taking a plane. I'll fold it, plane, because the dimension was 2. I'll fold it, fold it n times. How many pieces? How many flat pieces? So this would be an essential step in understanding how close the function, what freedom you have in the function f. For example, can you approximate any continuous function by one of these functions f by taking enough folds? Seems like the answer should be yes, and it is yes. So that's one big, for pure math, that's one question. Is this class of functions universal? So the universality theorem would be to say that any function, sine x, whatever, could be approximated as close as you like by one of these guys with enough folds. And over here, we're kind of making it more numerical. We're going to count the number of pieces just to see how quickly do they grow. So what happens here? So I have four folds now. This right now, I have n equal 2. m is 2 here in this picture. And I'm trying to draw the surface. And here, I've put in 2. Did I take n? Yeah, two folds. And now I'm going to go up to three folds. So let me fold it along that line. How many pieces have I got now? Let's see. Can I count those pieces? Is it seven? So what is a formula? What if I do another fold? What happens? Yeah, let's pretend we do another fold now. Yeah? AUDIENCE 2. Do the power of n by itself? Yeah, well, maybe that's going to be it. It's a kind of nice question, because it asks you to visualize this thing. So what happens? How many of those lines will be, if I put in a fourth line, how many new folds do I create? That's kind of the question. And I'm assuming that fourth line doesn't go through any of these points. It's sort of in general position. Yeah. So I put in a fourth line. There it is. OK, so what happened here? How many new ones did it create? How many new ones did it create? Let me make that one green, because I'm distinguishing. That's the guy that's added after the original. We had seven. We had seven pieces. And now we've got more. Was it seven? It was, wasn't it? 1, 2, 3, 4, 5, 6, 7. But now how many pieces have I got? Or how many pieces did this new line create? We want to build it up, use every recursion. How many pieces did this new line fold and create a one new piece there, right? One new piece there, one new piece there, one new piece there. So there were four new pieces. OK. Yes. So there's some formula, right, that's going to tell us that. And now what would the next one create? Well, now I have 1, 2, 3, 4 lines. So now I'm going to put through a fifth line. And that will create a whole bunch of pieces. I'm losing the thread of this argument. But you're onto it, right? Yeah. So any suggestions? Yeah. Yeah, I think you add, essentially, the number of lines that you have each time you add a line at most. OK, yes. That's right. So there is a recursion formula that I want to know. And I learned it from Kleinberg's paper. And then we have an addition to do. So the recursion will tell me how much it goes up with each new function. And then we have to add. OK, so the recursion formula, let me write that down. So this is R of n and m that I'd like to find a formula for. It's the number of flat pieces with an m-dimensional surface. Well, we're taking m to be 2. And n folds. And let's just, so n equal 1, 2, 3. Let's write down the numbers we know. With one fold, how many pieces? Two, good. So far, so good. With one fold, there were two pieces. So this is the count R. And then with two folds, how many? Oh, we've gone past that point. So can we get back to just those two? Was it four? OK, thanks. Now, when I put in that third fold, how many did I have? Without the green line yet. Seven, was it seven? And when the fourth one went in, that green one, how many have I got in this picture? So the question is, how many new ones did I create, I guess? So that line got chopped into that piece, that piece, that piece, that piece. Four pieces for the new line. Four pieces for the new line. And then each of those pieces added a flat bit, because that piece from here to here separated these two, which were previously just one piece, one flat piece. I folded on that line. I folded on this. I folded there. I think it went up by 4 to 11. So now we just have to guess a formula that matches those numbers. And then, of course, we really should guess it for any m and any n. And I'll write down the formula that they found. It involves binomial numbers. Everything in the world involves binomial numbers, because they satisfy every identity you could think of. So here's their formula. R with n folds, and we're in m dimensions. So we've really, in our thinking, had m equal to 2. But we should grow up and get m to be five dimensional. So we have a five dimensional. Let's not think about that. So it turns out it's binomial numbers n0, n1, up to nm. So for m equal to 2, which is my picture, it's n0 plus n1 plus n2. And what does that n2 mean, for example? That's a binomial number. I don't know if you're keen on binomial numbers. Some people, their whole lives go into binomial numbers. So it's something like, is it n factorial divided by n minus 2 factorial and 2 factorial? I think that's what that number means. That's the binomial number. So this would be, I go up to. So at this point, I'm hoping to get the answer 7, I think. Right now, I've gone up to m equal to. I'm in m equal to. I've gone up to 2. Yeah. So I think, yeah, I've obviously allowed for three cuts. And the r, when we had just three, was 7. So is that, is this, so this is now I'm taking n to be 3. And I'm hoping for hope answer is 7. So what is 3? What is 3? So I add these three things. So what is 3? The binomial number 3 with 2. I've forgotten how to say that. I'm ashamed to admit. 3 choose 2. Thanks. I knew there was a good way. So what is 3 choose 2? Well, put in 3 and 2. It's in there already. So that'd be 6 over 1 times 2. This would be 3. Would that be 3? 3 choose 1. And what is 3 choose 1? How do you know that? You're probably right. 3, I think, yeah? Oh, yeah, probably a theorem that if these add to 3. Yeah, so I'm doing n equals 3 here. OK, so yeah, I agree. That's 3. And what about n choose 0? What's that? You have to live with 0 factorial. But that 0 factorial is by no means 0. So what is 0 factorial? 1. Yeah. I remember when I was an undergraduate having a bet on that. I won, but he didn't pay off. So yeah. So 3, this is 3 factorial over 3 factorial times 0 factorial. So it's 6 over 6 times 1. So it's 1. Yeah, so 1 and 3 and 3 make 7. So that proves the formula. Well, it doesn't quite prove the formula. But the way to prove it is by an induction. And I'll just, if you like this stuff, the recursion that you use induction on, which is just what we did now, what we did here. Here comes in a number 4. And it cuts through. Yeah, and then we just counted the four pieces there. So yeah, so let me just tell you what the R of n and m, the number we're looking for, is the number that we had with one less cut. So that's the previous count of flat pieces. Plus the number that was here was 4, the number of pieces that cut that. And that's R of n minus 1, m minus 1. Yeah. And yeah, I won't go further. Time's up. But that rule for recursion is proved in the section 7.1, taken from the paper by Kleinberg and others. Yeah, so OK. I think this is, I don't know what you feel. For me, this gave me a better feeling that I was understanding what kind of functions we had here. And so then the question is, with this family of functions, we want to choose the A's and the weights, the A's and the B's, to match the training data. And so we have a problem in minimizing the total loss. And we have a gradient descent problem. So we have to find the gradient. So that's Wednesday's job. Wednesday's job is to find the gradient of F. And that's back propagation. Good. Thank you very much. That's 7.1 is done.