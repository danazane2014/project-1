 OK. So let's get started. This is first lecture for the course, Introduction to Functional Analysis. OK, so let me give you a brief preview or a few words about what functional analysis is or initially aimed to do. So by this point, you've taken, or at least what the prerequisites are supposed to be, you've taken linear algebra, you've taken calculus. And what these subjects allow you to do is solve problems where you have finitely many independent variables, if you like. You're working in finite dimensions. So you always have, for example, in calculus, you're trying to find the min or max of a function of one, two, three, or four variables. Or in linear algebra, you're trying to solve a set of linear equations, but there's five equations and five unknowns. So there's always finitely many independent variables. Now that allows you to solve a lot of fun problems of how fast water is leaking from a cone. I think that's one of the problems you solve or something of that sort. But then when you move on in life, you come across ODEs and PDEs and other types of minimization, maximization problems, where now, if you'd like, the set of independent variables is no longer finite dimensional. So let's think of the number of your independent variable as being a member of some vector space. So when we were talking about calculus, functions of one, two, or three variables, these are functions of r, r2, r3, so on and so on. But it turns out that if you want to consider, for example, what's the shortest curve between two points, this is a natural functional, meaning, well, this is terminology that means now the argument is a function, that the points, your independent variables, are curves, are functions. And it takes, for a vector in r3, say, it takes three numbers to specify a vector, the three coordinates. How many numbers do you need to specify, say, a continuous curve on the interval, say, 0, 1? Well, you need infinitely many numbers. You need to know the graph of that curve. So functional analysis, in short, was built to be able to start solving problems where the vector spaces are not necessarily finite dimensional. And as we'll see in the problems that we work through and the situations that pop up, this arises quite naturally for very particular, I mean, not particular, but for concrete problems. This is not just some sort of academic exercise. This whole subject grew out of trying to understand particular concrete problems involving PDEs and minimization and optimization of now functions of functions. That was the original terminology, functions of functions, where now the vector space is some space of functions, not just spaces of, say, three dimensional vectors or two dimensional vectors. And that's the name functional. OK, so that's a few words about how this subject grew. What's kind of the point? So let's start getting into specifics. So again, I'm going to be using a lot of terminology that comes from linear algebra and the real analysis course, 18.100B. But at the start, I'll be reminding you of what some of these terms that I'm using mean. But as the course goes on, I will stop redefining terms that you should have seen in real analysis or linear algebra and just use them. OK, so the first topic that we're going to deal with are normed spaces. Normed spaces are kind of the central objects or starting point in functional analysis, which are the analog of R2, R3, and so on. So what's the setup? Let V be a vector space over R or even C, so it could be a complex vector space. Either of these spaces we'll usually denote by a boldface K. So what does this mean? So again, this is one of those points where I'll just quickly remind you what a vector space is. And V comes with two operations, plus and scalar multiplication. So plus going from V cross V into V, which we denote by two vectors in V. They get mapped to the new vector, which I denote V1 plus V2. And then I have scalar multiplication from the set of scalars cross V into V. And this goes alpha V gets mapped to alpha times V. So you have these two operations, and they satisfy certain conditions, assumptions, relations between them, which are part of the axioms of a vector space, which you can read in the last section of the notes if you want to refresh your memory. And so V is a vector space, has these two operations satisfying certain set of axioms. And so for example, familiar old examples, R2, RN, and then of course C, the set of n tuples of R or C. But here's another simple example, C01, which I'll remind you this notation here means the set of functions from 01 into, let's say, their complex value just to fix a field of scalars to work with such that F is continuous, meaning it's continuous at every point. This is also a vector field because the sum of two continuous functions is continuous. And if I take a scalar multiple of a continuous function, then that's also continuous. And then these operations satisfy the axioms that you need for vector space. But there really is a big, pun intended, difference between these spaces here and these spaces here or that space there. And what is the difference? The size. Now in analysis, size was, you kind of had maybe one or two different notions of size you were introduced to depending on how much analysis you've seen, but one was cardinality. That's not what I'm talking about when I mean size. What I mean is the following. I mean the dimension of these spaces. So let me recall the following definition that we say a vector space V is finite dimensional. And these were a lot of the vector spaces you were first introduced to. If every linearly independent set is in fact a finite set. And so let me again, since I'm using some of these words to help you recall, what does this mean in math? This means for every set E that is linearly independent, meaning which have the following properties so that if I take any elements in E that, so E satisfies that if I take any many elements of E, the assumption that there's a linear combination of them giving zero implies that all of these scalars must be zero. So this here is the definition of being linearly independent for all E satisfying this condition. So this is kind of poorly written, but I hope you follow. This is the definition of linearly independence. Then for every set that's linearly independent in this set E is finite in the sense of cardinality. In the sense there's only 100 elements in there or not. So this is finite dimensional and say V is infinite dimensional if V is not finite dimensional. So some of you I saw have taken a course from me before. I tend to use a lot of abbreviations when I write, but typically these abbreviations are pretty clear what they mean if you just sound it out. So vector space V and these infinite dimensional guys, these are the guys we're going to be dealing with a lot in this course. The finite dimensional ones you dealt with in linear algebra, maybe you used a few, you had a few infinite dimensional examples if you were looking at examples of vector spaces, but these infinite dimensional vector spaces, these are the type of guys or the type of vector spaces we're now going to solve linear equations on. And in some sense do calculus on. That's not quite true, but we're going to use calculus and some tools to be able to say some things about linear equations on these infinite dimensional spaces. But they won't just be any type of infinite dimensional space and I'll say what type we're looking at in a minute. So finite dimensional, infinite dimensional. So the first set of examples, R1, R2, RN, CN, so on, those are finite dimensional spaces and the dimension is N if I had defined what the dimension is. What is an example of infinite dimensional? Well you can probably guess since I led up to it with saying there's a big difference between this one and RN and CN, the space of continuous functions on the interval 0, 1, this is infinite dimensional. Why is that? This is because the set, like E, given by the functions Fn of x equals x to the n, here n is a natural number, or 0, this is a linearly independent set. I'll let you think about why that is. And you see that it's not a finite set. It contains infinitely many different functions. So this is a linearly independent set. So like I said, what we're going to be dealing with is how to handle solving linear equations or questions about analysis that we'll need to solve other problems on these infinite dimensional spaces. Unlike in the past where we did analysis on finite dimensional spaces. When the types of things you proved in the analysis class were something like the Heine-Borel theorem that closed and bounded subsets of RN are compact, meaning every bounded sequence has a convergent subsequence. This is, in fact, something you proved to show that every continuous function on a closed and bounded set has a min and a max in that set. But that statement that I just said about the Heine-Borel theorem, that is not true once we get to infinite dimensions. And so if we want to be able to solve problems, we'll have to develop some machinery to get around that. It is one of the main issues that arises when you move from doing analysis on finite dimensions to infinite dimensions. So mathematically, I haven't said much, but I have been trying to gin up the subject to make sure you stay engaged. So we have vector spaces, but to do analysis, we need some sort of notion of how close things are. And to do that, we introduce the notion of a norm. So a norm on a vector space V. If I don't write vector space V, you should say to yourself, this capital V is a vector space. A norm on a vector space V, this is a function. This is going to be an object that generalizes length. So it's a function from V to a set of non-negative numbers with three properties that we kind of associate to length. One, that the norm of V is 0, implies, well, I should say, if and only if P equals 0. Two, if I take V and I multiply it by a scalar, and then I take its length, I should get something like that scalar times the length of the vector. If I take a vector, multiply it by 2, I should get twice times the length of the vector. So this is expressed by this, and this is for all lambda in my field of scalars, and for all V and V. So this property here is referred to as homogeneity. This property here is referred to as definiteness. I don't know if I'm spelling that right, but definiteness. And then the third property is that it satisfies the triangle inequality. This is that for all V1, V2, and V, the norm of V1 plus V2, this is less than or equal to the norm of V1 plus V2. And any vector space that has a norm on it, we call a normed space. The norm is what we call a normed space. And this thing here, I usually refer to as the triangle inequality. So a vector space with a function on it that satisfies these three properties we call a normed space. So like I said in my past classes, whenever you see a decent definition or something with substance, you should do examples. We'll do that in just a minute after I give a few more definitions. So let me just add to this one. This was the definition of a norm. A semi-norm wants to be a norm, but it's not quite, is a function, which I'll also denote with these two parallel lines on each side, is a function satisfying homogeneity and the triangle inequality, but not necessarily positive or definiteness, or positive definiteness is also what that goes by, satisfying 2 and 3, but maybe not necessarily 1. Again, semi-norms kind of pop up in a natural way, and I'll give you an example in just a second. So first off, we have this notion of length in a vector space, which is a norm. And if we're given a norm on a vector space, we can associate a metric. So remember, a metric, so from real analysis, I want you to recall that a function, d, on a set, if x is a set, a function d, x cross x into 0 infinity, is a metric if you have three conditions satisfied, a, so the distance between a point in itself, or let me write it this way, the distance between two points is 0 if and only if x equals y, b, for all x, y in the set x, d x, y equals d y, x, this is symmetry of the distance, and you have the triangle inequality for the distance for all x, y and x, d for all x, y and z, and x, d x, y is less than or equal to the distance from x to z plus the distance from z to y. So if I have a vector space and I have a norm on it, I can turn that space now into a metric space, and this metric that I'm about to write down is usually referred to as the metric induced by the norm. So our first little kind of mini-theorem here, if I have a norm on a vector space, then d of, let me use the same, if I define a function d v w to be simply the length of v minus w, so for elements of v and w in the vector space, defines metric on v, and this metric we refer to as the metric induced by the norm. And this is not difficult to prove, basically 1, 2, and 3 imply respectively a, b, and c. The first property of a norm implies a, this is pretty clear, the distance between v, w is 0 if and only if v minus w equals 0, which is if and only if v equals w, that gives us part a. b we get from 2, since by 2, v minus w is equal to minus 1 times w minus v equals, now we pull the scalar out and take its absolute value, so since by 2 we have the length of v minus w equals the length of w minus v, this implies b, and then c just follows again immediately from the triangle inequality 3 by just adding and subtracting a third element. So let me just write 3 implies c immediately. So when we have a norm, we get a notion of a metric, a notion of distance between two vectors in our vector space by just taking the length of the difference of them. So again, this is supposed to be an analog of what we see in R and Rn in general. So for example, let me just recall this. So now let's look at a few norms. Instead of n-tuples of Rn or Cn, where we have the Euclidean norm, here if I have an n-tuple given by x, so let me put a 2 here to denote this norm, then the Euclidean norm of this vector, so this guy is in Rn or Cn, then its Euclidean norm is given by the sum of i equals 1 to n xi length squared 1 half. And that gives you the standard notion of length and distance between points that you've dealt with in Euclidean space. But that's not the only norm you could have on these spaces that you dealt with before. Another one, let me put an infinity here. This norm is the max between 1 and n of xi. So to measure the length of a vector, I take this to be the magnitude of the largest entry in that vector. And in general, there's a whole family of norms I could put on Rn or Cn. Let me put a p here. This is the LP norm, little lp norm, is the sum of the p-th power of the xi's raised to the 1 over p. Of course, you need this 1 over p for homogeneity to work out and also the triangle inequality. And this is for 1 less than or equal to p less than infinity. I didn't write infinity there because that doesn't make sense, although you can actually prove that if I take a fixed vector and I let p go to infinity, then this quantity here converges to this quantity. It's not hard to show. So let me quickly draw you a quick picture of what the unit balls look like in R2, say, with the different norms. So let me recall that if I have in a metric space a metric, then Bxr, this is a set of all y and x so that the distance from x to y is less than or equal to r. Now you know what the ball looks like for the Euclidean norm. This is just a circle and filled in, of course. I'm not going to fill this in, so now what I'm looking at is, and I'll put a 2. This is the ball centered at 0, radius 1, so everything inside. What about for the infinity norm? Let's say I want to look at what does this look like? This in fact is square. And what about, let's do one more, about the little l1 norm, which is just the length of the magnitude of the entries, the length of the absolute value of the entries. So all these go through these points here on the axis. This ball, so first off, everything inside the blue is the l infinity ball. Everything inside the white is that little l2 ball. The little l1 ball is everything inside of this square, which is now tilted. And every other little lp ball is in between the yellow and the blue, and if you take p goes to infinity, then that ball converges in a certain sense to this l infinity ball, which is in blue. So you see, changing the norm, even on these finite dimensional spaces, changes the geometry of the balls, if you like. But not in too drastic of a way, meaning if I take a large enough l1 ball, that will swallow up an l infinity ball, and therefore the two balls are kind of, and I can take the size of that ball to be maybe of size three, and so the balls are kind of the same. One can always be sandwiched in the other. I'll talk a little more about that when we talk about equivalent norms, at least in the problem sets. Okay, so that's an example of norms on a finite dimensional vector space. Let's look at another norm. Let's say, let's take a metric space. So I remember we have, so this is just any old metric space. And now I'm going to define a vector space, c lower infinity x, this is defined to be the set of all continuous functions on this metric space. Okay, remember if we have a metric space, we have a notion of continuous functions on it. Such that, what? So these are, so again to fix this, let me just clarify where it's going. F goes from x to, let's say, c, such that f is continuous and f is bounded. Meaning the image of x under f is a bounded subset of c. All right? So just so you can connect this with something I just wrote down a minute ago, the set of all bounded functions, continuous functions on zero one, this is just the set of continuous functions on zero one, because we know continuous functions on a closed and bounded interval are bounded. So I don't have to say bounded whenever I write this. Okay, so I have this space of continuous functions on a metric space, which are bounded. And I'm going to define a norm on this. So this is a vector space. As any sum of two continuous functions is continuous, scalar multiple times a continuous function is continuous. So, and again, those two operations satisfy the axioms of a vector space. And I can define a norm on this space. And I claim that, what do I use here, then if I define an infinity norm again, which will look similar to what I wrote up there, as this is the soup of all x and capital X of u of x, then this is a norm on this space of continuous, bounded continuous functions. Okay, so one and two are pretty easy to see from the definition. So properties one and two are easy to see. For the triangle inequality, well, that follows essentially from the triangle inequality for C. These are C-valued, complex-valued functions. If you like, replace it with real-valued functions. That makes you feel better in the first lecture, although we'll need complex numbers eventually. So, let's check that this function satisfies the triangle inequality and therefore is a norm. If u and v are two bounded continuous functions on x, then for all x and x, if I take ux plus vx, this is less than or equal to, by the triangle inequality for C, the absolute value of u of x plus v of x. Again, u of x is a complex number, and so is v of x. So this is by triangle inequality. But now, this, for any old x, is always bounded by the supremum of that over all values. So let me write. So u of x, for any fixed value of x, is always bounded by the supremum over all x's in the capital X, which is the norm of u. So what I've shown is that for all x in capital X, the absolute value of u of x plus v of x is bounded by this number. And therefore, this number is an upper bound for the set of absolute values of these guys. And therefore, the supremum, which implies that, which is the least upper bound of all these quantities as x ranges over x, is less than or equal to this number here. And therefore, we have the triangle inequality for this function. And therefore, this defines a norm, which I'll often refer to as the uniform norm or L infinity norm, just because there's an infinity. But the content should be clear on what I'm talking about. I mean, this is not inconsistent with what I wrote down, because Rn, that's just a set of, well, OK, never mind. Let me stop talking before I get myself twisted in a knot. So what does convergence mean in this norm here? We know what convergence means in the kind of Euclidean or any of these norms. It means the points are getting together. The fixed points in the plane are starting to get closer and closer together, at least in R2 or C2. What about here? Now, so let me just note that, so remember, un converges to u in this space of bounded continuous functions. What does this mean? This means the distance between un and u goes to 0 as n goes to infinity. So here I'm talking about what is convergence of a sequence of elements of this space mean. So that means that the distance between un and u goes to 0 as n goes to infinity. And the distance, remember, is defined in terms of the norm. So convergence in the space of bounded continuous functions just means this. But in terms of something covered in past analysis class, what is that equivalent to? I'll write it out. This means for all epsilon positive, there exists a natural number n such that, now this is the sup of u of x for all, or sup of un of x minus u of x for all x and x. So I can write such that for all n bigger than or equal to n for all x and x, un of x minus u of x is less than epsilon. But that's just a definition of uniform convergence uniformly on x. So the point of this little note is that convergence in this norm or in this metric, I'm going to use norm and metric interchangeably because this metric is induced by this norm. So convergence in norm in the space of bounded continuous functions is the same as saying that this sequence of functions converges to this function uniformly on x. So I hope that's clear. When you look, when you, so maybe I should say this now instead of in the eighth lecture. But really take the time to actually watch these lectures for two reasons. One, I'm actually here recording them. So instead of just saying read this and ask me if you have any questions. So I'm giving you some more insight than just what's in the notes. And two, it keeps you engaged. So you should treat these as you actually being there. Have your notebook, take notes as I lecture. The great thing is that you can pause and rewind. This space of continuous functions, we have that norm. OK so some more examples of norm spaces is, so I was calling that little lp norm. But the little is not necessarily little. So the actual little lp space that I will typically refer to, this is going to be the space of all, this is the space of all sequences now. So the vectors in this space are sequences. The points in this space are sequences. Such that, so call this thing element A. So A is a sequence. So this is a set of all sequences that have lp norm that's finite. And what is the lp norm in this case? Well it's a natural generalization of that guy, where the lp norm is equal to sum j equals one to infinity for one p between one and infinity. And then the l infinity norm is just sup over j. All right. So little lp stands for the space of sequences with finite lp norm, or you could say they're lp summable. Their p-th power is summable. So let me just kind of state a silly example. The sequence one over j, j equals one to infinity. This is in little lp. We're all p bigger than one, but not for p equals one, because then we get the harmonic series. Now why, first off, why the triangle inequality holds even in the finite dimensional case, and why this is an actual vector space is non-trivial. So you shouldn't be able to actually see, say, oh, OK, that makes sense. It satisfies the triangle inequality. It's not clear. It's non-trivial that this is, in fact, a norm. This one's easier to see, but it's not clear for p bigger than one that this is a norm. And then therefore, little lp and that the sum of two guys in little lp are in lp, so that this is an actual vector space, and then we have the triangle inequality so that this is a norm. That'll be in the exercises. But just take me at my word that this is indeed a vector space. If I take two sequences that are in little lp, meaning their p-th power is summable, then their sum, entry by entry, is also in little lp and so on, and that this function here defines a norm on this space, little lp. So just accept that. And so now we're not interested. So we've kind of gone a little bit, narrowed down our spaces we're interested in a little bit more. So we've gone from general infinite dimensional vector spaces now to normed spaces being our interest, what we're interested in. But we're not exactly interested in just any normed vector space. The central objects in functional analysis that we're interested in are kind of the analogs of Rn. Now what property that Rn and Cn have is that their metric, that this metric that you have on these sets is complete, that Cauchy sequences always converge. And this is our next narrowing down of the spaces we're interested in. And these have a special name. So these are called Banach spaces, after Stefan Banach. So normed space, so a vector space with a norm, is a Banach space if it is complete with respect to the metric induced by the norm. So we have a normed space. We have a metric that's associated to that by defining the distance between two guys by that equation up there. And so we say it's a Banach space if that metric is complete, meaning Cauchy sequences in that space with respect to this metric converge in the space. Now in first year analysis, you learn that a set of rational numbers, they are not complete. They are Cauchy sequences which do not converge to a rational number. Every real number you can write as a limit as finitely many decimals. So square root of 2 will be a number where you can form a Cauchy sequence of rational numbers converging to it. But it's not a rational number. So the rational numbers are not complete. But R is complete. And in general, we give a name to those normed spaces such that this metric is complete. We call those Banach spaces. So let me. So examples which you saw at least for the Euclidean norm and should be able to prove on your own, assuming the triangle inequality for the little lp norms, these are complete with respect to any of the little lp norms. Now let's do a non-trivial one. Let's show that the space of bounded continuous functions on a metric space is complete. So let's make this a theorem. If x is a complete metric space, then it is a Banach space. BSP, that's my abbreviation for Banach space. So for a complete metric space, the space of bounded continuous functions on x is a Banach space. We've already shown that that function over there defines a norm on it. So I'm saying it's complete with respect to that norm. Cauchy sequences always converge in this space. So let me just write this out. We want to show that every Cauchy sequence u n in the space C of bounded continuous functions has a limit in the space of bounded continuous functions. So let's take a Cauchy sequence. And the way this proof is going to work is the way essentially really all of the proofs of showing something is a Banach space works is you take a Cauchy sequence, then you'll be able to come up with a candidate for the limit. And then your job is to show two things, that that candidate is in the space itself, and then that the convergence happens. And sometimes those two come together, or it can be done at the same time. So and you'll see what I mean. Let u n be a Cauchy sequence in C infinity in the space of bounded continuous functions. First off, I claim that this forms a bounded sequence in this space. This is a fact from metric space theory, but I'll write it out again. Then there exists a natural number n0 such that for all n bigger than or equal to n0, the difference between u n0 and u, so let me see, for all nm bigger than or equal to n0, u n minus u m in the infinity norm is less than 1. So what I'm first going to do, I'm first going to show that this sequence of functions are bounded in this space. Each of them are, of course, bounded, but I'm saying that they form a bounded sequence in this space. Then, let's see, how do we write this? For all n bigger than or equal to n0, u n in norm, this is less than or equal to u n minus u n0 plus u n0, and this is less than 1 plus u n0. So for all n bigger than or equal to this fixed number n0, u n in infinity norm are bounded by 1 plus the norm of this fixed guy. Then for all in a natural number, the norm of u n is less than or equal to, if I put u 1, right? Now if n is bigger than or equal to n0, then this is less than or equal to this guy, so it's certainly less than or equal to some non-negative things plus this guy. Meanwhile, if n is less than n0, then the norm of it is less than or equal to one of these norms that appear here, which is also, again, less than or equal to this entire number that I wrote down here. And let me define that to be this number b. So I've shown for all natural numbers n, the norm of u n is bounded by b. So this forms a bounded sequence in the space of bounded continuous functions. You have to keep track of where this bounded, where I'm saying this bounded, is taking place. Each of these functions is bounded, is a bounded function. What I'm saying here is that they form a bounded sequence in this space. So let me make a note of this. This is bounded by this. All right, now, what do we know? And let me, in fact, I should have written this out over here, but let me write it out again. What does it mean for this sequence to be Cauchy in this space? This means for all epsilon positive, there exists a natural number n such that for all n m bigger than or equal to n, u n minus u m in this uniform norm is less than epsilon. Now since for all x, I have that u n of x minus u m of x, an absolute value is less than or equal to the sup over all x's in capital X, which is just the uniform norm, the L infinity norm on this space. And I am assuming it's Cauchy, so it satisfies this property. I get that for all x and x, the sequence now of complex numbers, u n of x. So this is now just a sequence of complex numbers. It's the value, I take x, I stick it into u sub n. I have now a sequence of complex numbers. This is Cauchy's sequence. All of this may seem a little bit weird at first, but after I finish this proof, do it again now for little l infinity. And you'll start getting the hang and seeing how the arguments go. So for every x in capital X, u n of x. So that's now a sequence of complex numbers. And yeah, I thought I didn't need it to be complete. I don't know why I wrote it down. Any metric space, if x is a metric space, then OK. All right, so for each x in the metric space, u n of x, which is now forming a sequence of complex numbers, this is a Cauchy sequence. But the space of complex numbers, this is a complete metric space. And therefore, for each x, this sequence has a limit. So by completeness of C, for all x in capital X, this sequence u n of x has a limit in C. And now I define what will be my candidate function, u of x to be this pointwise limit. You limit as n goes to infinity of u sub n of x. So in fact, in a few words, if you remember what these words mean, what we've shown is that every Cauchy sequence in the space of bounded continuous functions has a pointwise limit. Now what we're going to show is that this guy is, in fact, in the space of bounded continuous functions, and that we have convergence of this sequence of functions to u in the space C infinity x, in the space of bounded continuous functions. We've only defined this guy as the pointwise limit. So as the pointwise limit of these guys. Then for all x in capital X, the absolute value of u of x is equal to the limit as n goes to infinity. So the absolute value of the limit, but since this converges, this is equal to the limit of the absolute values. And each of these guys are bounded by b. They're bounded by the infinity norm, which is bounded by b. So this is less than or equal to b. And thus, so this is a bounded function at least on this metric space. So now we're going to achieve two things at once. We're going to show that it's continuous and that we have convergence in this space by showing it is, by showing this L infinity norm of the difference goes to zero of u minus u n. So first we're going to show that, so think of this just now as a function, not necessarily a norm. So maybe I'm being too careful. I'm just going to say now we're going to show that this quantity here goes to zero as n goes to infinity. And how do we do this? Well, since we're just going to do this the old fashioned way of let epsilon be positive and show that we can choose an n such that this is less than or equal to epsilon. I know in the definition you're supposed to have less than epsilon, but less than or equal to is good enough. So let epsilon be positive since this sequence is Cauchy in this space. This implies there exists a natural number n such that for all n, m bigger than or equal to n. I have that u n minus u m L infinity is less than, all right, let's make it epsilon over two. And for all n, m bigger than or equal to m, this means u n of x, so let x be in capital X. We now want to show that for all little n bigger than or equal to capital N, in fact, u n minus u in this norm is less than or equal to epsilon over two. For all n, m bigger than or equal to n, I have that u, which is less than or equal to u n minus u m. And therefore, if I take the limit as m goes to infinity, remember u of x is the pointwise limit. I fixed x in capital X. I get that for all n bigger than or equal to m, u n of x minus u of x is less than or equal to epsilon over two. So what have I shown? I've shown for all n bigger than or equal to capital N, and this capital N came from this condition, not anything having to do with x. It came from this condition. I have u n of x minus u of x is less than or equal to epsilon over two. And therefore, the soup over all x's is less than or equal to epsilon over two, which is less than epsilon. Thus, u n converges to u, or I should say, as n goes to infinity. Now what's the last step? I have this candidate u. u n's converge to u with respect to this sense. I need to conclude also that u is an element of the space of bounded continuous functions. I know it's bounded. Why is it continuous? Well, since u n minus u goes to zero, this implies that u n, by what we remarked a little bit earlier, means u n converges to u uniformly on x. And since u is the uniform limit of a sequence of continuous functions, that implies that u is continuous. So let me just reiterate what we've done. In sequence, we've shown that u x is bounded. We've then shown that the soup over all x and x, so I should have put that in yellow. We've shown convergence to u with respect to this norm. And we've shown u is, in fact, in the space. So therefore, u is in. This space is complete, and therefore, a Banach space. So the first time you see that proof, and again, this is kind of how all the proofs of something being a Banach space goes. When you see that for the first time, it's a little weird. But this will be in the exercise, and you can get a jump start on that by looking at maybe the simplest one. Well, I still have space over here. So little l p, this is a Banach space for all p between 1 and infinity. Another space, which maybe try your hand at this one instead of little l infinity, because at least something's a little different. Little c 0, which is the set of sequences in little l infinity. So each element of c 0 is a sequence, a bounded sequence, such that limit j goes to infinity of aj equals 0. This is also a Banach space. So I encourage you to take this example of bounded sequences that converge to 0. First off, it's pretty clear it's a vector space. It's actually a subspace, and I'll get to subspaces of Banach spaces next lecture. So it's a Banach space with the l infinity norm. So again, how would you prove that this is a Banach space? You would take a co-sheet, so you have to start thinking of, again, these Banach spaces, these spaces you're looking at can be made up of complicated things. Little l p, this is a space of sequences. So each point in the space is a sequence. It's a sequence of numbers. And here, so your sequence of points is a sequence of sequences. Just like in the example we did here, your sequence of points in your space of bounded continuous functions is a sequence of functions. Here we have a sequence of sequences, which again, that sequence is just a function, so you shouldn't be too scared. But try your hand at showing that this is a Banach space just from what we've done so far, following this kind of blueprint. And again, it'll be kind of the same. You first show that a Cauchy sequence in here is in fact bounded. Then show that point-wise, each of the, in here, point-wise should mean each of the entries of your sequence of sequences forms a Cauchy sequence. Then that allows you to obtain a candidate sequence as the limit of your sequence of sequences. And then you have to show again through this argument that you do have convergence with respect to this norm, that that sequence is bounded, and in fact, that that sequence satisfies this condition in order to be in this space. So I think I'll stop there.