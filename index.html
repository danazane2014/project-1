  <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
  <html>

  <!-- ======================================================================= -->
  <script src="http://www.google.com/jsapi" type="text/javascript"></script>
  <script type="text/javascript">google.load("jquery", "1.3.2");</script>
  <style type="text/css">
    body {
      font-family: "Crimson Text","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
      font-weight:300;
      font-size:18px;
      margin-left: auto;
      margin-right: auto;
      width: 100%;
    }

    pre {
      background-color: #f6f8fa;
      padding: 16px;
    }

    code {
      font-family: "SFMono-Regular","Consolas","Liberation Mono","Menlo",monospace;
      overflow: scroll;
    }

    h1 {
      font-family: "Source Sans Pro";
      font-weight:300;
    }

    div {
      max-width: 95%;
      margin:auto;
      padding: 10px;
    }

    .table-like {
      display: flex;
      flex-wrap: wrap;
      flex-flow: row wrap;
      justify-content: center;
    }

    .disclaimerbox {
      background-color: #eee;
      border: 1px solid #eeeeee;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
      padding: 20px;
    }

    video.header-vid {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
    }

    img {
      padding: 0;
      display: block;
      margin: 0 auto;
      max-height: 100%;
      max-width: 100%;
    }

    iframe {
      max-width: 100%;
    }

    img.header-img {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
    }

    img.rounded {
      border: 1px solid #eeeeee;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
      color: #1367a7;
      text-decoration: none;
    }
    a:hover {
      color: #208799;
    }

    td.dl-link {
      height: 160px;
      text-align: center;
      font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow:
              0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
              5px 5px 0 0px #fff, /* The second layer */
              5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
              10px 10px 0 0px #fff, /* The third layer */
              10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
              15px 15px 0 0px #fff, /* The fourth layer */
              15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
              20px 20px 0 0px #fff, /* The fifth layer */
              20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
              25px 25px 0 0px #fff, /* The fifth layer */
              25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
      margin-left: 10px;
      margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow:
              0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
              5px 5px 0 0px #fff, /* The second layer */
              5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
              10px 10px 0 0px #fff, /* The third layer */
              10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
      margin-top: 5px;
      margin-left: 10px;
      margin-right: 30px;
      margin-bottom: 5px;
    }

    .vert-cent {
      position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
      border: 0;
      height: 1px;
      max-width: 1100px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }

    #authors td {
      padding-bottom:5px;
      padding-top:30px;
    }
  </style>
  <!-- ======================================================================= -->

  <!-- Start : Google Analytics Code -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-64069893-4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-64069893-4');
  </script> -->
  <!-- End : Google Analytics Code -->

  <script type="text/javascript" src="resources/hidebib.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
  <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">

  <head>
  <div max-width=100%>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <link rel="icon" href="favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="57x57" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-152x152.png" />
    <link rel="apple-touch-icon" sizes="180x180" href="//www-media.stanford.edu/assets/favicon/apple-touch-icon-180x180.png" />

    <link rel="icon" type="image/png" href="//www-media.stanford.edu/assets/favicon/favicon-196x196.png" sizes="196x196" />
    <link rel="icon" type="image/png" href="//www-media.stanford.edu/assets/favicon/favicon-192x192.png" sizes="192x192" />
    <link rel="icon" type="image/png" href="//www-media.stanford.edu/assets/favicon/favicon-128.png" sizes="128x128" />
    <link rel="icon" type="image/png" href="//www-media.stanford.edu/assets/favicon/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/png" href="//www-media.stanford.edu/assets/favicon/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="//www-media.stanford.edu/assets/favicon/favicon-16x16.png" sizes="16x16" />

    <link rel="mask-icon" href="//www-media.stanford.edu/assets/favicon/safari-pinned-tab.svg" color="#ffffff">
    <meta name="application-name" content="Stanford University"/>
    <meta name="msapplication-TileColor" content="#FFFFFF" />
    <meta name="msapplication-TileImage" content="//www-media.stanford.edu/assets/favicon/mstile-144x144.png" />
    <meta name="msapplication-square70x70logo" content="//www-media.stanford.edu/assets/favicon/mstile-70x70.png" />
    <meta name="msapplication-square150x150logo" content="//www-media.stanford.edu/assets/favicon/mstile-150x150.png" />
    <meta name="msapplication-square310x310logo" content="//www-media.stanford.edu/assets/favicon/mstile-310x310.png" />
    <title>SIGHT: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts</title>
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="canonical" href="https://ezliu.github.io/" />
  <meta name="referrer" content="no-referrer-when-downgrade" />

  <meta property="og:site_name" content="SIGHT" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="SIGHT: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts" />
  <meta property="og:description" content="Rose E. Wang, Pawan Wirawarn, Noah Goodman, Dorottya Demszky. SIGHT: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts. 2020." />
  <meta property="og:url" content="https://ezliu.github.io/" />
  <meta property="og:image" content="https://ezliu.github.io/resources/blue.svg" />

  <meta property="article:publisher" content="https://ezliu.github.io/" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="SIGHT: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts" />
  <meta name="twitter:description" content="Rose E. Wang, Pawan Wirawarn, Noah Goodman, Dorottya Demszky. SIGHT: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts. 2020." />
  <meta name="twitter:url" content="https://ezliu.github.io/" />
  <meta name="twitter:image" content="https://ezliu.github.io/resources/red.png" />
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

  <script src="https://www.youtube.com/iframe_api"></script>
  <meta name="twitter:player" content="https://www.youtube.com/embed/EiIC0Rkz8-s" />
  <meta name="twitter:player:width" content="640" />
  <meta name="twitter:player:height" content="360" />
</head>

<body>

      <br>
      <center><span style="font-size:44px;font-weight:bold;font-family:Source Sans Pro;">SIGHT: A Large Annotated Dataset on <br/>Student Insights Gathered from Higher Education Transcripts</span></center><br/>
      <div class="table-like" style="justify-content:space-evenly;max-width:900px;margin:auto;">
          <div><center><span style="font-size:25px"><a href="https://cs.stanford.edu/~rewang" target="_blank">Rose E. Wang*</a></span></center>
          <center><span style="font-size:25px">Stanford</span></center>
          </div>

          <div><center><span style="font-size:25px"><a href="https://profiles.stanford.edu/pawan-wirawarn" target="_blank">Pawan Wirawarn*</a></span></center>
          <center><span style="font-size:25px">Stanford</span></center>
          </div>

          <div><center><span style="font-size:25px"><a href="https://cocolab.stanford.edu/ndg" target="_blank">Noah Goodman</a></span></center>
          <center><span style="font-size:25px">Stanford</span></center>
          </div>

          <div><center><span style="font-size:25px"><a href="https://www.dorademszky.com/" target="_blank">Dorottya Demszky</a></span></center>
          <center><span style="font-size:25px">Stanford</span></center>
          </div>
          <div>
            <center><span style="font-size:15px">* = Equal Contributions</span></center>
          </div>
          <center><span style="font-size:25px">Proceedings of Innovative Use of NLP for Building Educational Applications (BEA), 2023</span></center>
      </div>

      <div class="table-like" style="justify-content:space-evenly;max-width:700px;margin:auto;padding:5px">
        <div><center><span style="font-size:28px"><a href="https://arxiv.org/abs/2306.09343">[Paper]</a></span></center></div>
        <div><center><span style="font-size:28px"><a href='https://github.com/rosewang2008/sight'>[Code]</a></span></center> </div>
        <div><center><span style="font-size:28px"><a href='https://www.youtube.com/watch?v=Yt-2jLJLKjI&ab_channel=RoseWang'>[Video]</a></span></center> </div>
      </div>

      <center>
      <iframe width="768" height="432" src="https://www.youtube.com/embed/Yt-2jLJLKjI" allowfullscreen></iframe>
      <br>

      <div style="width:800px; margin:0 auto" align="justify">
        <p><b>Abstract.</b> Lectures are a learning experience for both students and teachers. Students learn from teachers about the subject material, while teachers learn from students about how to refine their instruction. However, online student feedback is unstructured and abundant, making it challenging for teachers to learn and improve. We take a step towards tackling this challenge. First, we contribute a dataset for studying this problem: SIGHT is a large dataset of 288 math lecture transcripts and 15,784 comments collected from the Massachusetts Institute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we develop a rubric for categorizing feedback types using qualitative analysis. Qualitative analysis methods are powerful in uncovering domain-specific insights, however they are costly to apply to large data sources. To overcome this challenge, we propose a set of best practices for using large language models (LLMs) to cheaply classify the comments at scale. We observe a striking correlation between the model's and humans' annotation: Categories with consistent human annotations (>0.9 inter-rater reliability, IRR) also display higher human-model agreement (>0.7), while categories with less consistent human annotations (0.7-0.8 IRR) correspondingly demonstrate lower human-model agreement (0.3-0.5). These techniques uncover useful student feedback from thousands of comments, costing around $0.002 per comment. We conclude by discussing exciting future directions on using online student feedback and improving automated annotation techniques for qualitative research.
      </p>
      </div>
      <br><hr>

      <center><h1>SIGHT dataset</h1></center>
      <div style="width:800px; margin:0 auto" align="justify">
        <p>
          SIGHT contains <b>288 math lecture transcripts and 15,784 comments</b> collected from the Massachusetts Institute of Technology OpenCourseWare (MIT OCW) YouTube channel.
          Below is an example of what the transcripts and user comments look like.
        </p>
        <center><h2>Lecture transcripts</h2></center>
        <!-- Code snippet of transcript -->
        <p>
          Here is an example of a lecture transcript in our dataset---this is from the course 18.065: Matrix Methods in Data Analysis, Signal Processing, and Machine Learning.
        </p>
        <div class="layered-paper-big">
          <pre align=left style="font-size:14px" width=800px><code>[...] OK, just as we're getting started, I thought I'd add a few words about a 
question that came up after class. Suppose in that discussion last time, where 
you were given three, you were given a distance matrix, you were given the distance 
between x1 and x2, between x2 and x3, and between x1 and x3, and you wanted to find 
points that satisfied that. Well, we're going to fail on this example, because if 
the distance here is 1, the distance here is 1, then by the triangle inequality, 
the distance from x1 to x3 could not be more than 2. And when we square it, it 
could not be more than 4. And here it's 6. So what's going to happen? What goes 
wrong in that case? Yeah, I hadn't commented on that, and I'm not sure that the 
paper that I referenced does so. So I had to do a little search back in the 
literature, because people couldn't overlook this problem. So this is the triangle 
inequality fails. And it's not going to help to go into 10 dimensions, because the 
triangle inequalities doesn't change. And it's still there in 10 dimensions, and 
we're still failing. So what happens? Well, what could happen? Do you remember, and 
you'll have to remind me, the key equation. You remember we had an equation 
connecting the matrix. [...]</code></pre>
        </div>
        <br/>
        <center><h2>User comments</h2></center>
        <p>
          We develop a rubric of different feedback categories and label each comment with whether the category applies. 
          Here are the feedback categories and examples.
        </p>
        <a href="assets/example_comments.png"><img src="assets/example_comments.png" width="800px" padding="10px"></img></a>
        <p>
          Many categories can apply to a given comment. Take for instance the comment below. Thus, in our dataset, each comment is annotated as a binary classification task per category, i.e., does this category apply to this comment?
        </p>
        <a href="assets/multiple_labels.png"><img src="assets/multiple_labels.png" width="800px"></img></a>
      </div>
      <br><hr>

      <center><h1>Annotating at Scale</h1></center>
      <div style="width:800px; margin:0 auto" align="justify">
        <p>
          The challenge with online student feedback is that it is <b>unstructured</b> and <b>abundant</b>. This makes it difficult for teachers to learn and improve. Our work investigates ways to automatically synthesize insights and learn from this abundance of student feedback in online educational settings. We propose a set of best practices for using large language models (LLMs) to cheaply classify the comments at scale. In particular, we use GPT-3.5-turbo-0301 to scale annotation of the rubric we've developed and analyze its performance.
        </p>
        <center><h2>Some takeaways from our work include...</h2></center>
          <ul>
            <li>
              <b>There is a striking correlation between the model's and humans' annotation! </b> Categories with consistent human annotations (>0.9 inter-rater reliability, IRR) also display higher human-model agreement (>0.7). Categories with less consistent human annotations (0.7-0.8 IRR) correspondingly demonstrate lower human-model agreement (0.3-0.5). 
              <div  style="padding:20px">
                <a href="assets/paper_results/correlation.png"><img src="assets/paper_results/correlation.png" width="600px"></img></a>
              </div>
            </li>
            <li>
              <b>Auxiliary information has variable effects on annotation across the categories.</b> For example, adding 3-shot examples to the prompt can make the model's performance sometimes worse (rf. `3-shot` on `clarification`), sometimes better (rf. `3-shot` on `pedagogy`).
              <div  style="padding:20px">
                <a href="assets/paper_results/irr_table.png"><img src="assets/paper_results/irr_table.png" width="600px"></img></a>
              </div>
            </li>
            <li>
              <b>Our error analysis on the categories with low human-model agreement reveals that the model misses subtle references to categories.</b> The table below illustrates a few examples on the `pedagogy` and `personal` categories.
              <div  style="padding:20px">
                <a href="assets/paper_results/error_analysis.png"><img src="assets/paper_results/error_analysis.png" width="600px"></img></a>
              </div>
            </li>
            <li>
              <b>Automated annotations with LLMs nonetheless provide a useful filter on feedback category types with high agreement.</b> The table below reveals the diversity of feedback types within the `confusion` category, identified from the 15k comments in SIGHT.
              <br />
              <div  style="padding:20px">
                <a href="assets/paper_results/confusion_examples.png"><img src="assets/paper_results/confusion_examples.png" width="600px"></img></a>
              </div>
            </li>
          </ul>
        </p>
        <center><h2>For more details, please check out our paper linked below!</h2></center>
      </div>

      <center><h1>Paper and BibTeX</h1></center>
      <table align=center width=800px>
        <tr>
        <td width=200px align=left>
          <pre align=left><code>@inproceedings{wang2023sight,
            title={SIGHT: A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts},
            author={Wang, Rose E and Wirawarn, Pawan and Goodman, Noah and Demszky, Dorottya},
            year={2023},
            month = jun,
            booktitle = {18th Workshop on Innovative Use of NLP for Building Educational Applications},
            month_numeric = {6}
          }</code></pre>
        </td>
      </table>
      <div class="table-like">
        <span style="font-size:28px"><a href="https://arxiv.org/abs/2306.09343">[ArXiv]</a></span>
      </div>
    <br><hr>
      <center id="acknowledgements"><h1>Acknowledgements</h1></center>
        <p>
          This website is adapted from
          <a href="https://orybkin.github.io/video-gcp/">this website</a>, which was
          in turn adapted from
          <a href="https://pathak22.github.io/modular-assemblies/">this website</a>.
          Feel free to use this website as a template for your own projects by referencing this!
        </p>

        <p>
          Icons used in some of the above figures were made by Freepik,
          ThoseIcons, dDara, Pixel perfect, ThoseIcons, mynamepong, Icongeek26,
          and Vitaly Gorbachev from
          <a href="https://www.flaticon.com">flaticon.com</a>.
        </p>
    </table>
</div>
</body>
</html>
